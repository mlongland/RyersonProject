{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Spark Logo](http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png) + ![Python Logo](http://spark-mooc.github.io/web-assets/images/python-logo-master-v3-TM-flattened_small.png)\n",
    "# **Feature Extraction From Beer Reviews**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preliminaries**\n",
    "#### We read in the allBeer.txt file and create an RDD consisting of lines.\n",
    "#### We want to remove the header from the file, so the parseDataFileLine function identifies lines starting with 'beer_id' and applies a flag of 0, other lines with the correct number of fields are flagged 1, and incorrect lines are flagged -1.  The lines are split into arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parseDatafileLine(datafileLine):\n",
    "    ##Parse a line of the data file using the specified regular expression pattern\n",
    "    splitArray = datafileLine.split(\"\\t\")\n",
    "    for x in range(0,len(splitArray)):\n",
    "        splitArray[x]=splitArray[x].replace(\"\\\"\",'')\n",
    "    #print len(splitArray)\n",
    "    #print splitArray[0],splitArray[1],splitArray[2]\n",
    "    if splitArray[0]=='beer_id':\n",
    "        return (splitArray,0)\n",
    "    elif len(splitArray)<>23:\n",
    "        ##this is a failed parse\n",
    "        return (splitArray,-1)\n",
    "    else:\n",
    "        return (splitArray, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the file\n",
    "#### We read the file into three rdds by first parsing the file as above, the header rdd, failed rdd and the valid rdd.  Print the header names so we can remember what fields we're dealing with and in what order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 beer_id\n",
      "1 beer_name\n",
      "2 brewer_name\n",
      "3 beer_style\n",
      "4 distribution\n",
      "5 brewery_location\n",
      "6 commercial_desc\n",
      "7 RATINGS: \n",
      "8 MEAN (/5)\n",
      "9 WEIGHTED AVG\n",
      "10 EST. CALORIES\n",
      "11 ABV (%)\n",
      "12 IBU\n",
      "13 SCORE\n",
      "14 AROMA (/10)\n",
      "15 APPEARANCE(/5)\n",
      "16 TASTE(/10)\n",
      "17 PALATE(/5)\n",
      "18 OVERALL(/20)\n",
      "19 reviewer_name\n",
      "20 review_location\n",
      "21 review_date\n",
      "22 review_content\n",
      "AllBeer.txt - Read 240355 lines, successfully parsed 240354 lines, failed to parse 0 lines\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "baseDir = os.path.join('')\n",
    "allBeer_Path = 'AllBeer.txt'\n",
    "STOPWORDS_PATH = 'stopwords.txt'\n",
    "\n",
    "def parseData(filename):\n",
    "    #Parse a data file returns a RDD of parsed lines\n",
    "    \n",
    "    return (sc\n",
    "            .textFile(filename, 4, 0)\n",
    "            .map(parseDatafileLine)\n",
    "            .cache())\n",
    "\n",
    "def loadData(path):\n",
    "    ##Load a data file, returns a RDD of parsed valid lines\n",
    "    \n",
    "    filename = os.path.join(baseDir, path)\n",
    "    raw = parseData(filename).cache()\n",
    "    failed = (raw\n",
    "              .filter(lambda s: s[1] == -1)\n",
    "              .map(lambda s: s[0]))\n",
    "    for line in failed.take(10):\n",
    "        print '%s - Invalid datafile line: %s' % (path, line)\n",
    "    valid = (raw\n",
    "             .filter(lambda s: s[1] == 1)\n",
    "             .map(lambda s: s[0])\n",
    "             .cache())\n",
    "    header = (raw\n",
    "              .filter(lambda s: s[1]==0)\n",
    "             .map(lambda s:s[0])\n",
    "             )\n",
    "    for line in header.take(1):\n",
    "        for x in range(0,len(line)):\n",
    "            print x,line[x]\n",
    "            \n",
    "    rawLines = raw.count()\n",
    "    validLines = valid.count()\n",
    "    failedLines = failed.count()\n",
    "    print '%s - Read %d lines, successfully parsed %d lines, failed to parse %d lines' % (path, rawLines, validLines,failedLines)\n",
    "    return valid\n",
    "    \n",
    "allBeer = loadData(allBeer_Path)\n",
    "#allReviews = loadData(allReviews_Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's examine the first few entries of a sample of 5 lines to check if things look ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "allBeer: 40920, Wernecker Haustrunk Pils, Wernecker Bierbrauerei, Pilsener, distribution unknown\n",
      "\n",
      "23\n",
      "allBeer: 21911, Au Ma'tre Brasseur La Boucaneuse, AMB - Ma'tre Brasseur, Smoked, distribution unknown\n",
      "\n",
      "23\n",
      "allBeer: 4991, New Albanian / Struise Naughty Girl, New Albanian Brewing Company, India Pale Ale (IPA), Regional Distribution\n",
      "\n",
      "23\n",
      "allBeer: 38430, BrewDog IPA is Dead - Pioneer, BrewDog, India Pale Ale (IPA), Broad Distribution\n",
      "\n",
      "23\n",
      "allBeer: 41353, Cascade Cerise Nouveau, Cascade Brewing, Sour/Wild Ale, Local Distribution\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampleArray=allBeer.takeSample(False,5,1)\n",
    "for line in sampleArray:\n",
    "    print len(line)\n",
    "    print 'allBeer: %s, %s, %s, %s, %s\\n' % (line[0], line[1], line[2],line[3],line[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we'll split the data into a training set (80%) and test set (%20).  \n",
    "#### This is slightly complicated by the fact that we want to split each user into 80/20, not the set of reviews as a whole.  We will take advantage of stratified sampling in Spark, grouping the reviews by the user name, then sampling by key.  To get the unused data we employ subtractByKey using a compound key of the username and the beer_id, guaranting uniqueness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240334\n",
      "192441\n",
      "47913\n"
     ]
    }
   ],
   "source": [
    "##Using the allBeer array, take stratified sample, and remove blank reviews.\n",
    "beerByUser = allBeer.map(lambda x:(x[19],x)).filter(lambda (x,y):y[22]!='')\n",
    "sampleKeys = beerByUser.keys().collect()\n",
    "fractions={}\n",
    "for k in sampleKeys:\n",
    "    fractions[k]=0.8\n",
    "    \n",
    "beerTrain = beerByUser.sampleByKey(False,fractions).cache()\n",
    "beerTrainKeyed = beerTrain.map(lambda (x,y):(y[0]+y[19],y))\n",
    "beerTest = allBeer.map(lambda x:(x[0]+x[19],x)).subtractByKey(beerTrainKeyed).map(lambda (x,y):(y[19],y)).cache()\n",
    "print beerByUser.count()\n",
    "print beerTrain.count()\n",
    "print beerTest.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's examine the results with a couple of random users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user patricks110 has 79 reviews, split into 57 Train and 22 Test\n",
      "The user slowrunner77 has 623 reviews, split into 489 Train and 134 Test\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import random_integers\n",
    "##find a random user and print out the train and test set.\n",
    "randomUsers = random_integers(1,len(sampleKeys),2)\n",
    "sampleUserReviewCount = beerByUser.filter(lambda (x,y):x==sampleKeys[randomUsers[0]]).count()\n",
    "sampleUserTrainCount = beerTrain.filter(lambda (x,y):x==sampleKeys[randomUsers[0]]).count()\n",
    "sampleUserTestCount = beerTest.filter(lambda (x,y):x==sampleKeys[randomUsers[0]]).count()\n",
    "print \"The user %s has %d reviews, split into %d Train and %d Test\" % (sampleKeys[randomUsers[0]],sampleUserReviewCount,sampleUserTrainCount,sampleUserTestCount)\n",
    "\n",
    "sampleUserReviewCount = beerByUser.filter(lambda (x,y):x==sampleKeys[randomUsers[1]]).count()\n",
    "sampleUserTrainCount = beerTrain.filter(lambda (x,y):x==sampleKeys[randomUsers[1]]).count()\n",
    "sampleUserTestCount = beerTest.filter(lambda (x,y):x==sampleKeys[randomUsers[1]]).count()\n",
    "print \"The user %s has %d reviews, split into %d Train and %d Test\" % (sampleKeys[randomUsers[1]],sampleUserReviewCount,sampleUserTrainCount,sampleUserTestCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the reviews:\n",
    "#### Each user has a different way of scoring beers, some people judge more harshly than others.  In order to even out these scores, we get get statistics for each user and adjust their scores to fit a common distribution.  In this particular case we use a normal distribution for it's simplicity to execute.  Users with 1 or less reviews will have a standard deviation of 0, in which case we substitute 1 to ensure the division when obtaining z-scores we will not divide by zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Lubiere', ['22524', 'Brutopia Gold n Wheat', 'Brutopia', 'Wheat Ale', 'distribution unknown', 'Montreal, Canada', 'No commercial description', '6.000', '2.980', '2.870', '', '', '', -0.05648804325138059, '6.000', '3.000', '7.000', '3.000', 0.21007660350402088, 'Lubiere', 'Ottawa, Ontario, CANADA ', 'APR 3, 2004 ', 'Golden clear beer with a fresh malt and cookie nose, and a pleasant aroma of hops. Nice crisp matly taste with some lactic /milkery notes, with a touch of lemon, and the light hoips which linger on pleasantly. Medium body for a lighter beer. ']), ('adnielsen', ['26927', 'Hill Farmstead Genealogy of Morals - Bourbon', 'Hill Farmstead Brewery', 'Imperial Stout', 'Local Distribution', 'Greensboro , Vermont USA', 'An Imperial Stout brewed with Wheat and Coffee and aged in Bourbon barrels from our favorite distilleries...', '97.000', '', '4.110', '300.000', '10.000', '', 1.4296487759258447, '9.000', '4.000', '8.000', '4.000', 1.5272391508510978, 'adnielsen', 'Fort Collins, Colorado, USA ', 'DEC 25, 2014', 'Bottle @ home. Christmas Eve 2014 with jcnielsen. Pours a black appearance with a brown head. Big sweet dark chocolate and toffee in the aroma with smooth whiskey, caramel, and coconut. Creamy mouth feel. Moderate high sweetness. Moderate low bitterness. Lots of coconut and whiskey in the flavor. Pretty fucken tasty. ']), ('Thorpe429', ['2118', 'Upright Sole Composition: Jaune Quatre (Gin Barrel)', 'Upright Brewing', 'Saison', 'distribution unknown', 'Portland , Oregon USA', 'Single cask batch of Four aged 3 months in Ransom Old Tom Gin barrels with dry chrysanthemum flowers as well as homegrown yellow rose petals.', '20.000', '3.850', '3.590', '135.000', '4.500', '', -0.09674685409875738, '6.000', '4.000', '6.000', '4.000', -0.1548815833814837, 'Thorpe429', ', Illinois, USA ', 'DEC 2, 2012 ', 'Big thanks to boralyl for sending this out my way. Served in a tumbler. Clear golden-peach color. The nose is slightly gin-like with some floral and earthy nights. The flavor is a bit spicy with floral notes. Touch of pepper. Very light and crisp. ']), ('hopdog', ['9114', 'Iron Hill Ore House IPA', 'Iron Hill Maple Shade', 'India Pale Ale (IPA)', 'Regional Distribution', 'Maple Shade , New Jersey USA', 'Golden IPA with a balanced hop bitterness and wonderful citrus and pine aroma and flavor.', '15.000', '3.620', '3.480', '201.000', '6.700', '60.000', 0.22345223340823162, '7.000', '3.000', '7.000', '3.000', 0.4067270872805663, 'hopdog', 'Lansdale, Pennsylvania, USA ', 'DEC 22, 2014', 'Tasted from Growler. Poured a golden color with an off white head. Citrus with pine. Some caramel in the tastes.']), ('firefly765', ['11832', 'Lagunitas Dogtown Pale Ale', 'Lagunitas Brewing Company', 'American Pale Ale', 'Regional Distribution', 'Petaluma , California USA', 'Medium amber malty American pale ale', '353.000', '', '3.400', '192.000', '6.400', '', -0.9171610478088179, '4.000', '4.000', '7.000', '5.000', -0.5773502691896258, 'firefly765', '', 'MAY 23, 2015', 'Pint draft at the brass tap in Bonita Springs. Light copper in color with a nice white frothy head. Not much aroma to speak of. Light bodied and crisp nice hops balance. Smooth and goes down easy low level of carbonation. '])]\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "##13 SCORE\n",
    "##14 AROMA (/10)\n",
    "##15 APPEARANCE(/5)\n",
    "##16 TASTE(/10)\n",
    "##17 PALATE(/5)\n",
    "##18 OVERALL(/20)\n",
    "\n",
    "def replaceZeroes(inputValue,replacementValue):\n",
    "    if inputValue == 0:\n",
    "        inputValue = replacementValue\n",
    "    return inputValue\n",
    "\n",
    "def subtractFromColumn(inputList,columnToChange,subtractAmount):\n",
    "    inputList[columnToChange]=float(inputList[columnToChange])-subtractAmount\n",
    "    return inputList\n",
    "\n",
    "def divideColumn(inputList,columnToChange,divisor):\n",
    "    inputList[columnToChange]=float(inputList[columnToChange])/divisor\n",
    "    return inputList\n",
    "\n",
    "\n",
    "### rewrite this to be RDD of (key,everything else) and return (key, everything with normalized column x)\n",
    "### Then run a few times and cache, and move this up into the preliminaries (post split)\n",
    "def normalizeScoreByKey(inputRDD,scoreColumn):\n",
    "    ##Takes in RDD of (key,array) and \n",
    "    ##returns RDD of (key,array with scoreColumn normalized)\n",
    "    sumScores = inputRDD.map(lambda (x,y):(x,float(y[scoreColumn]))).reduceByKey(lambda a,b:a+b)\n",
    "    #print sumScores.map(lambda (x,y):y).reduce(lambda a,b:a+b)\n",
    "    countScoresPerKey = inputRDD.map(lambda (x,y):(x,1)).reduceByKey(lambda a,b:a+b)\n",
    "    #print countKeys.map(lambda (x,y):y).reduce(lambda a,b:a+b)\n",
    "    averageScores = sumScores.join(countScoresPerKey).map(lambda (x,y):(x,y[0]/y[1]))\n",
    "    #print averageScores.takeSample(False,5,3)\n",
    "    centredScores = inputRDD.join(averageScores).map(lambda (x,(y,z)):(x,subtractFromColumn(y,scoreColumn,z)))\n",
    "    #print centredScores.map(lambda (x,y):y[scoreColumn]).reduce(lambda a,b:a+b)\n",
    "    centredScoresSquaredSum = centredScores.map(lambda (x,y):(x,y[scoreColumn]*y[scoreColumn])).reduceByKey(lambda a,b:a+b)\n",
    "    centredScoresSquaredSumAndCount = centredScoresSquaredSum.join(countScoresPerKey)\n",
    "    stdDeviationByKey = centredScoresSquaredSumAndCount.map(lambda (x,y):(x,sqrt(y[0]/y[1])))\n",
    "    ##This is actually pointless since a centred score is 0 and 0/anything = 0\n",
    "    ##countLines = stdDeviationByUser.count()\n",
    "    ##avgStdDev = stdDeviationByUser.map(lambda (x,y):y).reduce(lambda a,b:a+b)/countLines\n",
    "    stdDeviationByKeyNoZero = stdDeviationByKey.map(lambda (x,y):(x,replaceZeroes(y,1)))\n",
    "    normalizedRDD = centredScores.join(stdDeviationByKeyNoZero).map(lambda (x,(y,z)):(x,divideColumn(y,scoreColumn,z)))\n",
    "    return normalizedRDD\n",
    "\n",
    "##Normalize the Scores\n",
    "normalizedScores = normalizeScoreByKey(beerTrain,13)\n",
    "##Normalize the rest of the ratings\n",
    "#beerTrainNormA = normalizeScoreByKey(normalizedScores,14)\n",
    "#beerTrainNormB = normalizeScoreByKey(beerTrainNormA,15)\n",
    "#beerTrainNormC = normalizeScoreByKey(beerTrainNormB,16)\n",
    "#beerTrainNormD = normalizeScoreByKey(beerTrainNormC,17)\n",
    "beerTrainNormalized = normalizeScoreByKey(normalizedScores,18).cache()\n",
    "\n",
    "print beerTrainNormalized.takeSample(False,5,4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Normalized Histograms**\n",
    "#### Plot histograms of the normalized ratings to check to see if normality approximately holds.\n",
    "#### Clearly score and overall are not normal, skewed right.  This would imply that when people hate a beer, they're more willing to review it harshly than they are willing to give a glowing review to a beer they love."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAADSCAYAAABeiClsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkqSOM5lLktRxJnNJkjru/wO3W3joGLEBVAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5376210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAADSCAYAAABeiClsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nD6dL8cpYINPhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x524a190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "##Get all the normalized scores into one list.\n",
    "scoreValues = beerTrainNormalized.map(lambda (x,y): y[13]).collect()\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "plt.title('Normalized Scores')\n",
    "plt.hist(scoreValues, 50, log=False)\n",
    "overallValues = beerTrainNormalized.map(lambda (x,y): y[18]).collect()\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "plt.title('Normalized Overall')\n",
    "plt.hist(overallValues, 50, log=False)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Making Bags of Words\n",
    "#### We can take the commercial descriptions and the user input text reviews and convert them into bags of words, we can then treat each word as a feature.  \n",
    "#### We should take out stopwords before we do this, to avoid unfairly weighting reviews based on words which don't contribute much meaning, such as \"the\", \"a\", \"is\", \"which\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the stopwords: set([u'all', u'just', u'being', u'over', u'both', u'through', u'yourselves', u'its', u'before', u'with', u'had', u'should', u'to', u'only', u'under', u'ours', u'has', u'do', u'them', u'his', u'very', u'they', u'not', u'during', u'now', u'him', u'nor', u'did', u'these', u't', u'each', u'where', u'because', u'doing', u'theirs', u'some', u'are', u'our', u'ourselves', u'out', u'what', u'for', u'below', u'does', u'above', u'between', u'she', u'be', u'we', u'after', u'here', u'hers', u'by', u'on', u'about', u'of', u'against', u's', u'or', u'own', u'into', u'yourself', u'down', u'your', u'from', u'her', u'whom', u'there', u'been', u'few', u'too', u'themselves', u'was', u'until', u'more', u'himself', u'that', u'but', u'off', u'herself', u'than', u'those', u'he', u'me', u'myself', u'this', u'up', u'will', u'while', u'can', u'were', u'my', u'and', u'then', u'is', u'in', u'am', u'it', u'an', u'as', u'itself', u'at', u'have', u'further', u'their', u'if', u'again', u'no', u'when', u'same', u'any', u'how', u'other', u'which', u'you', u'who', u'most', u'such', u'why', u'a', u'don', u'i', u'having', u'so', u'the', u'yours', u'once'])\n",
      "['test', 'tf', 'function', 'return', 'non', 'stopword', 'frequencies', 'frequency', 'sourness']\n"
     ]
    }
   ],
   "source": [
    "stopfile = os.path.join(baseDir, STOPWORDS_PATH)\n",
    "stopwords = set(sc.textFile(stopfile).collect())\n",
    "testString = \"This is a test of the tf function.  It should return non stopword frequencies frequency sourness\"\n",
    "print 'These are the stopwords: %s' % stopwords\n",
    "split_regex = r'\\W+'\n",
    "\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "#Stmmr = PorterStemmer()\n",
    "\n",
    "def tokenize(string):\n",
    "    ##takes in a string and tokenizes it, removing stopwords, returns list\n",
    "    simple=filter(None,re.split(split_regex,string.lower()))\n",
    "    #simple = [Stmmr.stem(i) for i in simple]\n",
    "    return [i for i in simple if i not in stopwords]\n",
    "\n",
    "print tokenize(testString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tokenizing the Commercial Description and Review**\n",
    "#### Now tokenize the commercial descriptions and reviews. \n",
    "#### To see how much data we're dealing with let's count the total number of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4672914 tokens in the commercial descriptions\n",
      "There are 6680826 tokens in the reviews\n"
     ]
    }
   ],
   "source": [
    "##6 commercial description\n",
    "##22 user input review\n",
    "##make an RDD where the user_id is the key, and the value is 2 arrays of tokens \n",
    "##and the original line\n",
    "beerTrainToToken = beerTrainNormalized.map(lambda (x,y):(y[19],(tokenize(y[6]),tokenize(y[22]),y)))\n",
    "\n",
    "def countTokens(textRDD,reviewTRUE):\n",
    "    ## Count and return the number of tokens\n",
    "    if reviewTRUE==True:\n",
    "        return textRDD.map(lambda (x,y):len(y[1])).reduce(lambda a,b:a+b)\n",
    "    else:\n",
    "        return textRDD.map(lambda (x,y):len(y[0])).reduce(lambda a,b:a+b)\n",
    "\n",
    "print 'There are %s tokens in the commercial descriptions' % countTokens(beerTrainToToken,False)\n",
    "print 'There are %s tokens in the reviews' % countTokens(beerTrainToToken,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get an idea of how big a review is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review from user \"SlovakSniper\" has the most tokens (579)\n",
      "The review from user \"Shurf\" has the least tokens (0)\n"
     ]
    }
   ],
   "source": [
    "def findBiggestRecord(textRDD,reviewTRUE):\n",
    "    # Find and return the record with the largest number of tokens\n",
    "    if reviewTRUE==True:\n",
    "        return textRDD.takeOrdered(1,lambda (x,y):-len(y[1]))\n",
    "    else:\n",
    "        return textRDD.takeOrdered(1,lambda (x,y):-len(y[0]))\n",
    "\n",
    "def findSmallestRecord(textRDD,reviewTRUE):\n",
    "    # Find and return the record with the largest number of tokens\n",
    "    if reviewTRUE==True:\n",
    "        return textRDD.takeOrdered(1,lambda (x,y):len(y[1]))\n",
    "    else:\n",
    "        return textRDD.takeOrdered(1,lambda (x,y):len(y[0]))\n",
    "\n",
    "biggestReview = findBiggestRecord(beerTrainToToken,True)\n",
    "print 'The review from user \"%s\" has the most tokens (%s)' % (biggestReview[0][0],\n",
    "                                                                   len(biggestReview[0][1][1]))\n",
    "smallestReview = findSmallestRecord(beerTrainToToken,True)\n",
    "print 'The review from user \"%s\" has the least tokens (%s)' % (smallestReview[0][0], len(smallestReview[0][1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So clearly we've got some reviews that are empty, and we'll need some special handling for those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Weighted Bag-of-Words using TF-IDF**\n",
    "\n",
    "### Term Frequency (TF) \n",
    "#### This gives higher weight to tokens that appear many times in a individual document. It is computed as the frequency of a token in a document. If a word occurs often in a document, then it is more important to the meaning of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'function': 0.14285714285714285, 'non': 0.14285714285714285, 'return': 0.14285714285714285, 'frequencies': 0.14285714285714285, 'stopword': 0.14285714285714285, 'tf': 0.14285714285714285, 'test': 0.14285714285714285}\n"
     ]
    }
   ],
   "source": [
    "testString = \"This is a test of the tf function.  It should return non stopword frequencies\"\n",
    "def tf(tokens):\n",
    "    ###Compute TF from list of tokens, return dictionary of word:tf\n",
    "    count = len(tokens)\n",
    "    words={}\n",
    "    for token in tokens:\n",
    "        words[token]=float(len([t for t in tokens if t==token]))/count\n",
    "    return words\n",
    "\n",
    "print tf(tokenize(testString))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency\n",
    "#### This gives higher weight to tokens that are rare over the entire dataset. The rationale is two documents are more alike if they have in common words which are not common to rest data set.  IDF weight for a token in a set of documents is calculated as D/d(t) where D is the total number of documents and d(t) is the number of documents with term t.  \n",
    "#### Keep in mind that the dataset for IDF is not the whole dataset, but the set of reviews for a particular user.  We want to find out what is special to that individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Chrism86', {'shop': 9.0, 'summer': 9.0, 'interpretation': 9.0, 'stlye': 9.0, 'offensive': 9.0, 'bad': 9.0, 'cheap': 9.0, 'fizzy': 9.0, 'abit': 9.0, 'bring': 9.0, 'mild': 4.5, 'citrusy': 9.0, 'looks': 9.0, 'roasted': 4.5, 'go': 9.0, 'earth': 9.0, 'alternative': 9.0, 'still': 9.0, 'bock': 9.0, 'apple': 9.0, 'style': 4.5, '21': 9.0, 'faults': 9.0, 'hops': 9.0, 'interesting': 9.0, 'honey': 4.5, 'seems': 9.0, 'character': 9.0, 'actually': 9.0, 'going': 4.5, 'black': 9.0, 'easy': 9.0, '8': 9.0, 'toffee': 9.0, 'real': 4.5, 'brown': 4.5, 'updated': 2.25, 'good': 4.5, 'dominant': 9.0, 'abv': 9.0, 'citrus': 9.0, 'familiar': 9.0, 'astringent': 9.0, 'overall': 9.0, 'none': 4.5, 'coloured': 4.5, 'dark': 3.0, 'made': 4.5, 'fan': 9.0, 'know': 9.0, 'stout': 9.0, 'drinking': 9.0, 'like': 9.0, 'peculier': 9.0, 'd': 9.0, 'malt': 1.5, 'notes': 4.5, 'didn': 9.0, 'loosely': 9.0, 'biscuity': 9.0, 'lightning': 9.0, 'benefit': 9.0, 'caramel': 4.5, 'common': 9.0, 'roast': 9.0, 'nz': 9.0, 'enhance': 9.0, 'nice': 2.25, 'round': 9.0, 'apples': 9.0, 'sep': 9.0, 've': 9.0, 'cider': 9.0, 'back': 4.5, 'synergy': 9.0, 'detection': 9.0, 'rusty': 9.0, 'sure': 9.0, 'carbonation': 4.5, 'thorogoods': 9.0, 'pale': 4.5, 'packed': 9.0, 'really': 4.5, 'lead': 9.0, 'away': 9.0, 'espresso': 9.0, 'musty': 9.0, 'hazy': 9.0, 'tend': 9.0, 'dispersed': 9.0, 'dominated': 9.0, '7': 9.0, 'prune': 9.0, 'aussie': 9.0, 'dominate': 9.0, 'across': 9.0, 'red': 9.0, 'shows': 9.0, 'body': 9.0, 'perception': 9.0, 'wheat': 9.0, 'doppel': 9.0, 'slight': 9.0, 'pours': 1.5, 'pils': 9.0, 'quite': 9.0, 'decent': 4.5, 'surely': 9.0, 'sweetened': 9.0, 'served': 9.0, 'menacing': 9.0, 'tried': 9.0, 'mullet': 9.0, 'bronze': 9.0, 'dry': 3.0, 'great': 9.0, 'technical': 9.0, 'hinting': 9.0, 'aromas': 3.0, 'raisin': 9.0, 'oatmeal': 9.0, 'agree': 9.0, 'thing': 4.5, 'amount': 9.0, 'expecting': 9.0, 'isn': 4.5, 'smoke': 9.0, 'pick': 9.0, 'lacked': 9.0, 'sweetness': 4.5, 'think': 9.0, 'comes': 9.0, 'amber': 4.5, 'golden': 3.0, 'piney': 9.0, 'whats': 9.0, 'characters': 3.0, 'presence': 9.0, 'sweet': 9.0, 'one': 9.0, 'undesirable': 9.0, 'lively': 4.5, 'murky': 9.0, 'flavoursome': 9.0, 'thick': 4.5, 'apa': 9.0, 'nose': 1.5, 'ash': 9.0, 'much': 3.0, 'would': 4.5, 'tasting': 9.0, 'assumed': 9.0, 'earthy': 9.0, 'realise': 9.0, 'least': 9.0, 'quickly': 4.5, 'beer': 9.0, 'poured': 2.25, 'lot': 9.0, 'forward': 9.0, 'lacing': 4.5, 'bitter': 4.5, 'oily': 9.0, 'thrown': 9.0, 'head': 1.125, 'medium': 9.0, 'finishes': 4.5, 'name': 9.0, 'brings': 4.5, 'tangy': 3.0, 'shattering': 9.0, 'expected': 9.0, 'tending': 9.0, 'beers': 9.0, 'heap': 9.0, 'white': 2.25, 'spice': 9.0, 'albeit': 9.0, 'kind': 9.0, '12': 9.0, 'wise': 9.0, 'dissapears': 9.0, 'tang': 9.0, 'straight': 9.0, 'grainy': 9.0, 'bitterness': 3.0, 'left': 9.0, 'suppose': 9.0, 'thin': 9.0, 'fruits': 9.0, 'detectable': 9.0, 'grass': 9.0, 'didnt': 9.0, 'leaves': 9.0, 'darker': 9.0, 'due': 9.0, 'palate': 1.0, 'reserved': 9.0, 'grassy': 9.0, 'tar': 9.0, '2009': 3.0, 'almost': 4.5, 'exceptionally': 9.0, 'year': 9.0, 'deep': 9.0, 'tad': 4.5, 'say': 9.0, 'substantial': 3.0, 'something': 9.0, 'sense': 9.0, 'tan': 9.0, 'well': 9.0, 'oxidised': 9.0, 'huge': 9.0, 'needs': 9.0, 'lemon': 9.0, 'etc': 9.0, 'rather': 4.5, 'yellow': 4.5, 'reminded': 9.0, 'exception': 9.0, 'adjunct': 9.0, 'also': 4.5, 'high': 4.5, 'complex': 9.0, 'popping': 4.5, 'hop': 4.5, 'department': 9.0, 'grain': 9.0, 'malts': 9.0, 'oz': 9.0, 'finish': 1.5, 'alot': 9.0, 'see': 9.0, 'though': 9.0, 'may': 4.5, 'knew': 9.0, 'upon': 9.0, 'drives': 9.0, 'ball': 9.0, 'falls': 9.0, 'driven': 9.0, 'm': 4.5, 'fruit': 3.0, 'significant': 9.0, 'realised': 9.0, 'nothing': 4.5, 'overt': 9.0, 'citrussy': 9.0, 'early': 9.0, 'winey': 9.0, 'short': 9.0, 'tested': 9.0, 'clear': 9.0, 'curve': 9.0, 'mar': 9.0, 'perhaps': 9.0, 'hugely': 9.0, 'time': 9.0, 'serious': 9.0, '2008': 9.0, 'pretty': 3.0, 'typical': 9.0}), ('shdougan', {'summer': 2.0, 'citrusy': 2.0, 'sweetness': 2.0, 'earth': 2.0, 'yet': 2.0, 'perfect': 2.0, 'cherry': 2.0, 'tickle': 2.0, 'grapefruit': 2.0, 'easy': 2.0, 'familiar': 2.0, 'dark': 2.0, 'cedar': 2.0, 'gem': 2.0, 'like': 2.0, 'caramels': 2.0, 'name': 2.0, 'eve': 2.0, 'large': 2.0, 'caramel': 2.0, 'nose': 2.0, 'brewing': 2.0, 'nice': 2.0, 'sensation': 2.0, 'carbonation': 2.0, 'lead': 2.0, 'slick': 2.0, 'hazy': 1.0, 'goes': 2.0, 'red': 2.0, 'body': 2.0, 'full': 2.0, 'pours': 2.0, 'burn': 2.0, 'let': 2.0, 'plum': 2.0, 'aromas': 2.0, 'days': 2.0, 'forgotten': 2.0, 'slightly': 2.0, 'first': 2.0, 'amber': 2.0, 'copper': 2.0, 'already': 2.0, 'followed': 2.0, 'sweet': 1.0, 'teasing': 2.0, 'one': 2.0, 'wasn': 2.0, 'smells': 2.0, 'pouring': 2.0, 'long': 2.0, 'tropical': 2.0, 'beer': 1.0, 'wood': 2.0, 'way': 2.0, 'white': 2.0, 'bitter': 2.0, 'oily': 2.0, 'head': 1.0, 'medium': 1.0, 'north': 2.0, 'brings': 2.0, 'back': 2.0, 'foamy': 1.0, 'mouthfeel': 1.0, 'bitterness': 2.0, 'whiskey': 2.0, 'light': 2.0, 'balance': 2.0, 'beautiful': 2.0, 'tan': 2.0, 'sip': 2.0, 'winter': 2.0, 'fitting': 2.0, 'definitely': 1.0, 'take': 2.0, 'malty': 2.0, 'beach': 2.0, 'tart': 2.0, 'finish': 2.0, 'backbone': 2.0, 'upon': 2.0, 'warming': 2.0, 'refreshing': 2.0, 'bodied': 2.0, 'mango': 2.0, 'brew': 2.0, 'berries': 2.0})]\n"
     ]
    }
   ],
   "source": [
    "def countEachToken(listOfTokens):\n",
    "    ##Count the number of times each token appears in the list\n",
    "    tokenSet = list(set(listOfTokens))\n",
    "    tokenDict={}\n",
    "    for token in tokenSet:\n",
    "        tokenDict[token]=0\n",
    "    for token in listOfTokens:\n",
    "        tokenDict[token]=tokenDict[token]+1\n",
    "    return tokenDict\n",
    "\n",
    "def divideIntByDict(inputDict,inputInt):\n",
    "    for entry in inputDict:\n",
    "        inputDict[entry]=float(inputInt)/float(inputDict[entry])\n",
    "    return inputDict\n",
    "\n",
    "\n",
    "def IDFByKey(keyCorpus):\n",
    "    uniqueTokens = keyCorpus.map(lambda (x,y):(x,list(set(y))))\n",
    "    tokensByKey = uniqueTokens.reduceByKey(lambda a,b:a+b)\n",
    "    tokensCountByKey = tokensByKey.map(lambda (x,y):(x,countEachToken(y)))\n",
    "    countDocsByKey=keyCorpus.map(lambda (x,y):(x,1)).reduceByKey(lambda a,b:a+b)\n",
    "    countDocsAndTokensByKey = tokensCountByKey.join(countDocsByKey)\n",
    "    IDF=countDocsAndTokensByKey.map(lambda (x,y):(x,divideIntByDict(y[0],y[1])))\n",
    "    return IDF\n",
    "\n",
    "#RDD of (beer_id,text)\n",
    "reviewTokens = beerTrainToToken.map(lambda (x,y):(x,y[1]))\n",
    "reviewIDF=IDFByKey(reviewTokens)\n",
    "print reviewIDF.takeSample(False,2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Implement a TF-IDF function**\n",
    "#### We want to weight the individual features (words) by the user's given scores.  This should increase the weightings of words used only in positive reviews and greatly increase rare words in positive reviews.  We then create an RDD of (key, dictionary) where the dictionary is a ranked collection of each user's individual preferences.  We have a customized set of features which indicate what a user likes.\n",
    "\n",
    "#### We then sum across all users and reviews to get a weighted feature set which pushes important words to the top and bottom of the list and unimportant words to the middle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 98393 unique features in the reviews\n",
      "The beer features which people hate the most are: \n",
      "[('corn', -6941.209993744306), ('watery', -5850.66264894118), ('water', -4683.900004495215), ('lager', -4389.999520993852), ('bad', -4275.710757612451), ('metallic', -4223.9412930499275), ('bland', -3937.619330094755), ('cardboard', -3801.816296439873), ('nothing', -3673.6976828052298), ('boring', -3215.0573825990336), ('artificial', -2980.1133995228292), ('stale', -2966.6472415862), ('infected', -2921.4956123918155), ('weak', -2842.48224693424), ('grainy', -2826.1889529502555), ('pale', -2825.5800669934138), ('much', -2786.526829001184), ('weird', -2732.136911924141), ('awful', -2689.753985258856), ('unpleasant', -2645.9264146945657)]\n",
      "The beer features which people love the most are: \n",
      "[('awesome', 2026.6487907496098), ('whiskey', 2029.6271022811795), ('great', 2047.5732642319715), ('grapefruit', 2078.4490199791044), ('complex', 2080.840894256015), ('full', 2088.7537960739724), ('balanced', 2211.276953904183), ('oak', 2405.5265184493824), ('smooth', 2407.398388231067), ('tropical', 2424.4399555253844), ('excellent', 2497.3027447054933), ('delicious', 2507.174881177065), ('coconut', 2586.5079574976553), ('rich', 2600.9804130228645), ('nice', 2604.2841425931874), ('black', 2625.5543116623157), ('vanilla', 3383.98450822304), ('coffee', 3473.4888677035397), ('chocolate', 3600.1390347490897), ('bourbon', 3892.1269748535938)]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b0aa1f631685>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"The beer features which people love the most are: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0msorted_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m \u001b[0mfeaturesFileName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbaseDir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeaturesFileName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msortedfeatures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "def multiplyDict(inputDict,multiplier):\n",
    "    #multiplies every entry in a dictionary by a number.\n",
    "    for item in inputDict:\n",
    "        inputDict[item]=inputDict[item]*multiplier\n",
    "    return inputDict\n",
    "\n",
    "def stf(tokens, score):\n",
    "    ### Compute S-TF\n",
    "    tfsDict = tf(tokens)\n",
    "    stfsDict = multiplyDict(tfsDict,score)\n",
    "    return stfsDict\n",
    "\n",
    "def multiplyTwoDicts(firstDict,secondDict):\n",
    "    multDict = {token:firstDict[token]*secondDict[token] for token in firstDict}\n",
    "    return multDict\n",
    "\n",
    "def addTwoDicts(firstDict,secondDict):\n",
    "    for token in firstDict:\n",
    "        if token in secondDict:\n",
    "            firstDict[token]=firstDict[token]+secondDict[token]\n",
    "    for token in secondDict:\n",
    "        if token in firstDict:\n",
    "            pass\n",
    "        else:\n",
    "            firstDict[token]=secondDict[token]            \n",
    "    return firstDict\n",
    "\n",
    "##13 SCORE\n",
    "##14 AROMA (/10)\n",
    "##15 APPEARANCE(/5)\n",
    "##16 TASTE(/10)\n",
    "##17 PALATE(/5)\n",
    "##18 OVERALL(/20)\n",
    "\n",
    "def stfidfByKey(inputRDD,idfRDD,reviewTrue,whichRating):\n",
    "    ##Takes RDD of form (key,(list,list,wholebeer)) and calculates the s-tf of \n",
    "    ##reviewTrue==True ===> review\n",
    "    ##reviewTrue==False ===> commercial Description\n",
    "    ##whichRating ==-1 => don't weight by any column, just use 1 as a factor\n",
    "    ##takes the sum of s-tf and applies the idf to it.\n",
    "    \n",
    "    if (whichRating < 13 or whichRating >18) and whichRating!=-1:\n",
    "        raise ValueError('whichRating must be between 13 and 18 or equal to 0, please refer to documentation about fields')\n",
    "                         \n",
    "    if reviewTrue==True:\n",
    "        #print \"Got past true\"\n",
    "        #print inputRDD.map(lambda (x,(a,b,c)):(x,(b,c[whichRating]))).takeSample(False,3,1)\n",
    "        if whichRating!=-1:\n",
    "            stfRDD = inputRDD.map(lambda (x,(a,b,c)):(x,(stf(b,float(c[whichRating]))))).reduceByKey(addTwoDicts)\n",
    "        else:\n",
    "            stfRDD = inputRDD.map(lambda (x,(a,b,c)):(x,(stf(b,1)))).reduceByKey(addTwoDicts)\n",
    "        #print stfRDD.takeSample(True,3,1)\n",
    "    else:\n",
    "        if whichRating!=-1:\n",
    "            stfRDD = inputRDD.map(lambda (x,(a,b,c)):(x,(stf(a,float(c[whichRating]))))).reduceByKey(lambda a,b:a+b)\n",
    "        else:\n",
    "            stfRDD = inputRDD.map(lambda (x,(a,b,c)):(x,(stf(a,1)))).reduceByKey(lambda a,b:a+b)\n",
    "            \n",
    "    stfidfRDD=stfRDD.join(idfRDD).map(lambda (x,(y,z)):(x,multiplyTwoDicts(y,z)))\n",
    "    #print stfidfRDD.takeSample(True,3,1)\n",
    "    return stfidfRDD\n",
    "\n",
    "    \n",
    "#Generate dictionaries of ranked terms for each user individually.\n",
    "scoreTfIdf = stfidfByKey(beerTrainToToken,reviewIDF,True,13)\n",
    "##Find the best keywords across all users.\n",
    "sumAllFeatures =scoreTfIdf.map(lambda (x,y):y).reduce(addTwoDicts)\n",
    "#print sumAllFeatures.takeSample(False,3,1)\n",
    "\n",
    "import operator\n",
    "sorted_features = sorted(sumAllFeatures.items(), key=operator.itemgetter(1))\n",
    "print \"There are %d unique features in the reviews\" % len(sorted_features)\n",
    "print \"The beer features which people hate the most are: \"\n",
    "print sorted_features[:20]\n",
    "print \"The beer features which people love the most are: \"\n",
    "print sorted_features[-20:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fantastic!\n",
    "### By amalgamating people's individual love/hates we show here that our intuition lines up with the methodology taken so far.  A vanilla bourbon beer beats an infected watery beer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featuresFileName = os.path.join(baseDir, \"sortedFeatures.txt\")\n",
    "with open(featuresFileName, \"w\") as f:\n",
    "    for feature in sorted_features:\n",
    "        f.write(str(feature[0]))\n",
    "        f.write(\",\")\n",
    "        f.write(str(feature[1]))\n",
    "        f.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
