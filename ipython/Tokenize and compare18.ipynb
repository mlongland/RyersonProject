{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Spark Logo](http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png) + ![Python Logo](http://spark-mooc.github.io/web-assets/images/python-logo-master-v3-TM-flattened_small.png)\n",
    "# **Text Analysis of Beer Reviews**\n",
    "Here we use pySpark to analyze the text in the commercial description and review text to create similarity scores between beers.  The scores can then be used for clustering and beer style identification or to find beers similar to what a user enjoys, as a recommendation service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preliminaries**\n",
    "#### We read in the allBeer.txt file and create an RDD consisting of lines.\n",
    "#### We want to remove the header from the file, so the parseDataFileLine function identifies lines starting with 'beer_id' and applies a flag of 0, other lines with the correct number of fields are flagged 1, and incorrect lines are flagged -1.  The lines are split into arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parseDatafileLine(datafileLine):\n",
    "    ##Parse a line of the data file using the specified regular expression pattern\n",
    "    splitArray = datafileLine.split(\"\\t\")\n",
    "    for x in range(0,len(splitArray)):\n",
    "        splitArray[x]=splitArray[x].replace(\"\\\"\",'')\n",
    "    #print len(splitArray)\n",
    "    #print splitArray[0],splitArray[1],splitArray[2]\n",
    "    if splitArray[0]=='beer_id':\n",
    "        return (splitArray,0)\n",
    "    elif len(splitArray)<>23:\n",
    "        ##this is a failed parse\n",
    "        return (splitArray,-1)\n",
    "    else:\n",
    "        return (splitArray, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the file\n",
    "#### We read the file into three rdds by first parsing the file as above, the header rdd, failed rdd and the valid rdd.  Print the header names so we can remember what fields we're dealing with and in what order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 beer_id\n",
      "1 beer_name\n",
      "2 brewer_name\n",
      "3 beer_style\n",
      "4 distribution\n",
      "5 brewery_location\n",
      "6 commercial_desc\n",
      "7 RATINGS: \n",
      "8 MEAN (/5)\n",
      "9 WEIGHTED AVG\n",
      "10 EST. CALORIES\n",
      "11 ABV (%)\n",
      "12 IBU\n",
      "13 SCORE\n",
      "14 AROMA (/10)\n",
      "15 APPEARANCE(/5)\n",
      "16 TASTE(/10)\n",
      "17 PALATE(/5)\n",
      "18 OVERALL(/20)\n",
      "19 reviewer_name\n",
      "20 review_location\n",
      "21 review_date\n",
      "22 review_content\n",
      "AllBeer.txt - Read 240355 lines, successfully parsed 240354 lines, failed to parse 0 lines\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "baseDir = os.path.join('')\n",
    "allBeer_Path = 'AllBeer.txt'\n",
    "STOPWORDS_PATH = 'stopwords.txt'\n",
    "\n",
    "def parseData(filename):\n",
    "    #Parse a data file returns a RDD of parsed lines\n",
    "    \n",
    "    return (sc\n",
    "            .textFile(filename, 4, 0)\n",
    "            .map(parseDatafileLine)\n",
    "            .cache())\n",
    "\n",
    "def loadData(path):\n",
    "    ##Load a data file, returns a RDD of parsed valid lines\n",
    "    \n",
    "    filename = os.path.join(baseDir, path)\n",
    "    raw = parseData(filename).cache()\n",
    "    failed = (raw\n",
    "              .filter(lambda s: s[1] == -1)\n",
    "              .map(lambda s: s[0]))\n",
    "    for line in failed.take(10):\n",
    "        print '%s - Invalid datafile line: %s' % (path, line)\n",
    "    valid = (raw\n",
    "             .filter(lambda s: s[1] == 1)\n",
    "             .map(lambda s: s[0])\n",
    "             .cache())\n",
    "    header = (raw\n",
    "              .filter(lambda s: s[1]==0)\n",
    "             .map(lambda s:s[0])\n",
    "             )\n",
    "    for line in header.take(1):\n",
    "        for x in range(0,len(line)):\n",
    "            print x,line[x]\n",
    "            \n",
    "    rawLines = raw.count()\n",
    "    validLines = valid.count()\n",
    "    failedLines = failed.count()\n",
    "    print '%s - Read %d lines, successfully parsed %d lines, failed to parse %d lines' % (path, rawLines, validLines,failedLines)\n",
    "    return valid\n",
    "    \n",
    "allBeer = loadData(allBeer_Path)\n",
    "#allReviews = loadData(allReviews_Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's examine the first few entries of a sample of 5 lines to check if things look ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "allBeer: 40920, Wernecker Haustrunk Pils, Wernecker Bierbrauerei, Pilsener, distribution unknown\n",
      "\n",
      "23\n",
      "allBeer: 21911, Au Ma'tre Brasseur La Boucaneuse, AMB - Ma'tre Brasseur, Smoked, distribution unknown\n",
      "\n",
      "23\n",
      "allBeer: 4991, New Albanian / Struise Naughty Girl, New Albanian Brewing Company, India Pale Ale (IPA), Regional Distribution\n",
      "\n",
      "23\n",
      "allBeer: 38430, BrewDog IPA is Dead - Pioneer, BrewDog, India Pale Ale (IPA), Broad Distribution\n",
      "\n",
      "23\n",
      "allBeer: 41353, Cascade Cerise Nouveau, Cascade Brewing, Sour/Wild Ale, Local Distribution\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampleArray=allBeer.takeSample(False,5,1)\n",
    "for line in sampleArray:\n",
    "    print len(line)\n",
    "    print 'allBeer: %s, %s, %s, %s, %s\\n' % (line[0], line[1], line[2],line[3],line[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we'll split the data into a training set (80%) and test set (%20).  \n",
    "#### This is slightly complicated by the fact that we want to split each user into 80/20, not the set of reviews as a whole.  We will take advantage of stratified sampling in Spark, grouping the reviews by the user name, then sampling by key.  To get the unused data we employ subtractByKey using a compound key of the username and the beer_id, guaranting uniqueness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240334\n",
      "192184\n",
      "48170\n"
     ]
    }
   ],
   "source": [
    "##Using the allBeer array, take stratified sample, and remove blank reviews.\n",
    "beerByUser = allBeer.map(lambda x:(x[19],x)).filter(lambda (x,y):y[22]!='')\n",
    "sampleKeys = beerByUser.keys().collect()\n",
    "fractions={}\n",
    "for k in sampleKeys:\n",
    "    fractions[k]=0.8\n",
    "    \n",
    "beerTrain = beerByUser.sampleByKey(False,fractions).cache()\n",
    "beerTrainKeyed = beerTrain.map(lambda (x,y):(y[0]+y[19],y))\n",
    "beerTest = allBeer.map(lambda x:(x[0]+x[19],x)).subtractByKey(beerTrainKeyed).map(lambda (x,y):(y[19],y)).cache()\n",
    "print beerByUser.count()\n",
    "print beerTrain.count()\n",
    "print beerTest.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's examine the results with a couple of random users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user hallinghansen has 106 reviews, split into 81 Train and 25 Test\n",
      "The user Stoned99 has 193 reviews, split into 151 Train and 42 Test\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import random_integers\n",
    "##find a random user and print out the train and test set.\n",
    "randomUsers = random_integers(1,len(sampleKeys),2)\n",
    "sampleUserReviewCount = beerByUser.filter(lambda (x,y):x==sampleKeys[randomUsers[0]]).count()\n",
    "sampleUserTrainCount = beerTrain.filter(lambda (x,y):x==sampleKeys[randomUsers[0]]).count()\n",
    "sampleUserTestCount = beerTest.filter(lambda (x,y):x==sampleKeys[randomUsers[0]]).count()\n",
    "print \"The user %s has %d reviews, split into %d Train and %d Test\" % (sampleKeys[randomUsers[0]],sampleUserReviewCount,sampleUserTrainCount,sampleUserTestCount)\n",
    "\n",
    "sampleUserReviewCount = beerByUser.filter(lambda (x,y):x==sampleKeys[randomUsers[1]]).count()\n",
    "sampleUserTrainCount = beerTrain.filter(lambda (x,y):x==sampleKeys[randomUsers[1]]).count()\n",
    "sampleUserTestCount = beerTest.filter(lambda (x,y):x==sampleKeys[randomUsers[1]]).count()\n",
    "print \"The user %s has %d reviews, split into %d Train and %d Test\" % (sampleKeys[randomUsers[1]],sampleUserReviewCount,sampleUserTrainCount,sampleUserTestCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the reviews:\n",
    "#### Each user has a different way of scoring beers, some people judge more harshly than others.  In order to even out these scores, we get get statistics for each user and adjust their scores to fit a common distribution.  In this particular case we use a normal distribution for it's simplicity to execute.  Users with 1 or less reviews will have a standard deviation of 0, in which case we substitute 1 to ensure the division when obtaining z-scores we will not divide by zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Lubiere', ['22239', 'La Souche St-Jones', 'La Souche', 'Abbey Dubbel', 'distribution unknown', 'Quebec City, Canada', 'No commercial description', '3.000', '3.100', '2.860', '192.000', '6.400', '', 0.16922201133172543, '7.000', '3.000', '7.000', '3.000', 0.2051353107202715, 'Lubiere', 'Ottawa, Ontario, CANADA ', 'SEP 27, 2014', 'A reddish copper ale with a thin mocha head. In aroma, nice fruity malt with candy sugar, caramel, dark fruits, molasses, nice. In mouth, a nice sweet fruity malt with light caramel malt, candy sugar, plums, nice. On tap at brewery. ']), ('Beerhunter111', ['6977', 'De Molen Nood & Deugd (Necessity & Virtue)', 'Brouwerij de Molen', 'Schwarzbier', 'distribution unknown', 'Bodegraven, Netherlands', \"Sometimes things go wrong at a brewery. While brewing our Donder & Bliksem a mistake was made and we added a lot of malts that weren't suppose to go in this brew. This is how our Bohemian Lager turned into a Schwarzbier. As you see, we turn our Difficulties into a Virtue. 14.9 'P / EBC 113 / 35EBU Pale, Cara, Chocolate malts & Roasted barley. Sladek & Saaz hops.\", '149.000', '', '3.350', '186.000', '6.200', '35.000', 0.7856943893976757, '7.000', '4.000', '6.000', '4.000', 0.6333576477287209, 'Beerhunter111', 'Hasborn, GERMANY ', 'APR 18, 2014', \"Sehr dunkel r'tlichbraunes Bier mit sch'ner Schaumkrone. Geruch r'stmalzig, Kaffee. Geschmack r'stmalzig, leicht schokoladig, Kaffee. \"]), ('Thorpe429', ['2118', 'Upright Sole Composition: Jaune Quatre (Gin Barrel)', 'Upright Brewing', 'Saison', 'distribution unknown', 'Portland , Oregon USA', 'Single cask batch of Four aged 3 months in Ransom Old Tom Gin barrels with dry chrysanthemum flowers as well as homegrown yellow rose petals.', '20.000', '3.850', '3.590', '135.000', '4.500', '', -0.1295246710664382, '6.000', '4.000', '6.000', '4.000', -0.1936286797279858, 'Thorpe429', ', Illinois, USA ', 'DEC 2, 2012 ', 'Big thanks to boralyl for sending this out my way. Served in a tumbler. Clear golden-peach color. The nose is slightly gin-like with some floral and earthy nights. The flavor is a bit spicy with floral notes. Touch of pepper. Very light and crisp. ']), ('hopdog', ['18204', 'Randys Fun Hunters Tye The Knot Annual Anniversary Rye', 'Randys Restaurant & Fun Hunters Brewery', 'Specialty Grain', 'distribution unknown', 'Whitewater , Wisconsin USA', \"Brewed for the brewery's second anniversary.\", '4.000', '2.920', '2.870', '', '', '', -0.6936811752112848, '6.000', '2.000', '6.000', '3.000', -0.44403037901099973, 'hopdog', 'Lansdale, Pennsylvania, USA ', 'JUL 27, 2007', \"4th anniversary versoin that I'm going to rate here as I can't see adding a new entry. On tap at the Randy's Fun Hunters Brew Pub. Poured a medium golden color with a small sized white head. Aromas of rye, grainy, and some citrus. Tastes follow with the rye coming out a little stronger \"]), ('aumax1', ['20555', \"Belgh Brasse L'Amoszus Blonde\", 'Belgh Brasse (Groupe Geloso)', 'Belgian Ale', 'Local Distribution', 'Amos, Canada', 'No commercial description', '16.000', '3.510', '3.300', '210.000', '7.000', '', 0.5914881913188962, '7.000', '4.000', '8.000', '4.000', 0.6518573715061334, 'aumax1', \"Qu'bec, Quebec, CANADA \", 'MAY 16, 2014', \"bouteille de 750ml de blonde. petite amertume et sucre r'siduelle. arome de c'r'ale int'ressante \"])]\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "##13 SCORE\n",
    "##14 AROMA (/10)\n",
    "##15 APPEARANCE(/5)\n",
    "##16 TASTE(/10)\n",
    "##17 PALATE(/5)\n",
    "##18 OVERALL(/20)\n",
    "\n",
    "def replaceZeroes(inputValue,replacementValue):\n",
    "    if inputValue == 0:\n",
    "        inputValue = replacementValue\n",
    "    return inputValue\n",
    "\n",
    "def subtractFromColumn(inputList,columnToChange,subtractAmount):\n",
    "    inputList[columnToChange]=float(inputList[columnToChange])-subtractAmount\n",
    "    return inputList\n",
    "\n",
    "def divideColumn(inputList,columnToChange,divisor):\n",
    "    inputList[columnToChange]=float(inputList[columnToChange])/divisor\n",
    "    return inputList\n",
    "\n",
    "\n",
    "### rewrite this to be RDD of (key,everything else) and return (key, everything with normalized column x)\n",
    "### Then run a few times and cache, and move this up into the preliminaries (post split)\n",
    "def normalizeScoreByKey(inputRDD,scoreColumn):\n",
    "    ##Takes in RDD of (key,array) and \n",
    "    ##returns RDD of (key,array with scoreColumn normalized)\n",
    "    sumScores = inputRDD.map(lambda (x,y):(x,float(y[scoreColumn]))).reduceByKey(lambda a,b:a+b)\n",
    "    #print sumScores.map(lambda (x,y):y).reduce(lambda a,b:a+b)\n",
    "    countScoresPerKey = inputRDD.map(lambda (x,y):(x,1)).reduceByKey(lambda a,b:a+b)\n",
    "    #print countKeys.map(lambda (x,y):y).reduce(lambda a,b:a+b)\n",
    "    averageScores = sumScores.join(countScoresPerKey).map(lambda (x,y):(x,y[0]/y[1]))\n",
    "    #print averageScores.takeSample(False,5,3)\n",
    "    centredScores = inputRDD.join(averageScores).map(lambda (x,(y,z)):(x,subtractFromColumn(y,scoreColumn,z)))\n",
    "    #print centredScores.map(lambda (x,y):y[scoreColumn]).reduce(lambda a,b:a+b)\n",
    "    centredScoresSquaredSum = centredScores.map(lambda (x,y):(x,y[scoreColumn]*y[scoreColumn])).reduceByKey(lambda a,b:a+b)\n",
    "    centredScoresSquaredSumAndCount = centredScoresSquaredSum.join(countScoresPerKey)\n",
    "    stdDeviationByKey = centredScoresSquaredSumAndCount.map(lambda (x,y):(x,sqrt(y[0]/y[1])))\n",
    "    ##This is actually pointless since a centred score is 0 and 0/anything = 0\n",
    "    ##countLines = stdDeviationByUser.count()\n",
    "    ##avgStdDev = stdDeviationByUser.map(lambda (x,y):y).reduce(lambda a,b:a+b)/countLines\n",
    "    stdDeviationByKeyNoZero = stdDeviationByKey.map(lambda (x,y):(x,replaceZeroes(y,1)))\n",
    "    normalizedRDD = centredScores.join(stdDeviationByKeyNoZero).map(lambda (x,(y,z)):(x,divideColumn(y,scoreColumn,z)))\n",
    "    return normalizedRDD\n",
    "\n",
    "##Normalize the Scores\n",
    "normalizedScores = normalizeScoreByKey(beerTrain,13)\n",
    "##Normalize the rest of the ratings\n",
    "#beerTrainNormA = normalizeScoreByKey(normalizedScores,14)\n",
    "#beerTrainNormB = normalizeScoreByKey(beerTrainNormA,15)\n",
    "#beerTrainNormC = normalizeScoreByKey(beerTrainNormB,16)\n",
    "#beerTrainNormD = normalizeScoreByKey(beerTrainNormC,17)\n",
    "beerTrainNormalized = normalizeScoreByKey(normalizedScores,18).cache()\n",
    "\n",
    "print beerTrainNormalized.takeSample(False,5,4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Normalized Histograms**\n",
    "#### Plot histograms of the normalized ratings to check to see if normality approximately holds.\n",
    "#### Clearly score and overall are not normal, skewed right.  This would imply that when people hate a beer, they're more willing to review it harshly than they are willing to give a glowing review to a beer they love."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAADSCAYAAABeiClsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSVLHmcwlSeq4/w9nl0KZyWcKDAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x67b9210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAADSCAYAAABeiClsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niJpLMY+IiKi5FPOIiIia+/+Xq+OdaoQjhwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x66c9190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "##Get all the normalized scores into one list.\n",
    "scoreValues = beerTrainNormalized.map(lambda (x,y): y[13]).collect()\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "plt.title('Normalized Scores')\n",
    "plt.hist(scoreValues, 50, log=False)\n",
    "overallValues = beerTrainNormalized.map(lambda (x,y): y[18]).collect()\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "plt.title('Normalized Overall')\n",
    "plt.hist(overallValues, 50, log=False)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's think about the test data set as if it were a menu in a pub\n",
    "#### For each of the beers on the menu we need to generate a score, to see how compatable the beer is with the beer drinker's tastes.  From these scores we can then order the list, best to worst and the user can make their choice.  To do that we first need to know what the user likes, so let's take a look at their reviews and generate a list of traits, with each trait weighted by their own review scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Making Bags of Words\n",
    "#### We can take the commercial descriptions and the user input text reviews and convert them into bags of words, we can then treat each word as a feature.  \n",
    "#### We should take out stopwords before we do this, to avoid unfairly weighting reviews based on words which don't contribute much meaning, such as \"the\", \"a\", \"is\", \"which\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the stopwords: set([u'all', u'just', u'being', u'over', u'both', u'through', u'yourselves', u'its', u'before', u'with', u'had', u'should', u'to', u'only', u'under', u'ours', u'has', u'do', u'them', u'his', u'very', u'they', u'not', u'during', u'now', u'him', u'nor', u'did', u'these', u't', u'each', u'where', u'because', u'doing', u'theirs', u'some', u'are', u'our', u'ourselves', u'out', u'what', u'for', u'below', u'does', u'above', u'between', u'she', u'be', u'we', u'after', u'here', u'hers', u'by', u'on', u'about', u'of', u'against', u's', u'or', u'own', u'into', u'yourself', u'down', u'your', u'from', u'her', u'whom', u'there', u'been', u'few', u'too', u'themselves', u'was', u'until', u'more', u'himself', u'that', u'but', u'off', u'herself', u'than', u'those', u'he', u'me', u'myself', u'this', u'up', u'will', u'while', u'can', u'were', u'my', u'and', u'then', u'is', u'in', u'am', u'it', u'an', u'as', u'itself', u'at', u'have', u'further', u'their', u'if', u'again', u'no', u'when', u'same', u'any', u'how', u'other', u'which', u'you', u'who', u'most', u'such', u'why', u'a', u'don', u'i', u'having', u'so', u'the', u'yours', u'once'])\n",
      "['test', 'tf', 'function', 'return', 'non', 'stopword', 'frequencies', 'frequency', 'sourness']\n"
     ]
    }
   ],
   "source": [
    "stopfile = os.path.join(baseDir, STOPWORDS_PATH)\n",
    "stopwords = set(sc.textFile(stopfile).collect())\n",
    "testString = \"This is a test of the tf function.  It should return non stopword frequencies frequency sourness\"\n",
    "print 'These are the stopwords: %s' % stopwords\n",
    "split_regex = r'\\W+'\n",
    "\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "#Stmmr = PorterStemmer()\n",
    "\n",
    "def tokenize(string):\n",
    "    ##takes in a string and tokenizes it, removing stopwords, returns list\n",
    "    simple=filter(None,re.split(split_regex,string.lower()))\n",
    "    #simple = [Stmmr.stem(i) for i in simple]\n",
    "    return [i for i in simple if i not in stopwords]\n",
    "\n",
    "print tokenize(testString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tokenizing the Commercial Description and Review**\n",
    "#### Now tokenize the commercial descriptions and reviews. \n",
    "#### To see how much data we're dealing with let's count the total number of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4656566 tokens in the commercial descriptions\n",
      "There are 6667984 tokens in the reviews\n"
     ]
    }
   ],
   "source": [
    "##6 commercial description\n",
    "##22 user input review\n",
    "##make an RDD where the user_id is the key, and the value is 2 arrays of tokens \n",
    "##and the original line\n",
    "beerTrainToToken = beerTrainNormalized.map(lambda (x,y):(y[19],(tokenize(y[6]),tokenize(y[22]),y)))\n",
    "\n",
    "def countTokens(textRDD,reviewTRUE):\n",
    "    ## Count and return the number of tokens\n",
    "    if reviewTRUE==True:\n",
    "        return textRDD.map(lambda (x,y):len(y[1])).reduce(lambda a,b:a+b)\n",
    "    else:\n",
    "        return textRDD.map(lambda (x,y):len(y[0])).reduce(lambda a,b:a+b)\n",
    "\n",
    "print 'There are %s tokens in the commercial descriptions' % countTokens(beerTrainToToken,False)\n",
    "print 'There are %s tokens in the reviews' % countTokens(beerTrainToToken,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get an idea of how big a review is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review from user \"SlovakSniper\" has the most tokens (579)\n",
      "The review from user \"Shurf\" has the least tokens (0)\n"
     ]
    }
   ],
   "source": [
    "def findBiggestRecord(textRDD,reviewTRUE):\n",
    "    # Find and return the record with the largest number of tokens\n",
    "    if reviewTRUE==True:\n",
    "        return textRDD.takeOrdered(1,lambda (x,y):-len(y[1]))\n",
    "    else:\n",
    "        return textRDD.takeOrdered(1,lambda (x,y):-len(y[0]))\n",
    "\n",
    "def findSmallestRecord(textRDD,reviewTRUE):\n",
    "    # Find and return the record with the largest number of tokens\n",
    "    if reviewTRUE==True:\n",
    "        return textRDD.takeOrdered(1,lambda (x,y):len(y[1]))\n",
    "    else:\n",
    "        return textRDD.takeOrdered(1,lambda (x,y):len(y[0]))\n",
    "\n",
    "biggestReview = findBiggestRecord(beerTrainToToken,True)\n",
    "print 'The review from user \"%s\" has the most tokens (%s)' % (biggestReview[0][0],\n",
    "                                                                   len(biggestReview[0][1][1]))\n",
    "smallestReview = findSmallestRecord(beerTrainToToken,True)\n",
    "print 'The review from user \"%s\" has the least tokens (%s)' % (smallestReview[0][0], len(smallestReview[0][1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So clearly we've got some reviews that are empty, and we'll need some special handling for those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Weighted Bag-of-Words using TF-IDF**\n",
    "\n",
    "### Term Frequency (TF) \n",
    "#### This gives higher weight to tokens that appear many times in a individual document. It is computed as the frequency of a token in a document. If a word occurs often in a document, then it is more important to the meaning of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'function': 0.14285714285714285, 'non': 0.14285714285714285, 'return': 0.14285714285714285, 'frequencies': 0.14285714285714285, 'stopword': 0.14285714285714285, 'tf': 0.14285714285714285, 'test': 0.14285714285714285}\n"
     ]
    }
   ],
   "source": [
    "testString = \"This is a test of the tf function.  It should return non stopword frequencies\"\n",
    "def tf(tokens):\n",
    "    ###Compute TF from list of tokens, return dictionary of word:tf\n",
    "    count = len(tokens)\n",
    "    words={}\n",
    "    for token in tokens:\n",
    "        words[token]=float(len([t for t in tokens if t==token]))/count\n",
    "    return words\n",
    "\n",
    "print tf(tokenize(testString))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency\n",
    "#### This gives higher weight to tokens that are rare over the entire dataset. The rationale is two documents are more alike if they have in common words which are not common to rest data set.  IDF weight for a token in a set of documents is calculated as D/d(t) where D is the total number of documents and d(t) is the number of documents with term t.  \n",
    "#### We want to find out what is special to each individual, so the IDF needs to be across all beer reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('notws', 192184.0), ('madsen', 192184.0), ('zpienione', 192184.0), ('vermilion', 96092.0), ('wexford', 48046.0)]\n"
     ]
    }
   ],
   "source": [
    "def countEachToken(listOfTokens):\n",
    "    ##Count the number of times each token appears in the list\n",
    "    tokenSet = list(set(listOfTokens))\n",
    "    tokenDict={}\n",
    "    for token in tokenSet:\n",
    "        tokenDict[token]=0\n",
    "    for token in listOfTokens:\n",
    "        tokenDict[token]=tokenDict[token]+1\n",
    "    return tokenDict\n",
    "\n",
    "def divideIntByDict(inputDict,inputInt):\n",
    "    for entry in inputDict:\n",
    "        inputDict[entry]=float(inputInt)/float(inputDict[entry])\n",
    "    return inputDict\n",
    "\n",
    "##IDFByKey is depricated, it just didn't make sense to pick words which each user used rarely.\n",
    "def IDFByKey(keyCorpus):\n",
    "    uniqueTokens = keyCorpus.map(lambda (x,y):(x,list(set(y))))\n",
    "    tokensByKey = uniqueTokens.reduceByKey(lambda a,b:a+b)\n",
    "    tokensCountByKey = tokensByKey.map(lambda (x,y):(x,countEachToken(y)))\n",
    "    countDocsByKey=keyCorpus.map(lambda (x,y):(x,1)).reduceByKey(lambda a,b:a+b)\n",
    "    countDocsAndTokensByKey = tokensCountByKey.join(countDocsByKey)\n",
    "    IDF=countDocsAndTokensByKey.map(lambda (x,y):(x,divideIntByDict(y[0],y[1])))\n",
    "    return IDF\n",
    "\n",
    "def IDFWhole(keyCorpus):\n",
    "    N = keyCorpus.count()\n",
    "    uniqueTokens = keyCorpus.map(lambda (x,y):list(set(y))).flatMap(lambda y:y)\n",
    "    tokenCountPairTuple = uniqueTokens.map(lambda y:(y,1))\n",
    "    tokenSumPairTuple = tokenCountPairTuple.reduceByKey(lambda a,b:a+b)\n",
    "    IDFs = tokenSumPairTuple.map(lambda (k,V):(k,float(N)/V))\n",
    "    return IDFs\n",
    "\n",
    "#RDD of (beer_id,text)\n",
    "reviewTokens = beerTrainToToken.map(lambda (x,y):(x,y[1]))\n",
    "#reviewIDF=IDFByKey(reviewTokens)\n",
    "##make this a broadcast variable, so each node has it.\n",
    "reviewIDF=IDFWhole(reviewTokens)\n",
    "print reviewIDF.take(5)\n",
    "#print reviewIDF.takeSample(False,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAADKCAYAAABXJGLeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x54fdb10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idf_values = reviewIDF.map(lambda s: s[1]).collect()\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "plt.hist(idf_values, 50, log=True)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Implement a TF-IDF function**\n",
    "#### We want to weight the individual features (words) by the user's given scores.  This should increase the weightings of words used only in positive reviews and greatly increase rare words in positive reviews.  We then create an RDD of (key, dictionary) where the dictionary is a ranked collection of each user's individual preferences.  We have a customized set of features which indicate what a user likes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hetyu', {'golden': 0.0, 'liked': 0.0, 've': 0.0, 'taste': 0.0, 'honey': 0.0, 'balanced': 0.0, 'tan': 0.0, '1': 0.0, 'little': 0.0, 'pet': 0.0, 'hazy': 0.0, 'note': 0.0, '5l': 0.0, 'beer': 0.0, 'complex': 0.0, 'present': 0.0, 'way': 0.0, 'late': 0.0, 'orange': 0.0, 'aftertaste': 0.0, 'tell': 0.0, 'head': 0.0, 'truth': 0.0, 'yeast': 0.0, 'bit': 0.0, 'color': 0.0, 'malt': 0.0, 'bitterness': 0.0, 'bottle': 0.0, 'small': 0.0, 'sweetness': 0.0, 'could': 0.0, 'comes': 0.0}), ('Chronoflash', {'cider': 0.034482758620689655, 'irish': 0.034482758620689655, 'palate': 0.034482758620689655, 'apple': -0.006333567909922587, 'flat': -0.02040816326530612, 'tepid': 0.034482758620689655, 'yellow': -0.02040816326530612, 'aroma': -0.04081632653061224, 'd': -0.02040816326530612, 'mild': 0.034482758620689655, 'spicy': -0.02040816326530612, 'lively': -0.02040816326530612, 'subtle': -0.02040816326530612, 'carbonation': -0.04081632653061224, 'thick': 0.034482758620689655, 'flavor': -0.02040816326530612, 'best': -0.02040816326530612, 'grassy': 0.034482758620689655, 'dense': -0.02040816326530612, 'pilsner': -0.02040816326530612, 'start': -0.02040816326530612, 'hops': -0.006333567909922587, 'top': 0.034482758620689655, 'stout': 0.034482758620689655, 'tame': -0.02040816326530612, 'creamy': 0.034482758620689655, 'beer': 0.034482758620689655, 'lifts': -0.02040816326530612, 'hoppy': -0.02040816326530612, 'krystal': 0.034482758620689655, 'white': 0.014074595355383534, 'refreshing': -0.02040816326530612, 'fizz': -0.02040816326530612, 'body': 0.034482758620689655, 'fairly': -0.02040816326530612, 'head': -0.02040816326530612, 'good': 0.014074595355383534, 'partly': -0.02040816326530612, 'foam': -0.02040816326530612, 'welterweight': -0.02040816326530612, 'finish': -0.02040816326530612, 'falls': -0.02040816326530612, 'padding': -0.02040816326530612, 'foamy': 0.034482758620689655, 'fizzling': -0.02040816326530612, 'mouth': 0.034482758620689655, 'kolsch': -0.02040816326530612, 'cereal': -0.02040816326530612, 'despite': -0.02040816326530612, 'end': -0.02040816326530612, 'bit': -0.02040816326530612, 'funk': 0.034482758620689655, 'prominent': 0.014074595355383534, 'wood': 0.034482758620689655, 'mouthfeel': -0.02040816326530612, 'like': -0.02040816326530612, 'grains': -0.02040816326530612, 'light': -0.02040816326530612, 'malt': 0.014074595355383534, 'density': 0.034482758620689655, 'stronger': -0.02040816326530612, 'bitterness': 0.034482758620689655, 'cloudy': -0.02040816326530612, 'american': 0.034482758620689655, 'green': -0.02040816326530612, 'nose': 0.034482758620689655, 'bodied': 0.034482758620689655, 'clear': 0.034482758620689655}), ('CorinHoskins', {'count': 0.0, 'beautiful': 0.0, 'chilled': 0.0, 'cider': 0.0, 'drink': 0.0, 'jar': 0.0, 'overly': 0.0, 'ice': 0.0, 'mason': 0.0, 'overall': 0.0, 'thing': 0.0, 'recommended': 0.0, 'served': 0.0, 'highly': 0.0, 'excited': 0.0}), ('williamblake', {'count': 0.0, 'try': 0.0, 'great': 0.0, 'good': 0.0, 'tasting': 0.0, 'far': 0.0, 'retains': 0.0, 'character': 0.0, 'worth': 0.0, 'looking': 0.0, 'definitely': 0.0, 'strong': 0.0, 'crafted': 0.0, 'ordinary': 0.0, 'trying': 0.0, 'bitter': 0.0, 'well': 0.0, 'nice': 0.0}), ('fatguys', {'summer': 0.011076975512434225, 'subpar': -0.03461554847635696, 'ale': -0.012461597451488508, 'aroma': 0.029423216204903423, 'flavor': -0.03461554847635696, 'still': -0.03461554847635696, 'superior': 0.029423216204903423, 'vierling': 0.029423216204903423, 'blueberries': 0.029423216204903423, 'interesting': 0.011076975512434225, 'lake': 0.029423216204903423, 'orange': 0.011076975512434225, 'good': 0.02215395102486845, 'get': -0.03461554847635696, 'citrus': 0.02215395102486845, 'lighter': 0.040500191717337646, 'bit': 0.029423216204903423, 'pinkish': -0.03461554847635696, 'like': 0.011076975512434225, 'name': -0.03461554847635696, 'notes': -0.023538572963922734, 'cloudy': 0.011076975512434225, 'small': -0.03461554847635696, 'served': 0.029423216204903423, 'grab': 0.029423216204903423, 'flavored': -0.03461554847635696, 'view': 0.029423216204903423, 'enjoy': 0.029423216204903423, 'seat': 0.029423216204903423, 'novelty': 0.029423216204903423, 'pint': -0.005192332271453534, 'brewery': -0.023538572963922734, 'body': 0.011076975512434225, 'wheat': -0.06334645371173322, 'pours': 0.011076975512434225, 'raspberry': -0.10384664542907086, 'unique': 0.029423216204903423, 'changed': -0.03461554847635696, 'grain': 0.02215395102486845, 'sweetness': 0.029423216204903423, 'options': 0.011076975512434225, 'first': -0.03461554847635696, 'golden': 0.011076975512434225, 'followed': -0.03461554847635696, 'sweet': 0.011076975512434225, 'primary': 0.011076975512434225, 'one': 0.058846432409806845, 'effervescent': 0.029423216204903423, 'blonde': 0.011076975512434225, 'flavors': 0.011076975512434225, 'decent': -0.03461554847635696, 'obligatory': 0.011076975512434225, 'beer': -0.033923237506829795, 'bitter': 0.02215395102486845, 'blueberry': 0.029423216204903423, 'hue': -0.03461554847635696, 'head': -0.03461554847635696, 'medium': 0.011076975512434225, 'finishes': -0.03461554847635696, 'offering': 0.011076975512434225, 'acutal': 0.029423216204903423, 'glass': 0.029423216204903423, 'beers': 0.029423216204903423, 'mouthfeel': -0.03461554847635696, 'bitterness': -0.03461554847635696, 'crystal': -0.03461554847635696, 'sour': -0.03461554847635696, 'thin': -0.03461554847635696, 'aromas': 0.011076975512434225, 've': 0.029423216204903423, 'give': 0.029423216204903423, 'juice': 0.011076975512434225, 'perhaps': 0.029423216204903423, 'cross': -0.03461554847635696, 'highlighted': -0.03461554847635696, 'hefe': 0.02215395102486845, 'strange': -0.03461554847635696, 'tart': 0.011076975512434225, 'watery': -0.03461554847635696, 'tried': 0.029423216204903423, 'fruit': 0.029423216204903423, 'arrived': -0.03461554847635696, 'refreshing': 0.011076975512434225, 'light': -0.023538572963922734, 'average': 0.011076975512434225, 'think': -0.03461554847635696, 'pineapple': 0.011076975512434225, 'order': 0.029423216204903423})]\n",
      "There are 98365 unique features in the reviews\n",
      "The beer features which people hate the most are: \n",
      "[('light', -497.7145106648159), ('white', -302.6625952145645), ('clear', -256.0953449843089), ('thin', -228.5551781226377), ('yellow', -209.51740255534548), ('watery', -191.690062731527), ('pale', -189.84309102853223), ('golden', -184.47834401351759), ('bad', -171.88439189663274), ('aroma', -170.53455043307102), ('much', -169.65746645441575), ('taste', -167.5603166990009), ('head', -159.15169648221882), ('like', -145.92923992492595), ('bit', -139.31965995355998), ('little', -127.29107975222159), ('corn', -122.83998417027763), ('grain', -121.64198220931162), ('grainy', -113.80007087862643), ('bottle', -110.96096226261527)]\n",
      "The beer features which people love the most are: \n",
      "[('tan', 126.46121719180545), ('fruit', 132.37084342149282), ('citrus', 134.39526362732437), ('rich', 135.3326463949085), ('grapefruit', 140.43290749852653), ('bourbon', 143.40571650249373), ('pine', 144.04451359898042), ('brown', 149.26207518775422), ('great', 157.0136228068408), ('well', 161.02490448498642), ('smooth', 170.2741040208751), ('full', 170.69555083197872), ('roasted', 223.63421623422633), ('vanilla', 225.02639229382763), ('good', 229.47353114867806), ('coffee', 316.9765101195241), ('black', 320.86281698944225), ('dark', 367.30103738861635), ('chocolate', 486.7460136961401), ('nice', 578.0075622513143)]\n"
     ]
    }
   ],
   "source": [
    "def multiplyDict(inputDict,multiplier):\n",
    "    #multiplies every entry in a dictionary by a number.\n",
    "    for item in inputDict:\n",
    "        inputDict[item]=inputDict[item]*multiplier\n",
    "    return inputDict\n",
    "\n",
    "def stf(tokens, score):\n",
    "    ### Compute S-TF\n",
    "    tfsDict = tf(tokens)\n",
    "    stfsDict = multiplyDict(tfsDict,score)\n",
    "    return stfsDict\n",
    "\n",
    "def multiplyTwoDicts(firstDict,secondDict):\n",
    "    multDict = {token:firstDict[token]*secondDict[token] for token in firstDict}\n",
    "    return multDict\n",
    "\n",
    "def addTwoDicts(firstDict,secondDict):\n",
    "    for token in firstDict:\n",
    "        if token in secondDict:\n",
    "            firstDict[token]=firstDict[token]+secondDict[token]\n",
    "    for token in secondDict:\n",
    "        if token in firstDict:\n",
    "            pass\n",
    "        else:\n",
    "            firstDict[token]=secondDict[token]            \n",
    "    return firstDict\n",
    "\n",
    "def stfidf(tokens, idfs, score):\n",
    "    \"\"\" Compute TF-IDF\n",
    "    Args:\n",
    "        tokens (list of str): input list of tokens from tokenize\n",
    "        idfs (dictionary): record to IDF value\n",
    "    Returns:\n",
    "        dictionary: a dictionary of records to TF-IDF values\n",
    "    \"\"\"\n",
    "    tfs = stf(tokens)\n",
    "    tfIdfDict = {token:tfs[token]*idfs[token] for token in tfs}\n",
    "    return tfIdfDict\n",
    "\n",
    "##13 SCORE\n",
    "##14 AROMA (/10)\n",
    "##15 APPEARANCE(/5)\n",
    "##16 TASTE(/10)\n",
    "##17 PALATE(/5)\n",
    "##18 OVERALL(/20)\n",
    "\n",
    "def stfidfByKey(inputRDD,idfRDD,reviewTrue,whichRating):\n",
    "    ##Takes RDD of form (key,(list,list,wholebeer)) and calculates the s-tf of \n",
    "    ##reviewTrue==True ===> review\n",
    "    ##reviewTrue==False ===> commercial Description\n",
    "    ##whichRating ==-1 => don't weight by any column, just use 1 as a factor\n",
    "    ##takes the sum of s-tf and applies the idf to it.\n",
    "    \n",
    "    if (whichRating < 13 or whichRating > 18) and whichRating!=-1:\n",
    "        raise ValueError('whichRating must be between 13 and 18 or equal to 0, please refer to documentation about fields')\n",
    "                         \n",
    "    if reviewTrue==True:\n",
    "        if whichRating!=-1:\n",
    "            stfRDD = inputRDD.map(lambda (x,(a,b,c)):(x,stfidf(b,idfRDD,float(c[whichRating])))).reduceByKey(addTwoDicts)\n",
    "        else:\n",
    "            stfRDD = inputRDD.map(lambda (x,(a,b,c)):(x,stfidf(b,idfRDD,1))).reduceByKey(addTwoDicts)\n",
    "        #print stfRDD.takeSample(True,3,1)\n",
    "    else:\n",
    "        if whichRating!=-1:\n",
    "            stfRDD = inputRDD.map(lambda (x,(a,b,c)):(x,stfidf(a,idfRDD,float(c[whichRating])))).reduceByKey(lambda a,b:a+b)\n",
    "        else:\n",
    "            stfRDD = inputRDD.map(lambda (x,(a,b,c)):(x,stfidf(a,idfRDD,1))).reduceByKey(lambda a,b:a+b)\n",
    "            \n",
    "    stfidfRDD=stfRDD.map(lambda (x,(y,z)):(x,multiplyTwoDicts(y,z)))\n",
    "    #print stfidfRDD.takeSample(True,3,1)\n",
    "    return stfidfRDD\n",
    "\n",
    "def stfidfReduced(inputRDD,idfRDD,reviewTrue,whichRating):\n",
    "    ##Takes RDD of form (key,(list,list,wholebeer)) and calculates the s-tf of \n",
    "    ##reviewTrue==True ===> review\n",
    "    ##reviewTrue==False ===> commercial Description\n",
    "    ##whichRating ==-1 => don't weight by any column, just use 1 as a factor\n",
    "    ##takes the sum of s-tf and applies the idf to it.\n",
    "    \n",
    "    if (whichRating < 13 or whichRating >18) and whichRating!=-1:\n",
    "        raise ValueError('whichRating must be between 13 and 18 or equal to 0, please refer to documentation about fields')\n",
    "                         \n",
    "    if reviewTrue==True:\n",
    "        if whichRating!=-1:\n",
    "            stfidfRDD = inputRDD.map(lambda (x,(a,b,c)):(x,(stf(b,float(c[whichRating]))))).reduceByKey(addTwoDicts)\n",
    "        else:\n",
    "            stfidfRDD = inputRDD.map(lambda (x,(a,b,c)):(x,(stf(b,1)))).reduceByKey(addTwoDicts)\n",
    "        #print stfRDD.takeSample(True,3,1)\n",
    "    else:\n",
    "        if whichRating!=-1:\n",
    "            stfidfRDD = inputRDD.map(lambda (x,(a,b,c)):(x,(stf(a,float(c[whichRating]))))).reduceByKey(lambda a,b:a+b)\n",
    "        else:\n",
    "            stfidfRDD = inputRDD.map(lambda (x,(a,b,c)):(x,(stf(a,1)))).reduceByKey(lambda a,b:a+b)\n",
    "            \n",
    "    #stfidfRDD=stfRDD.map(lambda (x,y):(x,multiplyTwoDicts(y,z)))\n",
    "    #print stfidfRDD.takeSample(True,3,1)\n",
    "    return stfidfRDD\n",
    "\n",
    "    \n",
    "#Generate dictionaries of ranked terms for each user individually.\n",
    "scoreTfIdf = stfidfReduced(beerTrainToToken,reviewIDF,True,13)\n",
    "print scoreTfIdf.take(5)\n",
    "##Find the best keywords across all users.\n",
    "sumAllFeatures =scoreTfIdf.map(lambda (x,y):y).reduce(addTwoDicts)\n",
    "#print sumAllFeatures.takeSample(False,3,1)\n",
    "\n",
    "import operator\n",
    "sorted_features = sorted(sumAllFeatures.items(), key=operator.itemgetter(1))\n",
    "print \"There are %d unique features in the reviews\" % len(sorted_features)\n",
    "print \"The beer features which people hate the most are: \"\n",
    "print sorted_features[:20]\n",
    "print \"The beer features which people love the most are: \"\n",
    "print sorted_features[-20:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fantastic!\n",
    "### By amalgamating people's individual love/hates we show here that our intuition lines up with the methodology taken so far.  A vanilla bourbon beer beats an infected watery beer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3:  Using reviews to identify features of each beer\n",
    "#### Now that we have a user's preference, we need to figure out what each beer actually contains.  We can do this in a very similar way to the user features.  Collecting the reviews per beer, and applying tf-idf to the review text.  We will build a crowd sourced dictionary of terms that people commonly use to describe each beer.\n",
    "\n",
    "### Generate the IDFs per beer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bovine', 96092.0), ('anywasy', 192184.0)]\n"
     ]
    }
   ],
   "source": [
    "### recall beerTrainNormalized is a normalized beerTrain which is 80% of each user's reviews.\n",
    "### This takes the form of beerByUser = allBeer.map(lambda x:(x[19],x)) Where x is the entire\n",
    "### line and x[19] is the user_id.  Let's remap this to use the beer id as the key\n",
    "### similar to beerTrainToToken.\n",
    "\n",
    "trainByBeer = beerTrainNormalized.map(lambda (x,y):(y[0],(tokenize(y[6]),tokenize(y[22]),y)))\n",
    "\n",
    "### Remap to form similar to reviewTokens = beerTrainToToken.map(lambda (x,y):(x,y[1]))\n",
    "### which is the input for the idfByKey function.\n",
    "reviewTokensByBeer = trainByBeer.map(lambda (x,(a,b,c)):(x,b))\n",
    "\n",
    "### Now apply the idfByKey Function to get the idf dictionaries for each beer\n",
    "idfByBeer = IDFWhole(reviewTokensByBeer)\n",
    "print idfByBeer.takeSample(False,2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate tf-idf of features in each beer.\n",
    "#### Time to make a tf-idf for each beer, this time we won't weight it by the review, as we're trying to extract honest features from the beer, not each user's opinion about those features.  If someone indicates that the beer tastes like grapefruit but does not enjoy grapefruit, it doesn't mean that another user who does enjoy grapefruit will not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('35618', {'farmhouse': 0.034482758620689655, 'tallahassee': 0.02857142857142857, 'tap': 0.08739495798319327, 'lace': 0.034482758620689655, 'sourness': 0.058823529411764705, 'copper': 0.02857142857142857, 'taste': 0.034482758620689655, 'fluffy': 0.034482758620689655, 'head': 0.12187771660388293, 'yellow': 0.058823529411764705, 'aroma': 0.06305418719211822, 'medium': 0.02857142857142857, 'dried': 0.02857142857142857, 'carbonation': 0.034482758620689655, 'flavor': 0.02857142857142857, 'george': 0.058823529411764705, 'upstairs': 0.02857142857142857, 'bubbly': 0.034482758620689655, 'lemon': 0.034482758620689655, 'gold': 0.034482758620689655, 'lemony': 0.058823529411764705, 'barnyard': 0.02857142857142857, 'cloudy': 0.058823529411764705, 'hazy': 0.06305418719211822, 'note': 0.02857142857142857, 'much': 0.02857142857142857, 'lori': 0.058823529411764705, 'yeast': 0.058823529411764705, 'malty': 0.034482758620689655, 'funkiness': 0.02857142857142857, 'tangy': 0.05714285714285714, 'funky': 0.09330628803245436, 'white': 0.09330628803245436, 'moderate': 0.034482758620689655, 'nice': 0.09753694581280788, 'pepper': 0.058823529411764705, 'finish': 0.034482758620689655, 'apricot': 0.05714285714285714, 'slight': 0.06305418719211822, 'pours': 0.06305418719211822, 'sour': 0.0916256157635468, 'dissipates': 0.034482758620689655, 'sweetness': 0.034482758620689655, 'floral': 0.058823529411764705, 'spritz': 0.02857142857142857, 'fl': 0.02857142857142857, 'funk': 0.034482758620689655, 'hints': 0.058823529411764705, 'vinegar': 0.02857142857142857, 'mouthfeel': 0.02857142857142857, 'slightly': 0.02857142857142857, 'notes': 0.02857142857142857, 'candy': 0.02857142857142857, 'st': 0.02857142857142857, 'leave': 0.034482758620689655, 'good': 0.058823529411764705, 'tennessee': 0.02857142857142857, 'acidity': 0.06896551724137931, 'light': 0.034482758620689655, 'crowler': 0.034482758620689655, 'spices': 0.058823529411764705, 'leathery': 0.02857142857142857, 'proof': 0.08739495798319327, 'tarts': 0.02857142857142857}), ('22490', {'right': 0.03333333333333333, 'tap': 0.03333333333333333, 'taste': 0.03333333333333333, 'sweet': 0.03333333333333333, 'aroma': 0.03333333333333333, 'something': 0.03333333333333333, 'little': 0.1, '20': 0.03333333333333333, 'nuts': 0.06666666666666667, 'malted': 0.03333333333333333, '19th': 0.03333333333333333, 'drank': 0.03333333333333333, 'barley': 0.03333333333333333, 'aftertaste': 0.03333333333333333, '2010': 0.03333333333333333, 'brown': 0.03333333333333333, 'head': 0.03333333333333333, 'exceptional': 0.03333333333333333, 'brewpub': 0.03333333333333333, 'dark': 0.03333333333333333, 'light': 0.03333333333333333, 'malt': 0.03333333333333333, 'caramel': 0.03333333333333333, 'oz': 0.03333333333333333, 'expecting': 0.03333333333333333, 'january': 0.03333333333333333, 'fruity': 0.03333333333333333})]\n"
     ]
    }
   ],
   "source": [
    "beerTfIdf = stfidfReduced(trainByBeer,idfByBeer,True,-1)\n",
    "print beerTfIdf.takeSample(False,2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4:  Cosine distance\n",
    "\n",
    "#### We now have two sets of features, one per user and one per beer.  How do we compare the two?  One method is to imagine a multidimensional space where each word, or feature is a direction.  The weight on each feature is the distance along that axis.  In order to compare, we measure the angle between the two vectors.  A smaller angle will correspond to vectors pointing in nearly the same direction.\n",
    "\n",
    "#### The formula for cosine distance is:\n",
    "#### $$ similarity = \\cos \\theta = \\frac{a \\cdot b}{\\|a\\| \\|b\\|} = \\frac{\\sum a_i b_i}{\\sqrt{\\sum a_i^2} \\sqrt{\\sum b_i^2}} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the components of a cosine distance function\n",
    "#### We need to make a function `similarity` that returns cosine distance given two dictionaries.  The dot product of two dictionaries divided by the magnitudes of each dictionary.  Since perpendicular components have a dot product of zero we can ignore features which do not appear in both dictionaries.  To do this we can use the intersection of their keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.925820099773\n",
      "0.633503512093\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def similarity(a, b):\n",
    "    if len(a)==0 or len(b)==0:\n",
    "         sim=0\n",
    "    else:\n",
    "        aDotB= sum([a[token]*b[token] for token in list(set(a.keys())&set(b.keys()))])\n",
    "        magA = sqrt(sum(a[token]*a[token] for token in a.keys()))\n",
    "        magB = sqrt(sum(b[token]*b[token] for token in b.keys()))\n",
    "        if magA!=0 and magB!=0:\n",
    "            sim = aDotB/(magA*magB)\n",
    "        else:\n",
    "            sim=0\n",
    "    return sim\n",
    "\n",
    "testVec1 = {'foo': 2, 'bar': 2, 'baz': 2 }\n",
    "testVec2 = {'foo': 3, 'bar': 2, 'baz': 1 }\n",
    "print similarity(testVec1, testVec2)\n",
    "\n",
    "testVec3 = {'foo': 20, 'bar': 1, 'baz': 1 }\n",
    "print similarity(testVec1, testVec3)\n",
    "\n",
    "testVec4={}\n",
    "print similarity(testVec1, testVec4)\n",
    "\n",
    "testVec5 = {'foo': 0, 'bar': 0, 'baz': 0 }\n",
    "print similarity(testVec1, testVec5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing a menu's worth of beers to a user\n",
    "#### Recall that we split the original data set into 80% for training and 20% for test.  We consider the 20% of each user's reviews as a menu.  We can then compare each of the beers on the menu, using the features extracted from the training set to the features we extracted for each user.  By using the cosine similarity we can generate a score for each beer and rank them.  We can then compare this ranking to the user's given ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### beerTest is of the form (user,line)\n",
    "### we can remap this to (beer, line) and then join with beerTfIdf, then remap back\n",
    "### to (user,line,beerTfIdf).  Then join to scoreTfIdf and generate cosine distance between\n",
    "### beerTfIdf and scoreTFIdf.  We'll then have (user,line,score) which we can examine\n",
    "\n",
    "beerTestByBeer = beerTest.map(lambda (x,y):(y[0],y))\n",
    "beerTestByBeerWithTfIdf = beerTestByBeer.join(beerTfIdf)\n",
    "beerTestByUserWithTfIdf = beerTestByBeerWithTfIdf.map(lambda (x,y):(y[0][19],(y[0],y[1])))\n",
    "beerTestByUserWithDicts = beerTestByUserWithTfIdf.join(scoreTfIdf)\n",
    "beerTestByUserWithDictsFlat = beerTestByUserWithDicts.map(lambda (x,y):(x,y[0][0],y[0][1],y[1]))\n",
    "##special handling, there are users with no review words and beers with no words\n",
    "##so get rid of them.\n",
    "removeEmpties = beerTestByUserWithDictsFlat.filter(lambda (a,b,c,d):(d!=False and c!=False))\n",
    "cosSim = removeEmpties.map(lambda (a,b,c,d):(a,(b,similarity(c,d)))).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('6952', '3.8', 0.05748772811699128), ('2026', '3.7', 0.3067587770003357), ('5108', '3.7', 0.058640107222095124), ('5567', '3.4', 0.17713119528057483)]\n"
     ]
    }
   ],
   "source": [
    "oneUser = cosSim.filter(lambda (x,y):x=='wilnatp').map(lambda (x,y):(y[0][0],y[0][13],y[1])).collect()\n",
    "print sorted(oneUser,key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantifying the fit\n",
    "#### Now that we've scored the beers and looking at the single user above we can visually see that there's a correspondence between the generated rating and the user's rating, we need to quantify how closely the two lists match.\n",
    "\n",
    "#### There are a number of ways to do this like the Rank Biased Overlap, the Kendall Tau and counting the pair wise swaps to match the lists exactly.  I'm going to try using Spearman's rank correlation coefficient as it measures monotonicity, in a simple way with statistical tests available.  It's also available in the Scipy library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, -1.0, 0.3839285714285714, 0.1517857142857143, 0, -0.5, 0, 0.64652014652014655, 0.4910714285714286, 0]\n",
      "0.185012263517\n"
     ]
    }
   ],
   "source": [
    "### ToDo: lookup Kendall Tau, Rank Biased Overlap (RBO), maybe mean squared error??\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats.stats import rankdata\n",
    "from scipy.stats import pearsonr\n",
    "import math\n",
    "\n",
    "### Need to implement a function which will take the results from the cosSim RDD and spit out\n",
    "### average?? spearman.\n",
    "\n",
    "def catTuplesToLists(tupleOne,tupleTwo):\n",
    "    if len(tupleOne)==len(tupleTwo):\n",
    "        a=[]\n",
    "        for x in range(0,len(tupleOne)):\n",
    "            firstEle=tupleOne[x]\n",
    "            if type(firstEle) is not list: firstEle = [ tupleOne[x] ]\n",
    "            secondEle=tupleTwo[x]\n",
    "            if type(secondEle) is not list: secondEle = [ tupleTwo[x] ]\n",
    "            a.append(firstEle+secondEle)\n",
    "        return tuple(a)\n",
    "    else:\n",
    "        raise ValueError('Two tuples are not the same dimensions')\n",
    "\n",
    "def mattSpearman(listOne,listTwo):\n",
    "    if type(listOne) is list and type(listTwo) is list:\n",
    "        lO=len(listOne)\n",
    "        if lO==len(listTwo) and lO>1:\n",
    "            lOR = rankdata(listOne)\n",
    "            lTR = rankdata(listTwo)\n",
    "            print lOR\n",
    "            print lTR\n",
    "            dSquared=0\n",
    "            for x in range(0,lO):\n",
    "                dSquared+=(lOR[x]-lTR[x])**2\n",
    "            return 1-6*dSquared/lO/(lO**2-1)\n",
    "        else:\n",
    "            raise ValueError(\"Both Lists must be same length and greater than one.\")\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def reduceNaN(a,b):\n",
    "    if math.isnan(a):\n",
    "        a=0\n",
    "    if math.isnan(b):\n",
    "        b=0\n",
    "    return a+b\n",
    "\n",
    "def avgSpearman(inputRDD):\n",
    "    #So the problem here is trying to output two lists which have the scores in the same order.\n",
    "    #Write custom reduce function, catTuplesToLists\n",
    "    convertedToLists = inputRDD.map(lambda (x,y):(x,(y[0][0],y[0][13],y[1]))).reduceByKey(catTuplesToLists)\n",
    "    ##Need to filter out lists that are of length 1, spearman R has term /n(n^2-1)\n",
    "    #####test2=convertedToLists.take(1)\n",
    "    #####print test2\n",
    "    #####print mattSpearman(test2[0][1][1],test2[0][1][2])\n",
    "    filteredLists = convertedToLists.filter(lambda (x,y):type(y[1]) is list)\n",
    "    ##Now apply spearmanr\n",
    "    #oneUserdata = filteredLists.filter(lambda ())\n",
    "    spearmanByKey = convertedToLists.map(lambda (x,y):(x,mattSpearman(y[1],y[2]), len(y[1])))\n",
    "    spearmanOnly = spearmanByKey.map(lambda (x,y,z):y)\n",
    "    #print spearmanOnly.count()\n",
    "    print spearmanOnly.takeSample(False,10,1)\n",
    "    avgSpearmanRho=spearmanOnly.reduce(lambda a,b:a+b)/spearmanOnly.count()\n",
    "    return avgSpearmanRho\n",
    "\n",
    "#print avgSpearman(oneUser)\n",
    "print avgSpearman(cosSim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(3b) Implement a `cosineSimilarity` function**\n",
    "#### Implement a `cosineSimilarity(string1, string2, idfsDictionary)` function that takes two strings and a dictionary of IDF weights, and computes their cosine similarity in the context of some global IDF weights.\n",
    "#### The steps you should perform are:\n",
    "* #### Apply your `tfidf` function to the tokenized first and second strings, using the dictionary of IDF weights\n",
    "* #### Compute and return your `cossim` function applied to the results of the two `tfidf` functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "def cosineSimilarity(string1, string2, idfsDictionary):\n",
    "    \"\"\" Compute cosine similarity between two strings\n",
    "    Args:\n",
    "        string1 (str): first string\n",
    "        string2 (str): second string\n",
    "        idfsDictionary (dictionary): a dictionary of IDF values\n",
    "    Returns:\n",
    "        cossim: cosine similarity value\n",
    "    \"\"\"\n",
    "    w1 = tfidf(tokenize(string1),idfsDictionary)\n",
    "    w2 = tfidf(tokenize(string2),idfsDictionary)\n",
    "    return cossim(w1, w2)\n",
    "\n",
    "cossimAdobe = cosineSimilarity('Adobe Photoshop',\n",
    "                               'Adobe Illustrator',\n",
    "                               idfsSmallWeights)\n",
    "\n",
    "print cossimAdobe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Implement a cosineSimilarity function (3b)\n",
    "Test.assertTrue(abs(cossimAdobe - 0.0577243382163) < 0.0000001, 'incorrect cossimAdobe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(3c) Perform Entity Resolution**\n",
    "#### Now we can finally do some entity resolution!\n",
    "#### For *every* product record in the small Google dataset, use your `cosineSimilarity` function to compute its similarity to every record in the small Amazon dataset.  Then, build a dictionary mapping `(Google URL, Amazon ID)` tuples to similarity scores between 0 and 1.\n",
    "#### We'll do this computation two different ways, first we'll do it without a broadcast variable, and then we'll use a broadcast variable\n",
    "#### The steps you should perform are:\n",
    "* #### Create an RDD that is a combination of the small Google and small Amazon datasets that has as elements all pairs of elements (a, b) where a is in self and b is in other. The result will be an RDD of the form: `[ ((Google URL1, Google String1), (Amazon ID1, Amazon String1)), ((Google URL1, Google String1), (Amazon ID2, Amazon String2)), ((Google URL2, Google String2), (Amazon ID1, Amazon String1)), ... ]`\n",
    "* #### Define a worker function that given an element from the combination RDD computes the cosineSimlarity for the two records in the element\n",
    "* #### Apply the worker function to every element in the RDD\n",
    "#### Now, compute the similarity between Amazon record `b000o24l3q` and Google record `http://www.google.com/base/feeds/snippets/17242822440574356561`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "crossSmall = (googleSmall\n",
    "              .cartesian(amazonSmall)\n",
    "              .cache())\n",
    "print crossSmall.take(5)\n",
    "def computeSimilarity(record):\n",
    "    \"\"\" Compute similarity on a combination record\n",
    "    Args:\n",
    "        record: a pair, (google record, amazon record)\n",
    "    Returns:\n",
    "        pair: a pair, (google URL, amazon ID, cosine similarity value)\n",
    "    \"\"\"\n",
    "    googleRec = record[0]\n",
    "    amazonRec = record[1]\n",
    "    googleURL = googleRec[0]\n",
    "    amazonID = amazonRec[0]\n",
    "    googleValue = googleRec[1]\n",
    "    amazonValue = amazonRec[1]\n",
    "    cs = cosineSimilarity(googleValue,amazonValue, idfsSmallWeights)\n",
    "    return (googleURL, amazonID, cs)\n",
    "\n",
    "similarities = (crossSmall\n",
    "                .map(lambda x:computeSimilarity(x))\n",
    "                .cache())\n",
    "print similarities.take(5)\n",
    "def similar(amazonID, googleURL):\n",
    "    \"\"\" Return similarity value\n",
    "    Args:\n",
    "        amazonID: amazon ID\n",
    "        googleURL: google URL\n",
    "    Returns:\n",
    "        similar: cosine similarity value\n",
    "    \"\"\"\n",
    "    return (similarities\n",
    "            .filter(lambda record: (record[0] == googleURL and record[1] == amazonID))\n",
    "            .collect()[0][2])\n",
    "\n",
    "similarityAmazonGoogle = similar('b000o24l3q', 'http://www.google.com/base/feeds/snippets/17242822440574356561')\n",
    "print 'Requested similarity is %s.' % similarityAmazonGoogle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Perform Entity Resolution (3c)\n",
    "Test.assertTrue(abs(similarityAmazonGoogle - 0.000303171940451) < 0.0000001,\n",
    "                'incorrect similarityAmazonGoogle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(3d) Perform Entity Resolution with Broadcast Variables**\n",
    "#### The solution in (3c) works well for small datasets, but it requires Spark to (automatically) send the `idfsSmallWeights` variable to all the workers. If we didn't `cache()` similarities, then it might have to be recreated if we run `similar()` multiple times. This would cause Spark to send `idfsSmallWeights` every time.\n",
    "#### Instead, we can use a broadcast variable - we define the broadcast variable in the driver and then we can refer to it in each worker. Spark saves the broadcast variable at each worker, so it is only sent once.\n",
    "#### The steps you should perform are:\n",
    "* #### Define a `computeSimilarityBroadcast` function that given an element from the combination RDD computes the cosine simlarity for the two records in the element. This will be the same as the worker function `computeSimilarity` in (3c) except that it uses a broadcast variable.\n",
    "* #### Apply the worker function to every element in the RDD\n",
    "#### Again, compute the similarity between Amazon record `b000o24l3q` and Google record `http://www.google.com/base/feeds/snippets/17242822440574356561`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "def computeSimilarityBroadcast(record):\n",
    "    \"\"\" Compute similarity on a combination record, using Broadcast variable\n",
    "    Args:\n",
    "        record: a pair, (google record, amazon record)\n",
    "    Returns:\n",
    "        pair: a pair, (google URL, amazon ID, cosine similarity value)\n",
    "    \"\"\"\n",
    "    googleRec = record[0]\n",
    "    amazonRec = record[1]\n",
    "    googleURL = googleRec[0]\n",
    "    amazonID = amazonRec[0]\n",
    "    googleValue = googleRec[1]\n",
    "    amazonValue = amazonRec[1]\n",
    "    cs = cosineSimilarity(googleValue,amazonValue, idfsSmallBroadcast.value)\n",
    "    return (googleURL, amazonID, cs)\n",
    "\n",
    "idfsSmallBroadcast = sc.broadcast(idfsSmallWeights)\n",
    "similaritiesBroadcast = (crossSmall\n",
    "                         .map(lambda x:computeSimilarityBroadcast(x))\n",
    "                         .cache())\n",
    "\n",
    "def similarBroadcast(amazonID, googleURL):\n",
    "    \"\"\" Return similarity value, computed using Broadcast variable\n",
    "    Args:\n",
    "        amazonID: amazon ID\n",
    "        googleURL: google URL\n",
    "    Returns:\n",
    "        similar: cosine similarity value\n",
    "    \"\"\"\n",
    "    return (similaritiesBroadcast\n",
    "            .filter(lambda record: (record[0] == googleURL and record[1] == amazonID))\n",
    "            .collect()[0][2])\n",
    "\n",
    "similarityAmazonGoogleBroadcast = similarBroadcast('b000o24l3q', 'http://www.google.com/base/feeds/snippets/17242822440574356561')\n",
    "print 'Requested similarity is %s.' % similarityAmazonGoogleBroadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Perform Entity Resolution with Broadcast Variables (3d)\n",
    "from pyspark import Broadcast\n",
    "Test.assertTrue(isinstance(idfsSmallBroadcast, Broadcast), 'incorrect idfsSmallBroadcast')\n",
    "Test.assertEquals(len(idfsSmallBroadcast.value), 4772, 'incorrect idfsSmallBroadcast value')\n",
    "Test.assertTrue(abs(similarityAmazonGoogleBroadcast - 0.000303171940451) < 0.0000001,'incorrect similarityAmazonGoogle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(3e) Perform a Gold Standard evaluation**\n",
    "#### First, we'll load the \"gold standard\" data and use it to answer several questions. We read and parse the Gold Standard data, where the format of each line is \"Amazon Product ID\",\"Google URL\". The resulting RDD has elements of the form (\"AmazonID GoogleURL\", 'gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GOLDFILE_PATTERN = '^(.+),(.+)'\n",
    "\n",
    "# Parse each line of a data file useing the specified regular expression pattern\n",
    "def parse_goldfile_line(goldfile_line):\n",
    "    \"\"\" Parse a line from the 'golden standard' data file\n",
    "    Args:\n",
    "        goldfile_line: a line of data\n",
    "    Returns:\n",
    "        pair: ((key, 'gold', 1 if successful or else 0))\n",
    "    \"\"\"\n",
    "    match = re.search(GOLDFILE_PATTERN, goldfile_line)\n",
    "    if match is None:\n",
    "        print 'Invalid goldfile line: %s' % goldfile_line\n",
    "        return (goldfile_line, -1)\n",
    "    elif match.group(1) == '\"idAmazon\"':\n",
    "        print 'Header datafile line: %s' % goldfile_line\n",
    "        return (goldfile_line, 0)\n",
    "    else:\n",
    "        key = '%s %s' % (removeQuotes(match.group(1)), removeQuotes(match.group(2)))\n",
    "        return ((key, 'gold'), 1)\n",
    "\n",
    "goldfile = os.path.join(baseDir, inputPath, GOLD_STANDARD_PATH)\n",
    "gsRaw = (sc\n",
    "         .textFile(goldfile)\n",
    "         .map(parse_goldfile_line)\n",
    "         .cache())\n",
    "\n",
    "gsFailed = (gsRaw\n",
    "            .filter(lambda s: s[1] == -1)\n",
    "            .map(lambda s: s[0]))\n",
    "for line in gsFailed.take(10):\n",
    "    print 'Invalid goldfile line: %s' % line\n",
    "\n",
    "goldStandard = (gsRaw\n",
    "                .filter(lambda s: s[1] == 1)\n",
    "                .map(lambda s: s[0])\n",
    "                .cache())\n",
    "\n",
    "print 'Read %d lines, successfully parsed %d lines, failed to parse %d lines' % (gsRaw.count(),\n",
    "                                                                                 goldStandard.count(),\n",
    "                                                                                 gsFailed.count())\n",
    "assert (gsFailed.count() == 0)\n",
    "assert (gsRaw.count() == (goldStandard.count() + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the \"gold standard\" data we can answer the following questions:\n",
    "* #### How many true duplicate pairs are there in the small datasets?\n",
    "* #### What is the average similarity score for true duplicates?\n",
    "* #### What about for non-duplicates?\n",
    "#### The steps you should perform are:\n",
    "* #### Create a new `sims` RDD from the `similaritiesBroadcast` RDD, where each element consists of a pair of the form (\"AmazonID GoogleURL\", cosineSimilarityScore). An example entry from `sims` is: ('b000bi7uqs http://www.google.com/base/feeds/snippets/18403148885652932189', 0.40202896125621296)\n",
    "* #### Combine the `sims` RDD with the `goldStandard` RDD by creating a new `trueDupsRDD` RDD that has the just the cosine similarity scores for those \"AmazonID GoogleURL\" pairs that appear in both the `sims` RDD and `goldStandard` RDD. Hint: you can do this using the join() transformation.\n",
    "* #### Count the number of true duplicate pairs in the `trueDupsRDD` dataset\n",
    "* #### Compute the average similarity score for true duplicates in the `trueDupsRDD` datasets. Remember to use `float` for calculation\n",
    "* #### Create a new `nonDupsRDD` RDD that has the just the cosine similarity scores for those \"AmazonID GoogleURL\" pairs from the `similaritiesBroadcast` RDD that **do not** appear in both the *sims* RDD and gold standard RDD.\n",
    "* #### Compute the average similarity score for non-duplicates in the last datasets. Remember to use `float` for calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "sims = similaritiesBroadcast.map(lambda (x,y,z):(\" \".join((y,x)),z))\n",
    "\n",
    "trueDupsRDD = (sims\n",
    "               .join(goldStandard))\n",
    "trueDupsCount = trueDupsRDD.count()\n",
    "avgSimDups = float(trueDupsRDD.map(lambda (a,b):b[0]).reduce(lambda a,b:a+b))/trueDupsCount\n",
    "\n",
    "nonDupsRDD = (sims\n",
    "              .leftOuterJoin(goldStandard).filter(lambda (a,b):b[1] is None))\n",
    "avgSimNon = float(nonDupsRDD.map(lambda (a,b):b[0]).reduce(lambda a,b:a+b))/nonDupsRDD.count()\n",
    "\n",
    "print 'There are %s true duplicates.' % trueDupsCount\n",
    "print 'The average similarity of true duplicates is %s.' % avgSimDups\n",
    "print 'And for non duplicates, it is %s.' % avgSimNon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Perform a Gold Standard evaluation (3e)\n",
    "Test.assertEquals(trueDupsCount, 146, 'incorrect trueDupsCount')\n",
    "Test.assertTrue(abs(avgSimDups - 0.264332573435) < 0.0000001, 'incorrect avgSimDups')\n",
    "Test.assertTrue(abs(avgSimNon - 0.00123476304656) < 0.0000001, 'incorrect avgSimNon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 4: Scalable ER**\n",
    "#### In the previous parts, we built a text similarity function and used it for small scale entity resolution.  Our implementation is limited by its quadratic run time complexity, and is not practical for even modestly sized datasets.  In this part, we will implement a more scalable algorithm and use it to do entity resolution on the full dataset.\n",
    "### Inverted Indices\n",
    "#### To improve our ER algorithm from the earlier parts, we should begin by analyzing its running time. In particular, the algorithm above is quadratic in two ways. First, we did a lot of redundant computation of tokens and weights, since each record was reprocessed every time it was compared. Second, we made quadratically many token comparisons between records.\n",
    "#### The first source of quadratic overhead can be eliminated with precomputation and look-up tables, but the second source is a little more tricky. In the worst case, every token in every record in one dataset exists in every record in the other dataset, and therefore every token makes a non-zero contribution to the cosine similarity. In this case, token comparison is unavoidably quadratic.\n",
    "#### But in reality most records have nothing (or very little) in common. Moreover, it is typical for a record in one dataset to have at most one duplicate record in the other dataset (this is the case assuming each dataset has been de-duplicated against itself). In this case, the output is linear in the size of the input and we can hope to achieve linear running time.\n",
    "#### An [**inverted index**](https://en.wikipedia.org/wiki/Inverted_index) is a data structure that will allow us to avoid making quadratically many token comparisons.  It maps each token in the dataset to the list of documents that contain the token.  So, instead of comparing, record by record, each token to every other token to see if they match, we will use inverted indices to *look up* records that match on a particular token.\n",
    "> #### **Note on terminology**: In text search, a *forward* index maps documents in a dataset to the tokens they contain.  An *inverted* index supports the inverse mapping.\n",
    "> #### **Note**: For this section, use the complete Google and Amazon datasets, not the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(4a) Tokenize the full dataset**\n",
    "#### Tokenize each of the two full datasets for Google and Amazon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "amazonFullRecToToken = amazon.map(lambda (x,y):(x,tokenize(y)))\n",
    "googleFullRecToToken = google.map(lambda (x,y):(x,tokenize(y)))\n",
    "print 'Amazon full dataset is %s products, Google full dataset is %s products' % (amazonFullRecToToken.count(),\n",
    "                                                                                    googleFullRecToToken.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Tokenize the full dataset (4a)\n",
    "Test.assertEquals(amazonFullRecToToken.count(), 1363, 'incorrect amazonFullRecToToken.count()')\n",
    "Test.assertEquals(googleFullRecToToken.count(), 3226, 'incorrect googleFullRecToToken.count()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(4b) Compute IDFs and TF-IDFs for the full datasets**\n",
    "#### We will reuse your code from above to compute IDF weights for the complete combined datasets.\n",
    "#### The steps you should perform are:\n",
    "* #### Create a new `fullCorpusRDD` that contains the tokens from the full Amazon and Google datasets.\n",
    "* #### Apply your `idfs` function to the `fullCorpusRDD`\n",
    "* #### Create a broadcast variable containing a dictionary of the IDF weights for the full dataset.\n",
    "* #### For each of the Amazon and Google full datasets, create weight RDDs that map IDs/URLs to TF-IDF weighted token vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "fullCorpusRDD = amazonFullRecToToken.union(googleFullRecToToken)\n",
    "idfsFull = idfs(fullCorpusRDD)\n",
    "idfsFullCount = idfsFull.count()\n",
    "print 'There are %s unique tokens in the full datasets.' % idfsFullCount\n",
    "\n",
    "# Recompute IDFs for full dataset\n",
    "idfsFullWeights = idfs(fullCorpusRDD)\n",
    "idfsFullBroadcast = sc.broadcast(idfsFullWeights.collectAsMap())\n",
    "# Pre-compute TF-IDF weights.  Build mappings from record ID weight vector.\n",
    "amazonWeightsRDD = amazonFullRecToToken.map(lambda (x,y):(x,tfidf(y,idfsFullBroadcast.value)))\n",
    "googleWeightsRDD = googleFullRecToToken.map(lambda (x,y):(x,tfidf(y,idfsFullBroadcast.value)))\n",
    "print 'There are %s Amazon weights and %s Google weights.' % (amazonWeightsRDD.count(),\n",
    "                                                              googleWeightsRDD.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Compute IDFs and TF-IDFs for the full datasets (4b)\n",
    "Test.assertEquals(idfsFullCount, 17078, 'incorrect idfsFullCount')\n",
    "Test.assertEquals(amazonWeightsRDD.count(), 1363, 'incorrect amazonWeightsRDD.count()')\n",
    "Test.assertEquals(googleWeightsRDD.count(), 3226, 'incorrect googleWeightsRDD.count()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(4c) Compute Norms for the weights from the full datasets**\n",
    "#### We will reuse your code from above to compute norms of the IDF weights for the complete combined dataset.\n",
    "#### The steps you should perform are:\n",
    "* #### Create two collections, one for each of the full Amazon and Google datasets, where IDs/URLs map to the norm of the associated TF-IDF weighted token vectors.\n",
    "* #### Convert each collection into a broadcast variable, containing a dictionary of the norm of IDF weights for the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "amazonNorms = amazonWeightsRDD.map(lambda (x,y):(x,norm(y)))\n",
    "amazonNormsBroadcast = sc.broadcast(amazonNorms.collectAsMap())\n",
    "googleNorms = googleWeightsRDD.map(lambda (x,y):(x,norm(y)))\n",
    "googleNormsBroadcast = sc.broadcast(googleNorms.collectAsMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Compute Norms for the weights from the full datasets (4c)\n",
    "Test.assertTrue(isinstance(amazonNormsBroadcast, Broadcast), 'incorrect amazonNormsBroadcast')\n",
    "Test.assertEquals(len(amazonNormsBroadcast.value), 1363, 'incorrect amazonNormsBroadcast.value')\n",
    "Test.assertTrue(isinstance(googleNormsBroadcast, Broadcast), 'incorrect googleNormsBroadcast')\n",
    "Test.assertEquals(len(googleNormsBroadcast.value), 3226, 'incorrect googleNormsBroadcast.value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(4d) Create inverted indicies from the full datasets**\n",
    "#### Build inverted indices of both data sources.\n",
    "#### The steps you should perform are:\n",
    "* #### Create an invert function that given a pair of (ID/URL, TF-IDF weighted token vector), returns a list of pairs of (token, ID/URL). Recall that the TF-IDF weighted token vector is a Python dictionary with keys that are tokens and values that are weights.\n",
    "* #### Use your invert function to convert the full Amazon and Google TF-IDF weighted token vector datasets into two RDDs where each element is a pair of a token and an ID/URL that contain that token. These are inverted indicies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "def invert(record):\n",
    "    \"\"\" Invert (ID, tokens) to a list of (token, ID)\n",
    "    Args:\n",
    "        record: a pair, (ID, token vector)\n",
    "    Returns:\n",
    "        pairs: a list of pairs of token to ID\n",
    "    \"\"\"\n",
    "    pairs=[]\n",
    "    for k in record[1]:\n",
    "        pairs.append((k,record[0]))\n",
    "    return (pairs)\n",
    "\n",
    "amazonInvPairsRDD = (amazonWeightsRDD\n",
    "                    .flatMap(lambda x:invert(x))\n",
    "                    .cache())\n",
    "googleInvPairsRDD = (googleWeightsRDD\n",
    "                    .flatMap(lambda x:invert(x))\n",
    "                    .cache())\n",
    "\n",
    "print 'There are %s Amazon inverted pairs and %s Google inverted pairs.' % (amazonInvPairsRDD.count(),\n",
    "                                                                            googleInvPairsRDD.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Create inverted indicies from the full datasets (4d)\n",
    "invertedPair = invert((1, {'foo': 2}))\n",
    "Test.assertEquals(invertedPair[0][1], 1, 'incorrect invert result')\n",
    "Test.assertEquals(amazonInvPairsRDD.count(), 111387, 'incorrect amazonInvPairsRDD.count()')\n",
    "Test.assertEquals(googleInvPairsRDD.count(), 77678, 'incorrect googleInvPairsRDD.count()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(4e) Identify common tokens from the full dataset**\n",
    "#### We are now in position to efficiently perform ER on the full datasets. Implement the following algorithm to build an RDD that maps a pair of (ID, URL) to a list of tokens they share in common:\n",
    "* #### Using the two inverted indicies (RDDs where each element is a pair of a token and an ID or URL that contains that token), create a new RDD that contains only tokens that appear in both datasets. This will yield an RDD of pairs of (token, iterable(ID, URL)).\n",
    "* #### We need a mapping from (ID, URL) to token, so create a function that will swap the elements of the RDD you just created to create this new RDD consisting of ((ID, URL), token) pairs.\n",
    "* #### Finally, create an RDD consisting of pairs mapping (ID, URL) to all the tokens the pair shares in common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "def swap(record):\n",
    "    \"\"\" Swap (token, (ID, URL)) to ((ID, URL), token)\n",
    "    Args:\n",
    "        record: a pair, (token, (ID, URL))\n",
    "    Returns:\n",
    "        pair: ((ID, URL), token)\n",
    "    \"\"\"\n",
    "    token = record[0]\n",
    "    keys = record[1]\n",
    "    return (keys, token)\n",
    "\n",
    "commonTokens = (amazonInvPairsRDD\n",
    "                .join(googleInvPairsRDD).map(lambda x:swap(x)).groupByKey()\n",
    "                .cache())\n",
    "print 'Found %d common tokens' % commonTokens.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Identify common tokens from the full dataset (4e)\n",
    "Test.assertEquals(commonTokens.count(), 2441100, 'incorrect commonTokens.count()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(4f) Identify common tokens from the full dataset**\n",
    "#### Use the data structures from parts **(4a)** and **(4e)** to build a dictionary to map record pairs to cosine similarity scores.\n",
    "#### The steps you should perform are:\n",
    "* #### Create two broadcast dictionaries from the amazonWeights and googleWeights RDDs\n",
    "* #### Create a `fastCosinesSimilarity` function that takes in a record consisting of the pair ((Amazon ID, Google URL), tokens list) and computes the sum for each of the tokens in the token list of the products of the Amazon weight for the token times the Google weight for the token. The sum should then be divided by the norm for the Google URL and then divided by the norm for the Amazon ID. The function should return this value in a pair with the key being the (Amazon ID, Google URL). *Make sure you use broadcast variables you created for both the weights and norms*\n",
    "* #### Apply your `fastCosinesSimilarity` function to the common tokens from the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "amazonWeightsBroadcast = sc.broadcast(amazonWeightsRDD.collectAsMap())\n",
    "googleWeightsBroadcast = sc.broadcast(googleWeightsRDD.collectAsMap())\n",
    "\n",
    "def fastCosineSimilarity(record):\n",
    "    \"\"\" Compute Cosine Similarity using Broadcast variables\n",
    "    Args:\n",
    "        record: ((ID, URL), token)\n",
    "    Returns:\n",
    "        pair: ((ID, URL), cosine similarity value)\n",
    "    \"\"\"\n",
    "    amazonRec = record[0][0]\n",
    "    googleRec = record[0][1]\n",
    "    tokens = record[1]\n",
    "    s = sum((amazonWeightsBroadcast.value[amazonRec][token]*googleWeightsBroadcast.value[googleRec][token] for token in tokens))\n",
    "    value = s/amazonNormsBroadcast.value[amazonRec]/googleNormsBroadcast.value[googleRec]\n",
    "    key = (amazonRec, googleRec)\n",
    "    return (key, value)\n",
    "\n",
    "similaritiesFullRDD = (commonTokens\n",
    "                       .map(lambda x:fastCosineSimilarity(x))\n",
    "                       .cache())\n",
    "\n",
    "print similaritiesFullRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST Identify common tokens from the full dataset (4f)\n",
    "similarityTest = similaritiesFullRDD.filter(lambda ((aID, gURL), cs): aID == 'b00005lzly' and gURL == 'http://www.google.com/base/feeds/snippets/13823221823254120257').collect()\n",
    "Test.assertEquals(len(similarityTest), 1, 'incorrect len(similarityTest)')\n",
    "Test.assertTrue(abs(similarityTest[0][1] - 4.286548414e-06) < 0.000000000001, 'incorrect similarityTest fastCosineSimilarity')\n",
    "Test.assertEquals(similaritiesFullRDD.count(), 2441100, 'incorrect similaritiesFullRDD.count()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 5: Analysis**\n",
    "#### Now we have an authoritative list of record-pair similarities, but we need a way to use those similarities to decide if two records are duplicates or not. The simplest approach is to pick a **threshold**. Pairs whose similarity is above the threshold are declared duplicates, and pairs below the threshold are declared distinct.\n",
    "#### To decide where to set the threshold we need to understand what kind of errors result at different levels. If we set the threshold too low, we get more **false positives**, that is, record-pairs we say are duplicates that in reality are not. If we set the threshold too high, we get more **false negatives**, that is, record-pairs that really are duplicates but that we miss.\n",
    "#### ER algorithms are evaluated by the common metrics of information retrieval and search called **precision** and **recall**. Precision asks of all the record-pairs marked duplicates, what fraction are true duplicates? Recall asks of all the true duplicates in the data, what fraction did we successfully find? As with false positives and false negatives, there is a trade-off between precision and recall. A third metric, called **F-measure**, takes the harmonic mean of precision and recall to measure overall goodness in a single value:\n",
    "#### $$ Fmeasure = 2 \\frac{precision * recall}{precision + recall} $$\n",
    "> #### **Note**: In this part, we use the \"gold standard\" mapping from the included file to look up true duplicates, and the results of Part 4.\n",
    "> #### **Note**: In this part, you will not be writing any code. We've written all of the code for you. Run each cell and then answer the quiz questions on Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(5a) Counting True Positives, False Positives, and False Negatives**\n",
    "#### We need functions that count True Positives (true duplicates above the threshold), and False Positives and False Negatives:\n",
    "* #### We start with creating the `simsFullRDD` from our `similaritiesFullRDD` that consists of a pair of ((Amazon ID, Google URL), simlarity score)\n",
    "* #### From this RDD, we create an RDD consisting of only the similarity scores\n",
    "* #### To look up the similarity scores for true duplicates, we perform a left outer join using the `goldStandard` RDD and `simsFullRDD` and extract the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an RDD of ((Amazon ID, Google URL), similarity score)\n",
    "simsFullRDD = similaritiesFullRDD.map(lambda x: (\"%s %s\" % (x[0][0], x[0][1]), x[1]))\n",
    "assert (simsFullRDD.count() == 2441100)\n",
    "\n",
    "# Create an RDD of just the similarity scores\n",
    "simsFullValuesRDD = (simsFullRDD\n",
    "                     .map(lambda x: x[1])\n",
    "                     .cache())\n",
    "assert (simsFullValuesRDD.count() == 2441100)\n",
    "\n",
    "# Look up all similarity scores for true duplicates\n",
    "\n",
    "# This helper function will return the similarity score for records that are in the gold standard and the simsFullRDD (True positives), and will return 0 for records that are in the gold standard but not in simsFullRDD (False Negatives).\n",
    "def gs_value(record):\n",
    "    if (record[1][1] is None):\n",
    "        return 0\n",
    "    else:\n",
    "        return record[1][1]\n",
    "\n",
    "# Join the gold standard and simsFullRDD, and then extract the similarities scores using the helper function\n",
    "trueDupSimsRDD = (goldStandard\n",
    "                  .leftOuterJoin(simsFullRDD)\n",
    "                  .map(gs_value)\n",
    "                  .cache())\n",
    "print 'There are %s true duplicates.' % trueDupSimsRDD.count()\n",
    "assert(trueDupSimsRDD.count() == 1300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next step is to pick a threshold between 0 and 1 for the count of True Positives (true duplicates above the threshold). However, we would like to explore many different thresholds. To do this, we divide the space of thresholds into 100 bins, and take the following actions:\n",
    "* #### We use Spark Accumulators to implement our counting function. We define a custom accumulator type, `VectorAccumulatorParam`, along with functions to initialize the accumulator's vector to zero, and to add two vectors. Note that we have to use the += operator because you can only add to an accumulator.\n",
    "* #### We create a helper function to create a list with one entry (bit) set to a value and all others set to 0.\n",
    "* #### We create 101 bins for the 100 threshold values between 0 and 1.\n",
    "* #### Now, for each similarity score, we can compute the false positives. We do this by adding each similarity score to the appropriate bin of the vector. Then we remove true positives from the vector by using the gold standard data.\n",
    "* #### We define functions for computing false positive and negative and true positives, for a given threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.accumulators import AccumulatorParam\n",
    "class VectorAccumulatorParam(AccumulatorParam):\n",
    "    # Initialize the VectorAccumulator to 0\n",
    "    def zero(self, value):\n",
    "        return [0] * len(value)\n",
    "\n",
    "    # Add two VectorAccumulator variables\n",
    "    def addInPlace(self, val1, val2):\n",
    "        for i in xrange(len(val1)):\n",
    "            val1[i] += val2[i]\n",
    "        return val1\n",
    "\n",
    "# Return a list with entry x set to value and all other entries set to 0\n",
    "def set_bit(x, value, length):\n",
    "    bits = []\n",
    "    for y in xrange(length):\n",
    "        if (x == y):\n",
    "          bits.append(value)\n",
    "        else:\n",
    "          bits.append(0)\n",
    "    return bits\n",
    "\n",
    "# Pre-bin counts of false positives for different threshold ranges\n",
    "BINS = 101\n",
    "nthresholds = 100\n",
    "def bin(similarity):\n",
    "    return int(similarity * nthresholds)\n",
    "\n",
    "# fpCounts[i] = number of entries (possible false positives) where bin(similarity) == i\n",
    "zeros = [0] * BINS\n",
    "fpCounts = sc.accumulator(zeros, VectorAccumulatorParam())\n",
    "\n",
    "def add_element(score):\n",
    "    global fpCounts\n",
    "    b = bin(score)\n",
    "    fpCounts += set_bit(b, 1, BINS)\n",
    "\n",
    "simsFullValuesRDD.foreach(add_element)\n",
    "\n",
    "# Remove true positives from FP counts\n",
    "def sub_element(score):\n",
    "    global fpCounts\n",
    "    b = bin(score)\n",
    "    fpCounts += set_bit(b, -1, BINS)\n",
    "\n",
    "trueDupSimsRDD.foreach(sub_element)\n",
    "\n",
    "def falsepos(threshold):\n",
    "    fpList = fpCounts.value\n",
    "    return sum([fpList[b] for b in range(0, BINS) if float(b) / nthresholds >= threshold])\n",
    "\n",
    "def falseneg(threshold):\n",
    "    return trueDupSimsRDD.filter(lambda x: x < threshold).count()\n",
    "\n",
    "def truepos(threshold):\n",
    "    return trueDupSimsRDD.count() - falsenegDict[threshold]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(5b) Precision, Recall, and F-measures**\n",
    "#### We define functions so that we can compute the [Precision][precision-recall], [Recall][precision-recall], and [F-measure][f-measure] as a function of threshold value:\n",
    "* #### Precision = true-positives / (true-positives + false-positives)\n",
    "* #### Recall = true-positives / (true-positives + false-negatives)\n",
    "* #### F-measure = 2 x Recall x Precision / (Recall + Precision)\n",
    "[precision-recall]: https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "[f-measure]: https://en.wikipedia.org/wiki/Precision_and_recall#F-measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Precision = true-positives / (true-positives + false-positives)\n",
    "# Recall = true-positives / (true-positives + false-negatives)\n",
    "# F-measure = 2 x Recall x Precision / (Recall + Precision)\n",
    "\n",
    "def precision(threshold):\n",
    "    tp = trueposDict[threshold]\n",
    "    return float(tp) / (tp + falseposDict[threshold])\n",
    "\n",
    "def recall(threshold):\n",
    "    tp = trueposDict[threshold]\n",
    "    return float(tp) / (tp + falsenegDict[threshold])\n",
    "\n",
    "def fmeasure(threshold):\n",
    "    r = recall(threshold)\n",
    "    p = precision(threshold)\n",
    "    return 2 * r * p / (r + p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(5c) Line Plots**\n",
    "#### We can make line plots of precision, recall, and F-measure as a function of threshold value, for thresholds between 0.0 and 1.0.  You can change `nthresholds` (above in part **(5a)**) to change the threshold values to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "thresholds = [float(n) / nthresholds for n in range(0, nthresholds)]\n",
    "falseposDict = dict([(t, falsepos(t)) for t in thresholds])\n",
    "falsenegDict = dict([(t, falseneg(t)) for t in thresholds])\n",
    "trueposDict = dict([(t, truepos(t)) for t in thresholds])\n",
    "\n",
    "precisions = [precision(t) for t in thresholds]\n",
    "recalls = [recall(t) for t in thresholds]\n",
    "fmeasures = [fmeasure(t) for t in thresholds]\n",
    "\n",
    "print precisions[0], fmeasures[0]\n",
    "assert (abs(precisions[0] - 0.000532546802671) < 0.0000001)\n",
    "assert (abs(fmeasures[0] - 0.00106452669505) < 0.0000001)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(thresholds, precisions)\n",
    "plt.plot(thresholds, recalls)\n",
    "plt.plot(thresholds, fmeasures)\n",
    "plt.legend(['Precision', 'Recall', 'F-measure'])\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "#### State-of-the-art tools can get an F-measure of about 60% on this dataset. In this lab exercise, our best F-measure is closer to 40%. Look at some examples of errors (both False Positives and False Negatives) and think about what went wrong.\n",
    "### There are several ways we might improve our simple classifier, including:\n",
    "#### * Using additional attributes\n",
    "#### * Performing better featurization of our textual data (e.g., stemming, n-grams, etc.)\n",
    "#### * Using different similarity functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
