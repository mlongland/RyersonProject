{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Spark Logo](http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png) + ![Python Logo](http://spark-mooc.github.io/web-assets/images/python-logo-master-v3-TM-flattened_small.png)\n",
    "# Getting Top 5 Breweries and Styles for each User."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.defaultParallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preliminaries**\n",
    "#### We read in the allBeer.txt file and create an RDD consisting of lines.\n",
    "#### We want to remove the header from the file, so the parseDataFileLine function identifies lines starting with 'beer_id' and applies a flag of 0, other lines with the correct number of fields are flagged 1, and incorrect lines are flagged -1.  The lines are split into arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parseDatafileLine(datafileLine):\n",
    "    ##Parse a line of the data file using the specified regular expression pattern\n",
    "    splitArray = datafileLine.split(\"\\t\")\n",
    "    for x in range(0,len(splitArray)):\n",
    "        splitArray[x]=splitArray[x].replace(\"\\\"\",'')\n",
    "    #print len(splitArray)\n",
    "    #print splitArray[0],\n",
    "    splitArray[1],splitArray[2]\n",
    "    if splitArray[0]=='beer_id':\n",
    "        return (splitArray,0)\n",
    "    elif len(splitArray)<>23:\n",
    "        ##this is a failed parse\n",
    "        return (splitArray,-1)\n",
    "    else:\n",
    "        return (splitArray, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the file\n",
    "#### We read the file into three rdds by first parsing the file as above, the header rdd, failed rdd and the valid rdd.  Print the header names so we can remember what fields we're dealing with and in what order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 beer_id\n",
      "1 beer_name\n",
      "2 brewer_name\n",
      "3 beer_style\n",
      "4 distribution\n",
      "5 brewery_location\n",
      "6 commercial_desc\n",
      "7 RATINGS: \n",
      "8 MEAN (/5)\n",
      "9 WEIGHTED AVG\n",
      "10 EST. CALORIES\n",
      "11 ABV (%)\n",
      "12 IBU\n",
      "13 SCORE\n",
      "14 AROMA (/10)\n",
      "15 APPEARANCE(/5)\n",
      "16 TASTE(/10)\n",
      "17 PALATE(/5)\n",
      "18 OVERALL(/20)\n",
      "19 reviewer_name\n",
      "20 review_location\n",
      "21 review_date\n",
      "22 review_content\n",
      "AllBeer.txt - Read 620388 lines, successfully parsed 620387 lines, failed to parse 0 lines\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "baseDir = os.path.join('')\n",
    "allBeer_Path = 'AllBeer.txt'\n",
    "STOPWORDS_PATH = 'stopwords.txt'\n",
    "\n",
    "def parseData(filename):\n",
    "    #Parse a data file returns a RDD of parsed lines\n",
    "    \n",
    "    return (sc\n",
    "            .textFile(filename, 4, True)\n",
    "            .map(parseDatafileLine)\n",
    "            .cache())\n",
    "\n",
    "def loadData(path):\n",
    "    ##Load a data file, returns a RDD of parsed valid lines\n",
    "    \n",
    "    filename = os.path.join(baseDir, path)\n",
    "    raw = parseData(filename).cache()\n",
    "    failed = (raw\n",
    "              .filter(lambda s: s[1] == -1)\n",
    "              .map(lambda s: s[0]))\n",
    "    for line in failed.take(10):\n",
    "        print '%s - Invalid datafile line: %s' % (path, line)\n",
    "    valid = (raw\n",
    "             .filter(lambda s: s[1] == 1)\n",
    "             .map(lambda s: s[0])\n",
    "             .cache())\n",
    "    header = (raw\n",
    "              .filter(lambda s: s[1]==0)\n",
    "             .map(lambda s:s[0])\n",
    "             )\n",
    "    headerDict={}\n",
    "    for line in header.take(1):\n",
    "        for x in range(0,len(line)):\n",
    "            headerDict[x]=line[x]\n",
    "            print x,line[x]\n",
    "            \n",
    "    rawLines = raw.count()\n",
    "    validLines = valid.count()\n",
    "    failedLines = failed.count()\n",
    "    print '%s - Read %d lines, successfully parsed %d lines, failed to parse %d lines' % (path, rawLines, validLines,failedLines)\n",
    "    return valid, headerDict\n",
    "    \n",
    "allBeer,headers = loadData(allBeer_Path)\n",
    "#allReviews = loadData(allReviews_Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's examine the first few entries of a sample of 5 lines to check if things look ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "allBeer: 62903, duclaw-bourbon-barrel-serum, DuClaw Brewing Company, Imperial IPA, distribution unknown\n",
      "\n",
      "23\n",
      "allBeer: 106807, atlas-red-squirrel, Atlas (Sinclair Breweries), Bitter, distribution unknown\n",
      "\n",
      "23\n",
      "allBeer: 108406, fiddler-ale, De Haagsche Bierbrouwerij, Bitter, distribution unknown\n",
      "\n",
      "23\n",
      "allBeer: 67592, hoganas-apa, H�gan�s Bryggeri, American Pale Ale, distribution unknown\n",
      "\n",
      "23\n",
      "allBeer: 78504, beach-city-kickout-double-ipa, Beach City Brewery, Imperial IPA, Local Distribution\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampleArray=allBeer.takeSample(False,5,1)\n",
    "for line in sampleArray:\n",
    "    print len(line)\n",
    "    print 'allBeer: %s, %s, %s, %s, %s\\n' % (line[0], line[1], line[2],line[3],line[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data\n",
    "#### Since we're heavily dependent on the number of reviews each individual gives we will need to remove users who have an unacceptably low number, since we're dividing into training and test sets and the goal is to predict an order we should have at least 3 beers per user in the test set.  If we split 80/20 this means at least 12 beer reviews overall.  We are also going to immediately purge any blank reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4005 users in the dataset.\n",
      "There are 99891 beers in the dataset.\n",
      "There are 591212 reviews in the dataset.\n"
     ]
    }
   ],
   "source": [
    "##Purge blank reviews and make (k,V) pairs\n",
    "nonEmpty = allBeer.map(lambda x:(x[19],x)).filter(lambda (x,y):y[22]!='')\n",
    "##Convert strings to floats for 13 through 18\n",
    "def convertStrings(inputList,indexList):\n",
    "    outList = []\n",
    "    for x in range(0,len(inputList)):\n",
    "        if x in indexList:\n",
    "            outList.append(float(inputList[x]))\n",
    "        else:\n",
    "            outList.append(inputList[x])\n",
    "    return outList\n",
    "convIndicies=[13,14,15,16,17,18]\n",
    "convertedToFloats = nonEmpty.map(lambda (x,y):(x,convertStrings(y,convIndicies)))\n",
    "\n",
    "##Remove users with less than 12 reviews.\n",
    "def removeUsers(inputRDD,minReviews):\n",
    "    countPerUser = inputRDD.map(lambda (x,y):(x,1)).reduceByKey(lambda a,b:a+b)\n",
    "    outRDD = inputRDD.join(countPerUser).filter(lambda (x,(y,z)):z>=minReviews)\n",
    "    return outRDD.map(lambda (x,(y,z)):(x,y))\n",
    "\n",
    "##Remove users not in Ontario.\n",
    "def filterByLocation(inputRDD,location):\n",
    "    outRDD = inputRDD.filter(lambda (x,y):y[20].lower().find(location)!=-1)\n",
    "    return outRDD\n",
    "\n",
    "beerByUser = removeUsers(convertedToFloats,12).cache()\n",
    "print \"There are %d users in the dataset.\" % beerByUser.map(lambda (x,y):x).distinct().count()\n",
    "print \"There are %d beers in the dataset.\" % beerByUser.map(lambda (x,y):y[0]).distinct().count()\n",
    "print \"There are %d reviews in the dataset.\" % beerByUser.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'nazzty', u'Manetsdad', u'Bewitched', u'Nejhleader', u'CObiased']\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import MySQLdb\n",
    "def getUsersFromDatabase():\n",
    "    userDictionary={}\n",
    "    mydb = MySQLdb.connect(host='localhost',\n",
    "        user='pythonconnector',\n",
    "        passwd='python1029',\n",
    "        db='BeerRatings')\n",
    "    cursor = mydb.cursor()\n",
    "    cursor.execute(\"SELECT * FROM users\")\n",
    "    queryResults = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    mydb.close()\n",
    "    for result in queryResults:\n",
    "        userDictionary[result[1].decode('utf-8')]=result[0]\n",
    "    return userDictionary\n",
    "\n",
    "userDict = getUsersFromDatabase()\n",
    "print userDict.keys()[0:5]\n",
    "\n",
    "beerById = beerByUser.map(lambda (x,y):(userDict[x],y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's find each user's favourite styles, so we can then output it to a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "def topNfromDict(inputDict,N):\n",
    "    return dict(sorted(inputDict.iteritems(), key=operator.itemgetter(1), reverse=True)[:N])\n",
    "    \n",
    "def reduceIntoDict(a,b):\n",
    "    #a and b should be dict of {style:(rating,1)}\n",
    "    combinedDict={}\n",
    "    for element in a:\n",
    "        if element in b:\n",
    "            combinedDict[element]=(a[element][0]+b[element][0],a[element][1]+b[element][1])\n",
    "        else:\n",
    "            combinedDict[element]=a[element]\n",
    "    for element in b:\n",
    "        if element in combinedDict:\n",
    "            pass\n",
    "        else:\n",
    "            combinedDict[element]=b[element]\n",
    "    return combinedDict\n",
    "\n",
    "def convertDict(inputDict,styleDict):\n",
    "    outDict={}\n",
    "    sumBeers=0\n",
    "    for style in inputDict:\n",
    "        sumBeers +=inputDict[style][1]\n",
    "    \n",
    "    for style in styleDict:\n",
    "        if style in inputDict:\n",
    "            outDict[style]=(inputDict[style][0]/inputDict[style][1],float(inputDict[style][1])/sumBeers)\n",
    "        else:\n",
    "            outDict[style]=(0,0)\n",
    "    return outDict\n",
    "\n",
    "import pickle\n",
    "beerStyles = beerByUser.map(lambda (x,y):y[3]).distinct().collect()\n",
    "styleDict={}\n",
    "for style in beerStyles:\n",
    "    styleDict[style]=(0,0)  ##count and sum\n",
    "    \n",
    "countPerSum = beerById.map(lambda (x,y):(y[3],1)).reduceByKey(lambda a,b:a+b)\n",
    "avgPerStyle = beerById.map(lambda (x,y):(y[3],y[13])).reduceByKey(lambda a,b:a+b).join(countPerSum).map(lambda (x,(y,z)):(x,y/z)).collect()\n",
    "avgPerStyleDict = {a[0]:a[1] for a in avgPerStyle}\n",
    "#print avgPerStyleDict\n",
    "with open('/usr/ALSServer/dbfiles/styleAverages.txt', 'wb') as f:\n",
    "    pickle.dump(avgPerStyleDict,f)\n",
    "styleSums = beerById.map(lambda(x,y):(x,{y[3]:(y[13],1)})).reduceByKey(reduceIntoDict)\n",
    "styleAvgAndFreq=styleSums.map(lambda (x,y):(x,convertDict(y,styleDict)))\n",
    "styleAvgAndFreqTop5=styleAvgAndFreq.map(lambda (x,y):(x,topNfromDict(y,5))).collect()\n",
    "with open('/usr/ALSServer/dbfiles/top5StylesPerUser.txt', 'wb') as f:\n",
    "    pickle.dump(styleAvgAndFreqTop5,f)\n",
    "#print styleAvgAndFreqTop5.takeSample(False,1,5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output top 5 breweries per person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1540L, {u'Brouwerij Emelisse': (4.0, 0.003424657534246575), u'City of Cambridge (Wolf)': (4.0, 0.003424657534246575), u'Brooklyn Brewery': (4.5, 0.003424657534246575), u'Duelund Bryglade': (4.3, 0.003424657534246575), u'Great Divide Brewing Company': (4.1, 0.003424657534246575)}), (3080L, {u'Spearhead Brewing Company': (4.1, 0.045454545454545456), u'Smithworks Brewing Company': (4.0, 0.045454545454545456), u'Railway City Brewing Company': (3.1, 0.045454545454545456), u'Martens': (3.1, 0.045454545454545456), u'Box Steam': (3.1, 0.045454545454545456)}), (1036L, {u'Southern Star Brewing Company': (4.6, 0.007518796992481203), u'Deschutes Brewery': (4.3, 0.007518796992481203), u'Stone Brewing Company': (4.0, 0.03007518796992481), u'Victory Brewing Company': (4.1, 0.015037593984962405), u'Founders Brewing Company': (4.0, 0.015037593984962405)}), (2576L, {u'Browar Cornelius': (3.7, 0.02702702702702703), u'Browar Artezan': (3.8, 0.02702702702702703), u'Browar Kingpin': (4.1, 0.02702702702702703), u'Mikkeller': (4.7, 0.02702702702702703), u'Browary Lodzkie': (4.1, 0.02702702702702703)}), (532L, {u'Three Floyds Brewing Company': (4.0, 0.034482758620689655), u'Kuhnhenn Brewing': (4.15, 0.022988505747126436), u'AleSmith Brewing Company': (4.3, 0.011494252873563218), u'Bi\\ufffdropholie': (4.2, 0.011494252873563218), u'Westbrook Brewing': (4.05, 0.022988505747126436)})]\n"
     ]
    }
   ],
   "source": [
    "breweries = beerByUser.map(lambda (x,y):y[2]).distinct().collect()\n",
    "brewerDict={}\n",
    "for brewer in breweries:\n",
    "    brewerDict[brewer]=(0,0)  ##count and sum\n",
    "    \n",
    "countPerSum = beerById.map(lambda (x,y):(y[2],1)).reduceByKey(lambda a,b:a+b)\n",
    "avgPerBrewer = beerById.map(lambda (x,y):(y[2],y[13])).reduceByKey(lambda a,b:a+b).join(countPerSum).map(lambda (x,(y,z)):(x,y/z)).collect()\n",
    "avgPerBrewerDict = {a[0]:a[1] for a in avgPerBrewer}\n",
    "#print avgPerBrewerDict\n",
    "with open('/usr/ALSServer/dbfiles/breweryAverages.txt', 'wb') as f:\n",
    "    pickle.dump(avgPerBrewerDict,f)\n",
    "brewerSums = beerById.map(lambda(x,y):(x,{y[2]:(y[13],1)})).reduceByKey(reduceIntoDict)\n",
    "brewerAvgAndFreq=brewerSums.map(lambda (x,y):(x,convertDict(y,brewerDict)))\n",
    "brewerAvgAndFreqTop5=brewerAvgAndFreq.map(lambda (x,y):(x,topNfromDict(y,5))).collect()\n",
    "with open('/usr/ALSServer/dbfiles/top5BrewersPerUser.txt', 'wb') as f:\n",
    "    pickle.dump(brewerAvgAndFreqTop5,f)\n",
    "print brewerAvgAndFreqTop5[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
