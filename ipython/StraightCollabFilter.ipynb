{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Spark Logo](http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png) + ![Python Logo](http://spark-mooc.github.io/web-assets/images/python-logo-master-v3-TM-flattened_small.png)\n",
    "# **Text Analysis of Beer Reviews**\n",
    "Here we use pySpark to analyze the text in the commercial description and review text to create similarity scores between beers.  The scores can then be used for clustering and beer style identification or to find beers similar to what a user enjoys, as a recommendation service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preliminaries**\n",
    "#### We read in the allBeer.txt file and create an RDD consisting of lines.\n",
    "#### We want to remove the header from the file, so the parseDataFileLine function identifies lines starting with 'beer_id' and applies a flag of 0, other lines with the correct number of fields are flagged 1, and incorrect lines are flagged -1.  The lines are split into arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parseDatafileLine(datafileLine):\n",
    "    ##Parse a line of the data file using the specified regular expression pattern\n",
    "    splitArray = datafileLine.split(\"\\t\")\n",
    "    for x in range(0,len(splitArray)):\n",
    "        splitArray[x]=splitArray[x].replace(\"\\\"\",'')\n",
    "    #print len(splitArray)\n",
    "    #print splitArray[0],splitArray[1],splitArray[2]\n",
    "    if splitArray[0]=='beer_id':\n",
    "        return (splitArray,0)\n",
    "    elif len(splitArray)<>23:\n",
    "        ##this is a failed parse\n",
    "        return (splitArray,-1)\n",
    "    else:\n",
    "        return (splitArray, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the file\n",
    "#### We read the file into three rdds by first parsing the file as above, the header rdd, failed rdd and the valid rdd.  Print the header names so we can remember what fields we're dealing with and in what order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 beer_id\n",
      "1 beer_name\n",
      "2 brewer_name\n",
      "3 beer_style\n",
      "4 distribution\n",
      "5 brewery_location\n",
      "6 commercial_desc\n",
      "7 RATINGS: \n",
      "8 MEAN (/5)\n",
      "9 WEIGHTED AVG\n",
      "10 EST. CALORIES\n",
      "11 ABV (%)\n",
      "12 IBU\n",
      "13 SCORE\n",
      "14 AROMA (/10)\n",
      "15 APPEARANCE(/5)\n",
      "16 TASTE(/10)\n",
      "17 PALATE(/5)\n",
      "18 OVERALL(/20)\n",
      "19 reviewer_name\n",
      "20 review_location\n",
      "21 review_date\n",
      "22 review_content\n",
      "AllBeer.txt - Read 240355 lines, successfully parsed 240354 lines, failed to parse 0 lines\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "baseDir = os.path.join('')\n",
    "allBeer_Path = 'AllBeer.txt'\n",
    "STOPWORDS_PATH = 'stopwords.txt'\n",
    "\n",
    "def parseData(filename):\n",
    "    #Parse a data file returns a RDD of parsed lines\n",
    "    \n",
    "    return (sc\n",
    "            .textFile(filename, 4, 0)\n",
    "            .map(parseDatafileLine)\n",
    "            .cache())\n",
    "\n",
    "def loadData(path):\n",
    "    ##Load a data file, returns a RDD of parsed valid lines\n",
    "    \n",
    "    filename = os.path.join(baseDir, path)\n",
    "    raw = parseData(filename).cache()\n",
    "    failed = (raw\n",
    "              .filter(lambda s: s[1] == -1)\n",
    "              .map(lambda s: s[0]))\n",
    "    for line in failed.take(10):\n",
    "        print '%s - Invalid datafile line: %s' % (path, line)\n",
    "    valid = (raw\n",
    "             .filter(lambda s: s[1] == 1)\n",
    "             .map(lambda s: s[0])\n",
    "             .cache())\n",
    "    header = (raw\n",
    "              .filter(lambda s: s[1]==0)\n",
    "             .map(lambda s:s[0])\n",
    "             )\n",
    "    for line in header.take(1):\n",
    "        for x in range(0,len(line)):\n",
    "            print x,line[x]\n",
    "            \n",
    "    rawLines = raw.count()\n",
    "    validLines = valid.count()\n",
    "    failedLines = failed.count()\n",
    "    print '%s - Read %d lines, successfully parsed %d lines, failed to parse %d lines' % (path, rawLines, validLines,failedLines)\n",
    "    return valid\n",
    "    \n",
    "allBeer = loadData(allBeer_Path)\n",
    "#allReviews = loadData(allReviews_Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's examine the first few entries of a sample of 5 lines to check if things look ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "allBeer: 40920, Wernecker Haustrunk Pils, Wernecker Bierbrauerei, Pilsener, distribution unknown\n",
      "\n",
      "23\n",
      "allBeer: 21911, Au Ma'tre Brasseur La Boucaneuse, AMB - Ma'tre Brasseur, Smoked, distribution unknown\n",
      "\n",
      "23\n",
      "allBeer: 4991, New Albanian / Struise Naughty Girl, New Albanian Brewing Company, India Pale Ale (IPA), Regional Distribution\n",
      "\n",
      "23\n",
      "allBeer: 38430, BrewDog IPA is Dead - Pioneer, BrewDog, India Pale Ale (IPA), Broad Distribution\n",
      "\n",
      "23\n",
      "allBeer: 41353, Cascade Cerise Nouveau, Cascade Brewing, Sour/Wild Ale, Local Distribution\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampleArray=allBeer.takeSample(False,5,1)\n",
    "for line in sampleArray:\n",
    "    print len(line)\n",
    "    print 'allBeer: %s, %s, %s, %s, %s\\n' % (line[0], line[1], line[2],line[3],line[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we'll split the data into a training set (80%) and test set (%20).  \n",
    "#### This is slightly complicated by the fact that we want to split each user into 80/20, not the set of reviews as a whole.  We will take advantage of stratified sampling in Spark, grouping the reviews by the user name, then sampling by key.  To get the unused data we employ subtractByKey using a compound key of the username and the beer_id, guaranting uniqueness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240334\n",
      "192623\n",
      "47731\n"
     ]
    }
   ],
   "source": [
    "##Using the allBeer array, take stratified sample, and remove blank reviews.\n",
    "beerByUser = allBeer.map(lambda x:(x[19],x)).filter(lambda (x,y):y[22]!='')\n",
    "sampleKeys = beerByUser.keys().collect()\n",
    "fractions={}\n",
    "for k in sampleKeys:\n",
    "    fractions[k]=0.8\n",
    "    \n",
    "beerTrain = beerByUser.sampleByKey(False,fractions).cache()\n",
    "beerTrainKeyed = beerTrain.map(lambda (x,y):(y[0]+y[19],y))\n",
    "beerTest = allBeer.map(lambda x:(x[0]+x[19],x)).subtractByKey(beerTrainKeyed).map(lambda (x,y):(y[19],y)).cache()\n",
    "print beerByUser.count()\n",
    "print beerTrain.count()\n",
    "print beerTest.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's examine the results with a couple of random users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user mzaar has 72 reviews, split into 60 Train and 12 Test\n",
      "The user Bosbouw has 86 reviews, split into 71 Train and 15 Test\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import random_integers\n",
    "##find a random user and print out the train and test set.\n",
    "randomUsers = random_integers(1,len(sampleKeys),2)\n",
    "sampleUserReviewCount = beerByUser.filter(lambda (x,y):x==sampleKeys[randomUsers[0]]).count()\n",
    "sampleUserTrainCount = beerTrain.filter(lambda (x,y):x==sampleKeys[randomUsers[0]]).count()\n",
    "sampleUserTestCount = beerTest.filter(lambda (x,y):x==sampleKeys[randomUsers[0]]).count()\n",
    "print \"The user %s has %d reviews, split into %d Train and %d Test\" % (sampleKeys[randomUsers[0]],sampleUserReviewCount,sampleUserTrainCount,sampleUserTestCount)\n",
    "\n",
    "sampleUserReviewCount = beerByUser.filter(lambda (x,y):x==sampleKeys[randomUsers[1]]).count()\n",
    "sampleUserTrainCount = beerTrain.filter(lambda (x,y):x==sampleKeys[randomUsers[1]]).count()\n",
    "sampleUserTestCount = beerTest.filter(lambda (x,y):x==sampleKeys[randomUsers[1]]).count()\n",
    "print \"The user %s has %d reviews, split into %d Train and %d Test\" % (sampleKeys[randomUsers[1]],sampleUserReviewCount,sampleUserTrainCount,sampleUserTestCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the fit\n",
    "#### So 0.1839 spearman correlation, this isn't so good, but it's a positive correlation which shows that there is some correlation between the order of beers we generate and the order of beers the user actually prefers.  What could be the issue, why is this number so low?  We have not yet added non textual features, such as the alcohol content, the style, the bitterness and the brewery, which could all play a factor in what user's like.  We also have a lot of extraneous words which contribute to the cosine distance, but have no real meaning in determining a user's preference for a beer, words such as 'yesterday'.  We also have many words that only appear once or twice in the set of reviews such as another user's name \"bob4532 gave me this beer to review\" which are also meaningless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('nazzty', 0), ('Bewitched', 1), ('Nejhleader', 8686), ('CObiased', 3), ('DeKreeft2799', 8687)]\n",
      "10420\n"
     ]
    }
   ],
   "source": [
    "##First need to make integer usernames since ALS doesn't support text userIDs.\n",
    "##Solution: create a hash dictionary\n",
    "#print beerTrain.take(5)\n",
    "userList = allBeer.map(lambda x: x[19]).collect()\n",
    "userList = list(set(userList))\n",
    "userDict={}\n",
    "for x in range(0,len(userList)):\n",
    "    userDict[userList[x]]=x\n",
    "print userDict.items()[0:5]\n",
    "print len(userDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Mean Squared Error = 0.000420930268195\n",
      "Test Mean Squared Error = 0.281912698633\n"
     ]
    }
   ],
   "source": [
    "#0 beer_id\n",
    "#1 beer_name\n",
    "#2 brewer_name\n",
    "#3 beer_style\n",
    "#4 distribution\n",
    "#5 brewery_location\n",
    "#6 commercial_desc\n",
    "#7 RATINGS: \n",
    "#8 MEAN (/5)\n",
    "#9 WEIGHTED AVG\n",
    "#10 EST. CALORIES\n",
    "#11 ABV (%)\n",
    "#12 IBU\n",
    "#13 SCORE\n",
    "#14 AROMA (/10)\n",
    "#15 APPEARANCE(/5)\n",
    "#16 TASTE(/10)\n",
    "#17 PALATE(/5)\n",
    "#18 OVERALL(/20)\n",
    "#19 reviewer_name\n",
    "#20 review_location\n",
    "#21 review_date\n",
    "#22 review_content\n",
    "\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "\n",
    "# Reshape data\n",
    "ratings = beerTrain.map(lambda l: Rating(int(l[1][0]), int(userDict[l[0]]), float(l[1][13])))\n",
    "#print ratings.takeSample(False,5,1)\n",
    "# Build the recommendation model using Alternating Least Squares\n",
    "rank = 80\n",
    "numIterations = 40\n",
    "model = ALS.train(ratings, rank, numIterations)\n",
    "\n",
    "# Evaluate the model on training data - bad form!\n",
    "testdata = ratings.map(lambda p: (p[0], p[1]))\n",
    "predictions = model.predictAll(testdata).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "ratesAndPreds = ratings.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "print(\"Training Mean Squared Error = \" + str(MSE))\n",
    "\n",
    "# Save and load model\n",
    "#model.save(sc, \"myModelPath\")\n",
    "#sameModel = MatrixFactorizationModel.load(sc, \"myModelPath\")\n",
    "\n",
    "\n",
    "##Evaluate the model on the test data\n",
    "testRatings = beerTest.map(lambda l: Rating(int(l[1][0]), int(userDict[l[0]]), float(l[1][13])))\n",
    "#print testRatings.takeSample(5,5,False)\n",
    "testdata = testRatings.map(lambda p: (p[0],p[1]))\n",
    "predictions = model.predictAll(testdata).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "ratesAndPreds = testRatings.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "#print ratesAndPreds.takeSample(False,5,1)\n",
    "MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "print(\"Test Mean Squared Error = \" + str(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predsByUser = ratesAndPreds.map(lambda r: (r[0][1],(r[0][0],r[1][0],r[1][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman correlation using collaborative filtering using only scores is 0.442987\n"
     ]
    }
   ],
   "source": [
    "### ToDo: lookup Kendall Tau, Rank Biased Overlap (RBO), maybe mean squared error??\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats.stats import rankdata\n",
    "from scipy.stats import pearsonr\n",
    "import math\n",
    "\n",
    "### Need to implement a function which will take the results from the cosSim RDD and spit out\n",
    "### average?? spearman.\n",
    "\n",
    "def catTuplesToLists(tupleOne,tupleTwo):\n",
    "    if len(tupleOne)==len(tupleTwo):\n",
    "        a=[]\n",
    "        for x in range(0,len(tupleOne)):\n",
    "            firstEle=tupleOne[x]\n",
    "            if type(firstEle) is not list: firstEle = [ tupleOne[x] ]\n",
    "            secondEle=tupleTwo[x]\n",
    "            if type(secondEle) is not list: secondEle = [ tupleTwo[x] ]\n",
    "            a.append(firstEle+secondEle)\n",
    "        return tuple(a)\n",
    "    else:\n",
    "        raise ValueError('Two tuples are not the same dimensions')\n",
    "\n",
    "def mattSpearman(listOne,listTwo):\n",
    "    if type(listOne) is list and type(listTwo) is list:\n",
    "        lO=len(listOne)\n",
    "        if lO==len(listTwo) and lO>1:\n",
    "            lOR = rankdata(listOne)\n",
    "            lTR = rankdata(listTwo)\n",
    "            print lOR\n",
    "            print lTR\n",
    "            dSquared=0\n",
    "            for x in range(0,lO):\n",
    "                dSquared+=(lOR[x]-lTR[x])**2\n",
    "            return 1-6*dSquared/lO/(lO**2-1)\n",
    "        else:\n",
    "            raise ValueError(\"Both Lists must be same length and greater than one.\")\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def reduceNaN(a,b):\n",
    "    if math.isnan(a):\n",
    "        a=0\n",
    "    if math.isnan(b):\n",
    "        b=0\n",
    "    return a+b\n",
    "\n",
    "def avgSpearman(inputRDD):\n",
    "    #So the problem here is trying to output two lists which have the scores in the same order.\n",
    "    #Write custom reduce function, catTuplesToLists\n",
    "    convertedToLists = inputRDD.reduceByKey(catTuplesToLists)\n",
    "    #print convertedToLists.take(5)\n",
    "    filteredLists = convertedToLists.filter(lambda (x,y):type(y[1]) is list)\n",
    "    #print filteredLists.take(5)\n",
    "    spearmanByKey = filteredLists.map(lambda (x,y):(x,mattSpearman(y[1],y[2]), len(y[1])))\n",
    "    #print spearmanByKey.take(5)\n",
    "    spearmanOnly = spearmanByKey.map(lambda (x,y,z):y)\n",
    "    #print spearmanOnly.count()\n",
    "    #print spearmanOnly.take(5)\n",
    "    avgSpearmanRho=spearmanOnly.reduce(lambda a,b:a+b)/spearmanOnly.count()\n",
    "    return avgSpearmanRho\n",
    "\n",
    "print \"The Spearman correlation using collaborative filtering using only scores is %f\" % avgSpearman(predsByUser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
