{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Spark Logo](http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png) + ![Python Logo](http://spark-mooc.github.io/web-assets/images/python-logo-master-v3-TM-flattened_small.png)\n",
    "# **Text Analysis of Beer Reviews**\n",
    "Here we use pySpark to analyze the text in the commercial description and review text to create similarity scores between beers.  The scores can then be used for clustering and beer style identification or to find beers similar to what a user enjoys, as a recommendation service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preliminaries**\n",
    "#### We read in the allBeer.txt file and create an RDD consisting of lines.\n",
    "#### We want to remove the header from the file, so the parseDataFileLine function identifies lines starting with 'beer_id' and applies a flag of 0, other lines with the correct number of fields are flagged 1, and incorrect lines are flagged -1.  The lines are split into arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parseDatafileLine(datafileLine):\n",
    "    ##Parse a line of the data file using the specified regular expression pattern\n",
    "    splitArray = datafileLine.split(\"\\t\")\n",
    "    for x in range(0,len(splitArray)):\n",
    "        splitArray[x]=splitArray[x].replace(\"\\\"\",'')\n",
    "    #print len(splitArray)\n",
    "    #print splitArray[0],splitArray[1],splitArray[2]\n",
    "    if splitArray[0]=='beer_id':\n",
    "        return (splitArray,0)\n",
    "    elif len(splitArray)<>23:\n",
    "        ##this is a failed parse\n",
    "        return (splitArray,-1)\n",
    "    else:\n",
    "        return (splitArray, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the file\n",
    "#### We read the file into three rdds by first parsing the file as above, the header rdd, failed rdd and the valid rdd.  Print the header names so we can remember what fields we're dealing with and in what order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 beer_id\n",
      "1 beer_name\n",
      "2 brewer_name\n",
      "3 beer_style\n",
      "4 distribution\n",
      "5 brewery_location\n",
      "6 commercial_desc\n",
      "7 RATINGS: \n",
      "8 MEAN (/5)\n",
      "9 WEIGHTED AVG\n",
      "10 EST. CALORIES\n",
      "11 ABV (%)\n",
      "12 IBU\n",
      "13 SCORE\n",
      "14 AROMA (/10)\n",
      "15 APPEARANCE(/5)\n",
      "16 TASTE(/10)\n",
      "17 PALATE(/5)\n",
      "18 OVERALL(/20)\n",
      "19 reviewer_name\n",
      "20 review_location\n",
      "21 review_date\n",
      "22 review_content\n",
      "AllBeer.txt - Read 240355 lines, successfully parsed 240354 lines, failed to parse 0 lines\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "baseDir = os.path.join('')\n",
    "allBeer_Path = 'AllBeer.txt'\n",
    "STOPWORDS_PATH = 'stopwords.txt'\n",
    "\n",
    "def parseData(filename):\n",
    "    #Parse a data file returns a RDD of parsed lines\n",
    "    \n",
    "    return (sc\n",
    "            .textFile(filename, 4, 0)\n",
    "            .map(parseDatafileLine)\n",
    "            .cache())\n",
    "\n",
    "def loadData(path):\n",
    "    ##Load a data file, returns a RDD of parsed valid lines\n",
    "    \n",
    "    filename = os.path.join(baseDir, path)\n",
    "    raw = parseData(filename).cache()\n",
    "    failed = (raw\n",
    "              .filter(lambda s: s[1] == -1)\n",
    "              .map(lambda s: s[0]))\n",
    "    for line in failed.take(10):\n",
    "        print '%s - Invalid datafile line: %s' % (path, line)\n",
    "    valid = (raw\n",
    "             .filter(lambda s: s[1] == 1)\n",
    "             .map(lambda s: s[0])\n",
    "             .cache())\n",
    "    header = (raw\n",
    "              .filter(lambda s: s[1]==0)\n",
    "             .map(lambda s:s[0])\n",
    "             )\n",
    "    for line in header.take(1):\n",
    "        for x in range(0,len(line)):\n",
    "            print x,line[x]\n",
    "            \n",
    "    rawLines = raw.count()\n",
    "    validLines = valid.count()\n",
    "    failedLines = failed.count()\n",
    "    print '%s - Read %d lines, successfully parsed %d lines, failed to parse %d lines' % (path, rawLines, validLines,failedLines)\n",
    "    return valid\n",
    "    \n",
    "allBeer = loadData(allBeer_Path)\n",
    "#allReviews = loadData(allReviews_Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's examine the first few entries of a sample of 5 lines to check if things look ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "allBeer: 40920, Wernecker Haustrunk Pils, Wernecker Bierbrauerei, Pilsener, distribution unknown\n",
      "\n",
      "23\n",
      "allBeer: 21911, Au Ma'tre Brasseur La Boucaneuse, AMB - Ma'tre Brasseur, Smoked, distribution unknown\n",
      "\n",
      "23\n",
      "allBeer: 4991, New Albanian / Struise Naughty Girl, New Albanian Brewing Company, India Pale Ale (IPA), Regional Distribution\n",
      "\n",
      "23\n",
      "allBeer: 38430, BrewDog IPA is Dead - Pioneer, BrewDog, India Pale Ale (IPA), Broad Distribution\n",
      "\n",
      "23\n",
      "allBeer: 41353, Cascade Cerise Nouveau, Cascade Brewing, Sour/Wild Ale, Local Distribution\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampleArray=allBeer.takeSample(False,5,1)\n",
    "for line in sampleArray:\n",
    "    print len(line)\n",
    "    print 'allBeer: %s, %s, %s, %s, %s\\n' % (line[0], line[1], line[2],line[3],line[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we'll split the data into a training set (80%) and test set (%20).  \n",
    "#### This is slightly complicated by the fact that we want to split each user into 80/20, not the set of reviews as a whole.  We will take advantage of stratified sampling in Spark, grouping the reviews by the user name, then sampling by key.  To get the unused data we employ subtractByKey using a compound key of the username and the beer_id, guaranting uniqueness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240334\n",
      "192427\n",
      "47927\n"
     ]
    }
   ],
   "source": [
    "##Using the allBeer array, take stratified sample, and remove blank reviews.\n",
    "beerByUser = allBeer.map(lambda x:(x[19],x)).filter(lambda (x,y):y[22]!='')\n",
    "sampleKeys = beerByUser.keys().collect()\n",
    "fractions={}\n",
    "for k in sampleKeys:\n",
    "    fractions[k]=0.8\n",
    "    \n",
    "beerTrain = beerByUser.sampleByKey(False,fractions).cache()\n",
    "beerTrainKeyed = beerTrain.map(lambda (x,y):(y[0]+y[19],y))\n",
    "beerTest = allBeer.map(lambda x:(x[0]+x[19],x)).subtractByKey(beerTrainKeyed).map(lambda (x,y):(y[19],y)).cache()\n",
    "print beerByUser.count()\n",
    "print beerTrain.count()\n",
    "print beerTest.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's examine the results with a couple of random users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user patrick767 has 259 reviews, split into 219 Train and 40 Test\n",
      "The user LoveABeer has 5 reviews, split into 3 Train and 2 Test\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import random_integers\n",
    "##find a random user and print out the train and test set.\n",
    "randomUsers = random_integers(1,len(sampleKeys),2)\n",
    "sampleUserReviewCount = beerByUser.filter(lambda (x,y):x==sampleKeys[randomUsers[0]]).count()\n",
    "sampleUserTrainCount = beerTrain.filter(lambda (x,y):x==sampleKeys[randomUsers[0]]).count()\n",
    "sampleUserTestCount = beerTest.filter(lambda (x,y):x==sampleKeys[randomUsers[0]]).count()\n",
    "print \"The user %s has %d reviews, split into %d Train and %d Test\" % (sampleKeys[randomUsers[0]],sampleUserReviewCount,sampleUserTrainCount,sampleUserTestCount)\n",
    "\n",
    "sampleUserReviewCount = beerByUser.filter(lambda (x,y):x==sampleKeys[randomUsers[1]]).count()\n",
    "sampleUserTrainCount = beerTrain.filter(lambda (x,y):x==sampleKeys[randomUsers[1]]).count()\n",
    "sampleUserTestCount = beerTest.filter(lambda (x,y):x==sampleKeys[randomUsers[1]]).count()\n",
    "print \"The user %s has %d reviews, split into %d Train and %d Test\" % (sampleKeys[randomUsers[1]],sampleUserReviewCount,sampleUserTrainCount,sampleUserTestCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the reviews:\n",
    "#### Each user has a different way of scoring beers, some people judge more harshly than others.  In order to even out these scores, we get get statistics for each user and adjust their scores to fit a common distribution.  In this particular case we use a normal distribution for it's simplicity to execute.  Users with 1 or less reviews will have a standard deviation of 0, in which case we substitute 1 to ensure the division when obtaining z-scores we will not divide by zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Skyview', ['18373', 'Rail House Brewers Best Pilsener', 'Rail House Restaurant and Brewery', 'Pilsener', 'Local Distribution', 'Marinette , Wisconsin USA', 'This classic Menominee-Marinette Brewery lager is brewed with only water, barley, hops, and is fermented at cave-like temperatures with lager yeast to produce its smooth character', '7.000', '2.910', '2.840', '150.000', '5.000', '', 0.18517035918953417, '6.000', '4.000', '6.000', '3.000', 0.7043100167332103, 'Skyview', 'Papoose Jct, Minnesota, USA ', 'JUL 2, 2007 ', \"Another one of Menominee-Marinette brewery brands of the past revived by Rail House. On tap and in bottles at the brewpub, this beer pours a light golden amber brew with a thick white head that leaves an excellent lacing. Aroma is lighter than Silver Cream but still has light roasted malt, flowery hops and a touch of vanilla. Taste is lightly carbonated with a sweet doughy taste. Finish is semi-sweet and creamy with a good bitter balance. Though this is not the original recipe of the historical Brewers' Best, it is still very refreshing! For you beer historians, this brand is the legendary Brewers' Best Pilsener beer that was at various times brewed by 13 different breweries between 1943 and 1967. Walter Brewing Company of Trinidad, Colorado started this beer in 1943 and shared a unique yeast strain that gave this a smooth, light bready and crisp flavor. Though the yeast strain has been long gone since 1950, (Two Rivers Beverage Co. in Two Rivers, Wisconsin had the last yeast batch), kudos to Rail House for reviving this historical brand of the very distant past.\"]), ('bigda83', ['27655', 'Switchback Berlinerweisse', 'Switchback Brewing Company', 'Berliner Weisse', 'distribution unknown', 'Burlington , Vermont USA', 'Brewed with our house Ale yeast and Lactobacillus producing this hazy, spritzy, straw colored beer with a clean lactic sourness.', '1.000', '3.900', '3.130', '90.000', '3.000', '10.000', 0.39063529896129845, '7.000', '4.000', '8.000', '4.000', 0.4578205243869588, 'bigda83', 'Jamestown, New York, USA ', 'JUL 24, 2015', 'Draft at the source a little over a week ago. Poured clear, golden, bright, and had a small fizzy white head. Aromas of citrus, grass, hay, funk hit the nose. Flavor was very nice with straw, grass, lemon, sour, and funk in it. Very tasty and refreshing. Light body and a creamy texture to it. Fizzy and bubbly carbonation and a dry finish. Nicely done.']), ('Lubiere', ['20442', \"Brasseurs et Fr'res Public House L'g're\", \"Brasseurs et Fr'res\", 'Golden Ale/Blond Ale', 'distribution unknown', 'Dunham, Canada', 'No commercial description', '15.000', '2.130', '2.310', '120.000', '4.000', '', -1.2143974218422313, '5.000', '3.000', '6.000', '2.000', -0.8689463260595255, 'Lubiere', 'Ottawa, Ontario, CANADA ', 'OCT 9, 2007 ', 'Alightly hazed blonde with a thin white head. A light malty sweet aroma, lightly hopped and faint. In mouth, a sweetish malt with very light floral hops, a bit buttery in mouthfeel. Not bad for a lager, but very uninspired. ']), ('KickInChalice', ['40694', 'Founders Cashew Mountain Brown', 'Founders Brewing Company', 'American Strong Ale', 'distribution unknown', 'Grand Rapids , Michigan USA', \"Imperial Brown Ale. Aged in maple syrup'bourbon barrels for 287 days in the caves beneath Grand Rapids. Crushed cashews are added into the fermenters and the barrels'and you won't doubt it when you try it. Taproom specialty.\", '36.000', '4.040', '3.850', '300.000', '10.000', '', -1.410400473133338, '6.000', '4.000', '5.000', '3.000', -1.721900182659792, 'KickInChalice', 'Chicago, Illinois, USA ', 'MAR 7, 2012 ', 'From notes. First reviewed 8/21/2011. Served on tap in a cervoise at the Great Taste of the Midwest. My pours has a full walnut brown color with a light red tint. A small tan cap disappears almost instantly. This aroma is supposed to be full of cashew, cocoa, and bourbon. Instead I get a very light tofffee and caramel malt aroma with a lot of ethyl alcohol. There is a little bit of cashew in the background, but I have to dig to find it. The flavor has a little bit of maple syrup, some toffee and bready malt up front, then a touch of cashew, a little bourbon, and some fusel alcohol flavors. It is being generous to say this tastes like a boozy brown ale. The mouthfeel is full bodied, with carbonation near the creamy end of the spectrum. The boozy nature of the beer warms the throat and stomach. A little bit oily, a little bit sticky. This was the most disappointing beer I had at the Great Taste. I was really looking forward to this, and as the first beer of the day, it was a huge dud. It is probably worth trying again to see if this was a bad batch; I would never expected this from Founders. ']), ('TBone', ['12149', 'Pipeworks Chipotle Smoked Porter', 'Pipeworks Brewing Company', 'Smoked', 'Local Distribution', 'Chicago , Illinois USA', 'For those crazy enough to think our smoked porter needed something more, we give you Chipotle Smoked Porter. In addition to the already bold character from the smoked malts, we bring the heat with a healthy dose of chipotle peppers to take this rich porter to the next level. Recommended pairing with a giant hunk of smoked meat and a big ass bon fire on a cold night.', '37.000', '3.580', '3.520', '225.000', '7.500', '', 0.17833963607165354, '7.000', '3.000', '6.000', '3.000', 0.02187211577665591, 'TBone', 'Pori, FINLAND ', 'NOV 20, 2013', 'Keg@Mikkeller Bar, CPH Dark brown color, small off-white head. Smoked, roasted, slightly fruity aroma. Medium-bodied. Caramel, light chilli, low bitterness. A bit dissapointing. '])]\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "##13 SCORE\n",
    "##14 AROMA (/10)\n",
    "##15 APPEARANCE(/5)\n",
    "##16 TASTE(/10)\n",
    "##17 PALATE(/5)\n",
    "##18 OVERALL(/20)\n",
    "\n",
    "def replaceZeroes(inputValue,replacementValue):\n",
    "    if inputValue == 0:\n",
    "        inputValue = replacementValue\n",
    "    return inputValue\n",
    "\n",
    "def subtractFromColumn(inputList,columnToChange,subtractAmount):\n",
    "    inputList[columnToChange]=float(inputList[columnToChange])-subtractAmount\n",
    "    return inputList\n",
    "\n",
    "def divideColumn(inputList,columnToChange,divisor):\n",
    "    inputList[columnToChange]=float(inputList[columnToChange])/divisor\n",
    "    return inputList\n",
    "\n",
    "\n",
    "### rewrite this to be RDD of (key,everything else) and return (key, everything with normalized column x)\n",
    "### Then run a few times and cache, and move this up into the preliminaries (post split)\n",
    "def normalizeScoreByKey(inputRDD,scoreColumn):\n",
    "    ##Takes in RDD of (key,array) and \n",
    "    ##returns RDD of (key,array with scoreColumn normalized)\n",
    "    sumScores = inputRDD.map(lambda (x,y):(x,float(y[scoreColumn]))).reduceByKey(lambda a,b:a+b)\n",
    "    #print sumScores.map(lambda (x,y):y).reduce(lambda a,b:a+b)\n",
    "    countScoresPerKey = inputRDD.map(lambda (x,y):(x,1)).reduceByKey(lambda a,b:a+b)\n",
    "    #print countKeys.map(lambda (x,y):y).reduce(lambda a,b:a+b)\n",
    "    averageScores = sumScores.join(countScoresPerKey).map(lambda (x,y):(x,y[0]/y[1]))\n",
    "    #print averageScores.takeSample(False,5,3)\n",
    "    centredScores = inputRDD.join(averageScores).map(lambda (x,(y,z)):(x,subtractFromColumn(y,scoreColumn,z)))\n",
    "    #print centredScores.map(lambda (x,y):y[scoreColumn]).reduce(lambda a,b:a+b)\n",
    "    centredScoresSquaredSum = centredScores.map(lambda (x,y):(x,y[scoreColumn]*y[scoreColumn])).reduceByKey(lambda a,b:a+b)\n",
    "    centredScoresSquaredSumAndCount = centredScoresSquaredSum.join(countScoresPerKey)\n",
    "    stdDeviationByKey = centredScoresSquaredSumAndCount.map(lambda (x,y):(x,sqrt(y[0]/y[1])))\n",
    "    ##This is actually pointless since a centred score is 0 and 0/anything = 0\n",
    "    ##countLines = stdDeviationByUser.count()\n",
    "    ##avgStdDev = stdDeviationByUser.map(lambda (x,y):y).reduce(lambda a,b:a+b)/countLines\n",
    "    stdDeviationByKeyNoZero = stdDeviationByKey.map(lambda (x,y):(x,replaceZeroes(y,1)))\n",
    "    normalizedRDD = centredScores.join(stdDeviationByKeyNoZero).map(lambda (x,(y,z)):(x,divideColumn(y,scoreColumn,z)))\n",
    "    return normalizedRDD\n",
    "\n",
    "##Normalize the Scores\n",
    "normalizedScores = normalizeScoreByKey(beerTrain,13)\n",
    "##Normalize the rest of the ratings\n",
    "#beerTrainNormA = normalizeScoreByKey(normalizedScores,14)\n",
    "#beerTrainNormB = normalizeScoreByKey(beerTrainNormA,15)\n",
    "#beerTrainNormC = normalizeScoreByKey(beerTrainNormB,16)\n",
    "#beerTrainNormD = normalizeScoreByKey(beerTrainNormC,17)\n",
    "beerTrainNormalized = normalizeScoreByKey(normalizedScores,18).cache()\n",
    "\n",
    "print beerTrainNormalized.takeSample(False,5,4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Normalized Histograms**\n",
    "#### Plot histograms of the normalized ratings to check to see if normality approximately holds.\n",
    "#### Clearly score and overall are not normal, skewed right.  This would imply that when people hate a beer, they're more willing to review it harshly than they are willing to give a glowing review to a beer they love."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAADSCAYAAABeiClsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiR1nMlckqSOM5lLktRx/x/2kV1tDlJPbQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x57a9110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAADSCAYAAABeiClsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJw7cYNzJAQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5bf2490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "##Get all the normalized scores into one list.\n",
    "scoreValues = beerTrainNormalized.map(lambda (x,y): y[13]).collect()\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "plt.title('Normalized Scores')\n",
    "plt.hist(scoreValues, 50, log=False)\n",
    "overallValues = beerTrainNormalized.map(lambda (x,y): y[18]).collect()\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "plt.title('Normalized Overall')\n",
    "plt.hist(overallValues, 50, log=False)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's think about the test data set as if it were a menu in a pub\n",
    "#### For each of the beers on the menu we need to generate a score, to see how compatable the beer is with the beer drinker's tastes.  From these scores we can then order the list, best to worst and the user can make their choice.  To do that we first need to know what the user likes, so let's take a look at their reviews and generate a list of traits, with each trait weighted by their own review scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Making Bags of Words\n",
    "#### We can take the commercial descriptions and the user input text reviews and convert them into bags of words, we can then treat each word as a feature.  \n",
    "#### We should take out stopwords before we do this, to avoid unfairly weighting reviews based on words which don't contribute much meaning, such as \"the\", \"a\", \"is\", \"which\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the stopwords: set([u'all', u'just', u'being', u'over', u'both', u'through', u'yourselves', u'its', u'before', u'with', u'had', u'should', u'to', u'only', u'under', u'ours', u'has', u'do', u'them', u'his', u'very', u'they', u'not', u'during', u'now', u'him', u'nor', u'did', u'these', u't', u'each', u'where', u'because', u'doing', u'theirs', u'some', u'are', u'our', u'ourselves', u'out', u'what', u'for', u'below', u'does', u'above', u'between', u'she', u'be', u'we', u'after', u'here', u'hers', u'by', u'on', u'about', u'of', u'against', u's', u'or', u'own', u'into', u'yourself', u'down', u'your', u'from', u'her', u'whom', u'there', u'been', u'few', u'too', u'themselves', u'was', u'until', u'more', u'himself', u'that', u'but', u'off', u'herself', u'than', u'those', u'he', u'me', u'myself', u'this', u'up', u'will', u'while', u'can', u'were', u'my', u'and', u'then', u'is', u'in', u'am', u'it', u'an', u'as', u'itself', u'at', u'have', u'further', u'their', u'if', u'again', u'no', u'when', u'same', u'any', u'how', u'other', u'which', u'you', u'who', u'most', u'such', u'why', u'a', u'don', u'i', u'having', u'so', u'the', u'yours', u'once'])\n",
      "['test', 'tf', 'function', 'return', 'non', 'stopword', 'frequencies', 'frequency', 'sourness']\n"
     ]
    }
   ],
   "source": [
    "stopfile = os.path.join(baseDir, STOPWORDS_PATH)\n",
    "stopwords = set(sc.textFile(stopfile).collect())\n",
    "testString = \"This is a test of the tf function.  It should return non stopword frequencies frequency sourness\"\n",
    "print 'These are the stopwords: %s' % stopwords\n",
    "split_regex = r'\\W+'\n",
    "\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "#Stmmr = PorterStemmer()\n",
    "\n",
    "def tokenize(string):\n",
    "    ##takes in a string and tokenizes it, removing stopwords, returns list\n",
    "    simple=filter(None,re.split(split_regex,string.lower()))\n",
    "    #simple = [Stmmr.stem(i) for i in simple]\n",
    "    return [i for i in simple if i not in stopwords]\n",
    "\n",
    "print tokenize(testString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tokenizing the Commercial Description and Review**\n",
    "#### Now tokenize the commercial descriptions and reviews. \n",
    "#### To see how much data we're dealing with let's count the total number of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4664703 tokens in the commercial descriptions\n",
      "There are 6679744 tokens in the reviews\n"
     ]
    }
   ],
   "source": [
    "##6 commercial description\n",
    "##22 user input review\n",
    "##make an RDD where the user_id is the key, and the value is 2 arrays of tokens \n",
    "##and the original line\n",
    "beerTrainToToken = beerTrainNormalized.map(lambda (x,y):(y[19],(tokenize(y[6]),tokenize(y[22]),y)))\n",
    "\n",
    "def countTokens(textRDD,reviewTRUE):\n",
    "    ## Count and return the number of tokens\n",
    "    if reviewTRUE==True:\n",
    "        return textRDD.map(lambda (x,y):len(y[1])).reduce(lambda a,b:a+b)\n",
    "    else:\n",
    "        return textRDD.map(lambda (x,y):len(y[0])).reduce(lambda a,b:a+b)\n",
    "\n",
    "print 'There are %s tokens in the commercial descriptions' % countTokens(beerTrainToToken,False)\n",
    "print 'There are %s tokens in the reviews' % countTokens(beerTrainToToken,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get an idea of how big a review is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review from user \"SlovakSniper\" has the most tokens (579)\n",
      "The review from user \"Shurf\" has the least tokens (0)\n"
     ]
    }
   ],
   "source": [
    "def findBiggestRecord(textRDD,reviewTRUE):\n",
    "    # Find and return the record with the largest number of tokens\n",
    "    if reviewTRUE==True:\n",
    "        return textRDD.takeOrdered(1,lambda (x,y):-len(y[1]))\n",
    "    else:\n",
    "        return textRDD.takeOrdered(1,lambda (x,y):-len(y[0]))\n",
    "\n",
    "def findSmallestRecord(textRDD,reviewTRUE):\n",
    "    # Find and return the record with the largest number of tokens\n",
    "    if reviewTRUE==True:\n",
    "        return textRDD.takeOrdered(1,lambda (x,y):len(y[1]))\n",
    "    else:\n",
    "        return textRDD.takeOrdered(1,lambda (x,y):len(y[0]))\n",
    "\n",
    "biggestReview = findBiggestRecord(beerTrainToToken,True)\n",
    "print 'The review from user \"%s\" has the most tokens (%s)' % (biggestReview[0][0],\n",
    "                                                                   len(biggestReview[0][1][1]))\n",
    "smallestReview = findSmallestRecord(beerTrainToToken,True)\n",
    "print 'The review from user \"%s\" has the least tokens (%s)' % (smallestReview[0][0], len(smallestReview[0][1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So clearly we've got some reviews that are empty, and we'll need some special handling for those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Weighted Bag-of-Words using TF-IDF**\n",
    "\n",
    "### Term Frequency (TF) \n",
    "#### This gives higher weight to tokens that appear many times in a individual document. It is computed as the frequency of a token in a document. If a word occurs often in a document, then it is more important to the meaning of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'function': 0.14285714285714285, 'non': 0.14285714285714285, 'return': 0.14285714285714285, 'frequencies': 0.14285714285714285, 'stopword': 0.14285714285714285, 'tf': 0.14285714285714285, 'test': 0.14285714285714285}\n"
     ]
    }
   ],
   "source": [
    "testString = \"This is a test of the tf function.  It should return non stopword frequencies\"\n",
    "def tf(tokens):\n",
    "    ###Compute TF from list of tokens, return dictionary of word:tf\n",
    "    count = len(tokens)\n",
    "    words={}\n",
    "    for token in tokens:\n",
    "        words[token]=float(len([t for t in tokens if t==token]))/count\n",
    "    return words\n",
    "\n",
    "print tf(tokenize(testString))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency\n",
    "#### This gives higher weight to tokens that are rare over the entire dataset. The rationale is two documents are more alike if they have in common words which are not common to rest data set.  IDF weight for a token in a set of documents is calculated as D/d(t) where D is the total number of documents and d(t) is the number of documents with term t.  \n",
    "#### Keep in mind that the dataset for IDF is not the whole dataset, but the set of reviews for a particular user.  We want to find out what is special to that individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('toddomundo', {'rating': 1.0, 'ipa': 1.0, 'outstanding': 1.0, '60': 1.0, 'mild': 1.0, 'want': 1.0, 'exclusion': 1.0, 'would': 1.0, 'hops': 1.0, 'delightfully': 1.0, 'perfectly': 1.0, 'sure': 1.0, 'bold': 1.0, 'citrus': 1.0, '70': 1.0, 'put': 1.0, 'overwhelming': 1.0, 'compliments': 1.0, 'smooth': 1.0, 'bitterness': 1.0, 'citra': 1.0, 'claims': 1.0, 'ibu': 1.0}), ('Reid', {'growlette': 23.0, 'powdery': 23.0, 'ale': 5.75, 'alc': 7.666666666666667, 'yellow': 11.5, 'zing': 23.0, 'woods': 23.0, 'gc': 23.0, 'bomber': 4.6, 'mellow': 11.5, 'suicide': 23.0, 'absolutly': 23.0, '1930s': 23.0, 'helps': 23.0, 'pleasing': 11.5, 'brown': 7.666666666666667, 'yeast': 11.5, 'coloured': 11.5, 'putting': 23.0, 'surprise': 23.0, 'unrefridgerated': 23.0, 'impressive': 23.0, 'cloudy': 11.5, 'try': 23.0, 'small': 7.666666666666667, 'says': 11.5, 'sign': 23.0, 'past': 23.0, 'dried': 23.0, 'even': 23.0, 'business': 23.0, 'rum': 23.0, 'espresso': 23.0, 'hazy': 2.875, 'flowing': 23.0, 'ever': 23.0, 'movement': 7.666666666666667, 'body': 5.75, 'degree': 23.0, 'strong': 2.875, 'orkney': 23.0, 'appears': 23.0, 'dry': 23.0, '39': 23.0, 'colored': 23.0, 'smoky': 23.0, 'aromas': 2.5555555555555554, 'haziness': 23.0, 'amount': 23.0, 'smoke': 23.0, 'sweetness': 23.0, 'golden': 4.6, 'ipa': 7.666666666666667, 'love': 23.0, 'apple': 5.75, 'lovelly': 23.0, 'straw': 23.0, 'market': 4.6, 'takes': 23.0, 'faint': 23.0, 'creamy': 2.3, 'going': 23.0, 'frothy': 3.2857142857142856, '6': 5.75, 'thru': 23.0, 'type': 23.0, 'minor': 23.0, 'sort': 23.0, 'almost': 7.666666666666667, 'drinkable': 4.6, 'starburst': 23.0, 'oregon': 7.666666666666667, 'chocolate': 11.5, '99': 2.090909090909091, 'glass': 11.5, 'warm': 23.0, 'excellent': 23.0, 'olive': 23.0, '90': 23.0, 'ihave': 23.0, 'hints': 23.0, 'room': 23.0, 'malt': 5.75, 'pour': 23.0, 'sour': 23.0, 'thin': 11.5, 'starts': 23.0, 'arrive': 23.0, 'example': 23.0, 'slightest': 11.5, 'onbe': 23.0, 'bittersweet': 23.0, 'grassy': 23.0, 'tad': 23.0, 'purchased': 7.666666666666667, 'tan': 3.2857142857142856, 'pink': 23.0, 'huge': 23.0, 'needs': 23.0, 'end': 2.875, 'provide': 23.0, 'rye': 11.5, 'nuts': 23.0, 'pine': 23.0, '1': 23.0, 'hop': 3.8333333333333335, 'barleywine': 23.0, 'fudge': 11.5, 'pint': 7.666666666666667, 'watery': 11.5, 'growl': 11.5, 'lighting': 23.0, 'floral': 7.666666666666667, 'grow': 23.0, 'wineish': 23.0, 'short': 23.0, 'natural': 3.8333333333333335, 'light': 4.6, 'bready': 11.5, 'mango': 11.5, 'keeps': 23.0, 'balancing': 23.0, 'typical': 23.0, 'six': 23.0, 'indeed': 23.0, 'move': 23.0, 'mainly': 11.5, 'soon': 23.0, 'years': 23.0, 'produced': 23.0, 'course': 23.0, 'still': 11.5, 'cola': 23.0, 'style': 7.666666666666667, '22': 2.875, '29': 7.666666666666667, 'winning': 23.0, 'quater': 23.0, 'complex': 23.0, 'orange': 5.75, 'might': 23.0, 'eventually': 23.0, 'non': 23.0, 'good': 2.090909090909091, 'pure': 11.5, 'citrus': 11.5, 'rummyflavour': 23.0, '9': 23.0, 'stout': 23.0, 'half': 11.5, 'front': 23.0, 'day': 23.0, 'bread': 23.0, 'coriander': 23.0, 'rocky': 11.5, 'yellowy': 23.0, 'cider': 11.5, 'roast': 11.5, 'fired': 23.0, 'citric': 11.5, 'idea': 23.0, 'oil': 23.0, '80': 23.0, 'large': 5.75, 'alcohol': 11.5, 'bauhaus': 23.0, 'looking': 11.5, '7': 23.0, 'got': 23.0, 'dominate': 11.5, 'cause': 23.0, 'red': 23.0, 'foundation': 23.0, 'monster': 23.0, 'whiff': 11.5, 'pours': 2.090909090909091, 'quite': 11.5, 'pleasant': 23.0, 'complicated': 23.0, 'thrown': 23.0, 'shelves': 23.0, 'roths': 5.75, 'american': 11.5, 'massive': 23.0, 'think': 23.0, 'south': 23.0, 'copper': 11.5, 'piney': 23.0, 'feel': 2.3, 'one': 5.75, 'carry': 23.0, 'thick': 2.3, 'little': 4.6, 'blossom': 23.0, 'bite': 23.0, 'claean': 23.0, '2': 11.5, 'nuttiness': 23.0, 'blossoms': 23.0, 'white': 1.7692307692307692, 'bitter': 23.0, 'banana': 23.0, 'store': 11.5, 'tempers': 23.0, 'mostly': 11.5, 'shelf': 11.5, 'pnw': 23.0, 'part': 11.5, 'somewhat': 23.0, 'overwhelming': 23.0, '10': 23.0, 'grocery': 5.75, '12': 7.666666666666667, 'grillin': 23.0, '16': 11.5, 'grocers': 5.75, 'bitterness': 23.0, 'dank': 23.0, 'lingering': 23.0, 'maybe': 11.5, 'fruity': 5.75, 'tasted': 23.0, 'resinous': 23.0, 'tonight': 23.0, 'say': 11.5, 'medium': 5.75, 'dryness': 23.0, 'cascade': 23.0, 'note': 23.0, 'also': 23.0, 'hefe': 23.0, 'take': 11.5, 'malty': 4.6, '22oz': 11.5, 'mustiness': 23.0, 'malts': 2.3, 'play': 23.0, 'sure': 11.5, 'bottle': 2.5555555555555554, 'though': 7.666666666666667, 'english': 23.0, 'mouth': 2.3, 'nothing': 23.0, '79': 11.5, 'refreshing': 23.0, 'largish': 23.0, 'clear': 7.666666666666667, 'later': 11.5, 'astonishing': 23.0, 'clean': 23.0, 'pineapple': 23.0, 'salt': 23.0, 'gold': 23.0, 'doughy': 11.5, 'boozy': 23.0, 'lifesource': 2.875, 'peaches': 23.0, 'bright': 7.666666666666667, 'session': 23.0, 'darkest': 23.0, 'fine': 7.666666666666667, 'thicker': 23.0, 'aint': 23.0, 'touches': 23.0, 'nectarine': 23.0, '500ml': 23.0, 'hops': 2.875, '3': 11.5, 'wood': 23.0, 'black': 23.0, 'pretty': 3.8333333333333335, '8': 23.0, 'toffee': 11.5, 'get': 23.0, 'capital': 23.0, 'overall': 11.5, 'simplistic': 23.0, 'feels': 23.0, 'outlet': 7.666666666666667, 'altogether': 23.0, 'mainlly': 23.0, 'temp': 23.0, 'tobacco': 23.0, 'bad': 5.75, 'stuff': 3.8333333333333335, 'caramel': 3.2857142857142856, 'discenable': 23.0, 'dsome': 23.0, 'seat': 23.0, 'flavours': 23.0, 'lowish': 23.0, 'best': 23.0, '2000th': 23.0, 'label': 23.0, 'grocer': 11.5, 'slighly': 23.0, 'horrible': 23.0, 'probably': 23.0, 'across': 23.0, 'bought': 2.875, 'sipper': 23.0, 'last': 23.0, 'mega': 23.0, 'berry': 23.0, 'disappears': 23.0, 'comes': 5.75, 'liked': 11.5, 'simple': 23.0, 'sweet': 3.2857142857142856, 'dimensional': 23.0, 'actually': 23.0, 'considering': 23.0, 'unusual': 23.0, 'peppery': 11.5, 'much': 11.5, 'expected': 11.5, 'yeasty': 11.5, 'lovely': 7.666666666666667, 'attractive': 7.666666666666667, 'rather': 7.666666666666667, 'finishes': 23.0, 'packs': 23.0, 'great': 7.666666666666667, 'mouthfeel': 5.75, 'look': 23.0, 'grains': 23.0, 'appearance': 11.5, 'balance': 23.0, 'pack': 11.5, 'backing': 23.0, 'coffee': 7.666666666666667, 'judgeing': 23.0, 'im': 23.0, 'different': 23.0, 'harsh': 23.0, 'perhaps': 23.0, 'make': 23.0, 'strange': 23.0, 'inch': 11.5, 'gets': 11.5, 'toasted': 23.0, 'finish': 23.0, 'papaya': 23.0, 'drink': 23.0, 'ness': 23.0, 'fruit': 7.666666666666667, 'darned': 23.0, 'hopping': 23.0, 'makes': 23.0, 'colour': 2.3, 'smoker': 23.0, 'thought': 23.0, 'components': 23.0, 'consistency': 23.0, 'smoked': 23.0, 'summer': 23.0, 'growler': 23.0, 'less': 23.0, 'aroma': 1.7692307692307692, 'roasted': 23.0, 'touch': 7.666666666666667, 'carbonation': 2.5555555555555554, 'yet': 11.5, 'pils': 11.5, 'huckleberry': 23.0, 'wee': 23.0, 'seems': 23.0, 'hoppy': 23.0, 'lets': 23.0, 'cherries': 23.0, '4': 2.875, 'real': 7.666666666666667, 'aspects': 23.0, 'gorcery': 23.0, 'big': 23.0, 'dark': 3.8333333333333335, 'darn': 23.0, 'bit': 5.75, 'burnt': 11.5, 'prominent': 23.0, 'eroded': 23.0, 'like': 3.2857142857142856, 'semi': 5.75, 'tend': 23.0, 'candy': 23.0, 'oddly': 23.0, 'sized': 3.8333333333333335, 'roth': 11.5, 'nose': 11.5, 'soft': 11.5, 'lager': 7.666666666666667, 'right': 23.0, 'old': 11.5, 'back': 11.5, 'hazed': 23.0, 'pale': 5.75, 'grapefruit': 23.0, 'wheat': 23.0, 'biscuity': 11.5, 'peel': 23.0, 'slight': 5.75, 'stone': 23.0, 'ok': 5.75, 'getting': 11.5, 'months': 23.0, 'oz': 1.9166666666666667, 'mixed': 23.0, 'tongue': 11.5, 'slightly': 5.75, 'slighty': 23.0, 'amber': 4.6, 'thinner': 23.0, 'garnet': 23.0, 'lively': 11.5, 'balanced': 5.75, 'bubbly': 5.75, 'beer': 2.875, 'fast': 23.0, 'noticed': 23.0, 'start': 23.0, 'poured': 11.5, 'sunnyslope': 7.666666666666667, 'low': 11.5, 'lot': 23.0, 'mediun': 23.0, 'head': 1.0, 'spicy': 5.75, 'elsewhere': 23.0, 'enough': 4.6, 'iipa': 23.0, 'buttery': 23.0, 'volume': 23.0, 'beech': 23.0, '12oz': 11.5, 'squeeze': 23.0, 'winco': 23.0, 'spice': 5.75, 'flavour': 7.666666666666667, 'places': 23.0, 'smooth': 2.875, 'bombers': 23.0, 'tones': 23.0, 'similar': 5.75, 'darker': 3.8333333333333335, 'palate': 3.2857142857142856, 'taste': 1.2777777777777777, 'deep': 4.6, 'salem': 1.15, 'tasty': 7.666666666666667, 'cream': 7.666666666666667, 'vista': 11.5, 'macro': 23.0, 'lemon': 11.5, 'peach': 11.5, 'treatment': 23.0, 'tight': 23.0, '5': 5.75, 'smell': 11.5, 'nice': 1.15, 'tasteful': 23.0, 'silky': 23.0, 'toasty': 23.0, 'dunkel': 11.5, 'meaning': 23.0, 'yeastiness': 23.0, 'kinda': 11.5, 'longer': 23.0, 'mass': 23.0, 'fresh': 7.666666666666667})]\n"
     ]
    }
   ],
   "source": [
    "def countEachToken(listOfTokens):\n",
    "    ##Count the number of times each token appears in the list\n",
    "    tokenSet = list(set(listOfTokens))\n",
    "    tokenDict={}\n",
    "    for token in tokenSet:\n",
    "        tokenDict[token]=0\n",
    "    for token in listOfTokens:\n",
    "        tokenDict[token]=tokenDict[token]+1\n",
    "    return tokenDict\n",
    "\n",
    "def divideIntByDict(inputDict,inputInt):\n",
    "    for entry in inputDict:\n",
    "        inputDict[entry]=float(inputInt)/float(inputDict[entry])\n",
    "    return inputDict\n",
    "\n",
    "\n",
    "def IDFByKey(keyCorpus):\n",
    "    uniqueTokens = keyCorpus.map(lambda (x,y):(x,list(set(y))))\n",
    "    tokensByKey = uniqueTokens.reduceByKey(lambda a,b:a+b)\n",
    "    tokensCountByKey = tokensByKey.map(lambda (x,y):(x,countEachToken(y)))\n",
    "    countDocsByKey=keyCorpus.map(lambda (x,y):(x,1)).reduceByKey(lambda a,b:a+b)\n",
    "    countDocsAndTokensByKey = tokensCountByKey.join(countDocsByKey)\n",
    "    IDF=countDocsAndTokensByKey.map(lambda (x,y):(x,divideIntByDict(y[0],y[1])))\n",
    "    return IDF\n",
    "\n",
    "#RDD of (beer_id,text)\n",
    "reviewTokens = beerTrainToToken.map(lambda (x,y):(x,y[1]))\n",
    "reviewIDF=IDFByKey(reviewTokens)\n",
    "print reviewIDF.takeSample(False,2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Implement a TF-IDF function**\n",
    "#### We want to weight the individual features (words) by the user's given scores.  This should increase the weightings of words used only in positive reviews and greatly increase rare words in positive reviews.  We then create an RDD of (key, dictionary) where the dictionary is a ranked collection of each user's individual preferences.  We have a customized set of features which indicate what a user likes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 98783 unique features in the reviews\n",
      "The beer features which people hate the most are: \n",
      "[('corn', -7014.251825890144), ('watery', -5925.509322959493), ('water', -4928.041378560695), ('lager', -4740.113953848786), ('bad', -4306.574231581611), ('metallic', -4148.324447660767), ('bland', -3913.7738413193733), ('cardboard', -3803.313819379331), ('nothing', -3633.9394346164154), ('boring', -3336.7367919585945), ('infected', -3115.6792169872647), ('artificial', -3112.3214606628317), ('grainy', -3032.0488878679444), ('stale', -3029.2839249377503), ('much', -2891.328086952873), ('pale', -2879.0751470069335), ('unpleasant', -2741.4630590838538), ('weak', -2695.0830170819663), ('thin', -2609.3817147933737), ('flat', -2551.3215369115374)]\n",
      "The beer features which people love the most are: \n",
      "[('dark', 1902.5681941086914), ('complex', 2002.4319337771572), ('awesome', 2032.0293577971988), ('great', 2054.2344876100583), ('grapefruit', 2128.388046714417), ('full', 2197.5481243727963), ('balanced', 2240.827272068244), ('coconut', 2289.2965900315303), ('smooth', 2295.4808317421744), ('tropical', 2401.0710806970033), ('oak', 2433.8358445363187), ('excellent', 2464.168298364538), ('delicious', 2496.7875833888234), ('nice', 2609.2961611092383), ('black', 2634.199325663437), ('rich', 2640.617142489453), ('vanilla', 3364.918528089706), ('coffee', 3575.4269973341266), ('chocolate', 3604.6774811660434), ('bourbon', 4050.1314867572432)]\n"
     ]
    }
   ],
   "source": [
    "def multiplyDict(inputDict,multiplier):\n",
    "    #multiplies every entry in a dictionary by a number.\n",
    "    for item in inputDict:\n",
    "        inputDict[item]=inputDict[item]*multiplier\n",
    "    return inputDict\n",
    "\n",
    "def stf(tokens, score):\n",
    "    ### Compute S-TF\n",
    "    tfsDict = tf(tokens)\n",
    "    stfsDict = multiplyDict(tfsDict,score)\n",
    "    return stfsDict\n",
    "\n",
    "def multiplyTwoDicts(firstDict,secondDict):\n",
    "    multDict = {token:firstDict[token]*secondDict[token] for token in firstDict}\n",
    "    return multDict\n",
    "\n",
    "def addTwoDicts(firstDict,secondDict):\n",
    "    for token in firstDict:\n",
    "        if token in secondDict:\n",
    "            firstDict[token]=firstDict[token]+secondDict[token]\n",
    "    for token in secondDict:\n",
    "        if token in firstDict:\n",
    "            pass\n",
    "        else:\n",
    "            firstDict[token]=secondDict[token]            \n",
    "    return firstDict\n",
    "\n",
    "##13 SCORE\n",
    "##14 AROMA (/10)\n",
    "##15 APPEARANCE(/5)\n",
    "##16 TASTE(/10)\n",
    "##17 PALATE(/5)\n",
    "##18 OVERALL(/20)\n",
    "\n",
    "def stfidfByKey(inputRDD,idfRDD,reviewTrue,whichRating):\n",
    "    ##Takes RDD of form (key,(list,list,wholebeer)) and calculates the s-tf of \n",
    "    ##reviewTrue==True ===> review\n",
    "    ##reviewTrue==False ===> commercial Description\n",
    "    ##whichRating ==-1 => don't weight by any column, just use 1 as a factor\n",
    "    ##takes the sum of s-tf and applies the idf to it.\n",
    "    \n",
    "    if (whichRating < 13 or whichRating >18) and whichRating!=-1:\n",
    "        raise ValueError('whichRating must be between 13 and 18 or equal to 0, please refer to documentation about fields')\n",
    "                         \n",
    "    if reviewTrue==True:\n",
    "        #print \"Got past true\"\n",
    "        #print inputRDD.map(lambda (x,(a,b,c)):(x,(b,c[whichRating]))).takeSample(False,3,1)\n",
    "        if whichRating!=-1:\n",
    "            stfRDD = inputRDD.map(lambda (x,(a,b,c)):(x,(stf(b,float(c[whichRating]))))).reduceByKey(addTwoDicts)\n",
    "        else:\n",
    "            stfRDD = inputRDD.map(lambda (x,(a,b,c)):(x,(stf(b,1)))).reduceByKey(addTwoDicts)\n",
    "        #print stfRDD.takeSample(True,3,1)\n",
    "    else:\n",
    "        if whichRating!=-1:\n",
    "            stfRDD = inputRDD.map(lambda (x,(a,b,c)):(x,(stf(a,float(c[whichRating]))))).reduceByKey(lambda a,b:a+b)\n",
    "        else:\n",
    "            stfRDD = inputRDD.map(lambda (x,(a,b,c)):(x,(stf(a,1)))).reduceByKey(lambda a,b:a+b)\n",
    "            \n",
    "    stfidfRDD=stfRDD.join(idfRDD).map(lambda (x,(y,z)):(x,multiplyTwoDicts(y,z)))\n",
    "    #print stfidfRDD.takeSample(True,3,1)\n",
    "    return stfidfRDD\n",
    "\n",
    "    \n",
    "#Generate dictionaries of ranked terms for each user individually.\n",
    "scoreTfIdf = stfidfByKey(beerTrainToToken,reviewIDF,True,13)\n",
    "##Find the best keywords across all users.\n",
    "sumAllFeatures =scoreTfIdf.map(lambda (x,y):y).reduce(addTwoDicts)\n",
    "#print sumAllFeatures.takeSample(False,3,1)\n",
    "\n",
    "import operator\n",
    "sorted_features = sorted(sumAllFeatures.items(), key=operator.itemgetter(1))\n",
    "print \"There are %d unique features in the reviews\" % len(sorted_features)\n",
    "print \"The beer features which people hate the most are: \"\n",
    "print sorted_features[:20]\n",
    "print \"The beer features which people love the most are: \"\n",
    "print sorted_features[-20:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fantastic!\n",
    "### By amalgamating people's individual love/hates we show here that our intuition lines up with the methodology taken so far.  A vanilla bourbon beer beats an infected watery beer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3:  Using reviews to identify features of each beer\n",
    "#### Now that we have a user's preference, we need to figure out what each beer actually contains.  We can do this in a very similar way to the user features.  Collecting the reviews per beer, and applying tf-idf to the review text.  We will build a crowd sourced dictionary of terms that people commonly use to describe each beer.\n",
    "\n",
    "### Generate the IDFs per beer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('40872', {'gold': 7.0, 'cheap': 7.0, 'yellow': 7.0, 'aroma': 2.3333333333333335, 'mild': 3.5, 'touch': 3.5, 'still': 3.5, 'hops': 7.0, '3': 7.0, 'hay': 3.5, 'scarlett': 7.0, 'town': 7.0, 'good': 7.0, 'coloured': 7.0, 'prunes': 7.0, 'flavour': 3.5, 'day': 7.0, 'notes': 7.0, 'leave': 7.0, 'bad': 7.0, 'stuff': 7.0, 'celbridge': 7.0, 'lager': 7.0, 'house': 7.0, 'college': 7.0, 'pale': 3.5, 'lemongrass': 7.0, 'sun': 7.0, 'away': 7.0, 'overly': 7.0, 'enough': 7.0, 'shared': 7.0, 'neither': 7.0, 'bought': 7.0, 'body': 3.5, 'foam': 7.0, 'power': 7.0, 'pours': 7.0, 'corn': 3.5, 'pilsener': 7.0, 'dry': 3.5, 'schaffer': 7.0, 'package': 7.0, 'could': 3.5, 'days': 7.0, 'grain': 7.0, 'ehad': 7.0, 'golden': 2.3333333333333335, 'sweet': 7.0, 'clear': 3.5, 'duck': 7.0, 'hoppy': 7.0, 'decent': 7.0, 'anyone': 7.0, 'almost': 7.0, 'beer': 3.5, 'low': 7.0, 'ireland': 3.5, 'lacing': 7.0, 'mucky': 7.0, 'head': 3.5, 'drinkable': 3.5, 'mostly': 7.0, 'happily': 7.0, 'semisweet': 7.0, 'foamy': 7.0, 'linh': 7.0, 'believe': 7.0, 'white': 3.5, 'count': 7.0, 'mouthfeel': 7.0, 'double': 7.0, 'malt': 7.0, 'grainy': 7.0, 'bitterness': 7.0, 'sour': 7.0, 'thin': 2.3333333333333335, 'light': 3.5, 'average': 7.0, 'donegal': 7.0, 'taste': 7.0, 'deep': 7.0, 'medium': 7.0, 'tasty': 7.0, 'sweetish': 7.0, 'huge': 7.0, 'make': 7.0, 'tip': 7.0, 'metallic': 7.0, 'malty': 3.5, 'buys': 7.0, 'party': 7.0, 'ordinary': 7.0, 'watery': 7.0, 'finish': 2.3333333333333335, 'slightly': 7.0, 'yespr': 7.0, 'centre': 7.0, 'drink': 3.5, 'sturdy': 7.0, 'maybe': 7.0, 'colour': 7.0, 'metal': 7.0, 'bottle': 3.5, 'pooping': 7.0}), ('20803', {'rating': 5.0, 'corps': 5.0, 'golden': 2.5, 'pleasure': 5.0, 'gorg': 5.0, 'boire': 1.6666666666666667, 'yellow': 5.0, 'aroma': 1.25, 'peaches': 5.0, 'soutient': 5.0, 'mild': 5.0, 'dough': 5.0, 'montr': 2.5, 'chissant': 5.0, 'subtle': 5.0, 'hopped': 5.0, 'still': 5.0, 'retention': 5.0, 'pils': 5.0, 'le': 5.0, 'mais': 5.0, 'everything': 5.0, 'hops': 5.0, 'cushy': 5.0, 'character': 5.0, '750ml': 5.0, 'sugar': 5.0, 'apr': 5.0, 'tl': 5.0, '4': 5.0, 'amertume': 5.0, '8': 5.0, 'fin': 5.0, 'sent': 5.0, 'happened': 5.0, 'extraction': 5.0, 'good': 5.0, 'around': 5.0, 'yeast': 5.0, 'citrus': 5.0, 'dark': 5.0, 'bean': 5.0, 'sont': 5.0, 'boozy': 2.5, 'bit': 5.0, 'du': 5.0, 'bread': 5.0, 'entire': 5.0, 'like': 5.0, 'covering': 5.0, 'follows': 5.0, 'notes': 2.5, 'l': 2.5, 'cloudy': 5.0, 'caramel': 5.0, 'nose': 2.5, 'citrusy': 5.0, 'soft': 2.5, 'towards': 5.0, 'rafra': 5.0, 'hora': 2.5, 'malgr': 5.0, 'smaller': 5.0, 'speci': 5.0, 'smooth': 5.0, 'spiciness': 5.0, 'bodied': 5.0, 'bounce': 5.0, 'd': 5.0, 'flavours': 5.0, 'sucr': 5.0, 'candy': 5.0, 'hell': 5.0, 'et': 5.0, 'liking': 5.0, 'pale': 5.0, 'refined': 5.0, 'best': 5.0, 'silky': 5.0, 'flower': 5.0, 'carbonation': 5.0, 'alcohol': 1.6666666666666667, 'bottom': 5.0, 'peu': 5.0, 'crust': 5.0, 'floral': 5.0, 're': 1.6666666666666667, 'enough': 5.0, 'score': 5.0, 'herbac': 5.0, 'herbal': 2.5, 'shared': 5.0, 'lagers': 5.0, 'baklava': 5.0, 'ever': 5.0, 'body': 2.5, 'candyish': 5.0, 'full': 5.0, 'generous': 5.0, 'pleasant': 5.0, 'les': 5.0, 'pilsener': 5.0, 'found': 5.0, 'qui': 5.0, 'strong': 5.0, 'lollipop': 5.0, 'dry': 2.5, 'c': 5.0, 'perceptions': 5.0, 'ok': 5.0, 'row': 5.0, 'houblons': 5.0, 'leaves': 5.0, 'la': 5.0, 'develops': 5.0, 'steroids': 5.0, 'personal': 5.0, 'amount': 5.0, 'tement': 5.0, 'avec': 5.0, 'weird': 5.0, 'spices': 5.0, 'sweetness': 5.0, 'think': 5.0, 'installe': 5.0, 'among': 5.0, 'palais': 5.0, 'presence': 5.0, 'feel': 5.0, 'sweet': 1.6666666666666667, 'prefer': 5.0, 'one': 5.0, 'brought': 5.0, 'marvelous': 5.0, 'en': 5.0, 'long': 5.0, 'balanced': 5.0, 'tap': 2.5, 'thick': 5.0, 'flavors': 5.0, 'little': 5.0, 'che': 5.0, 'would': 5.0, 'tasting': 5.0, 'leading': 2.5, 'muddy': 5.0, 'faint': 5.0, 'moderately': 5.0, 'honeyed': 1.6666666666666667, 'heavy': 5.0, 'creamy': 1.6666666666666667, 'beer': 2.5, 'much': 5.0, 'typing': 5.0, 'yeasty': 5.0, 'white': 1.6666666666666667, 'assez': 5.0, 'warmth': 5.0, 'foam': 5.0, 'laces': 5.0, 'hue': 5.0, 'head': 1.25, 'medium': 1.6666666666666667, 'plusieurs': 5.0, 'great': 5.0, 'brewpub': 1.6666666666666667, 'al': 2.5, 'flowery': 5.0, 'heat': 5.0, 'maltiness': 5.0, 'angles': 5.0, 'seduces': 5.0, 'complexit': 5.0, 'line': 5.0, 'flowers': 5.0, 'lacing': 5.0, 'cerealic': 5.0, 'misty': 5.0, 'kind': 5.0, 'mouthfeel': 5.0, 'look': 5.0, 'hop': 1.6666666666666667, 'malt': 2.5, 'grainy': 5.0, 'bitterness': 2.5, 'unfortunately': 5.0, 'pr': 5.0, 'crackery': 5.0, 'strawberry': 5.0, 'un': 5.0, 'fruits': 2.5, 'robuste': 5.0, 'fruity': 5.0, 'expect': 5.0, 'flavor': 5.0, 'palate': 2.5, 'cereals': 2.5, 'grassy': 2.5, 'ln': 5.0, 'taste': 5.0, 'well': 5.0, 'accents': 5.0, 'pic': 5.0, 'pie': 5.0, 'comfortable': 5.0, 'honey': 2.5, 'spicy': 1.6666666666666667, 'something': 5.0, 'beautifully': 5.0, 'sharp': 5.0, 'leafy': 5.0, 'levelled': 5.0, 'generously': 5.0, 'imho': 5.0, 'huge': 5.0, 'blonde': 5.0, 'harsh': 5.0, 'pure': 5.0, 'permanence': 5.0, 'studying': 5.0, 'gravity': 5.0, 'topped': 5.0, 'tr': 5.0, 'note': 5.0, 'apricots': 5.0, 'cerna': 2.5, 'es': 5.0, 'malty': 5.0, 'robustesse': 5.0, 'malts': 2.5, 'toasted': 5.0, 'higher': 5.0, 'profile': 5.0, 'lam': 5.0, 'finish': 1.6666666666666667, 'countryside': 5.0, 'drink': 5.0, 'compl': 5.0, 'breadcrumb': 5.0, 'moment': 5.0, 'est': 5.0, 'two': 5.0, 'valak': 5.0, 'pastry': 5.0, 'cracker': 5.0, 'assailli': 5.0, 'else': 2.5, 'friends': 5.0, 'warming': 5.0, 'short': 5.0, 'pints': 5.0, 'especially': 5.0, 'light': 2.5, 'clear': 5.0, 'grass': 5.0, 'life': 5.0, 'sv': 5.0, 'pears': 5.0, 'caramunich': 5.0, 'bottle': 2.5, 'classy': 5.0, 'far': 5.0, 'fresh': 2.5})]\n"
     ]
    }
   ],
   "source": [
    "### recall beerTrainNormalized is a normalized beerTrain which is 80% of each user's reviews.\n",
    "### This takes the form of beerByUser = allBeer.map(lambda x:(x[19],x)) Where x is the entire\n",
    "### line and x[19] is the user_id.  Let's remap this to use the beer id as the key\n",
    "### similar to beerTrainToToken.\n",
    "\n",
    "trainByBeer = beerTrainNormalized.map(lambda (x,y):(y[0],(tokenize(y[6]),tokenize(y[22]),y)))\n",
    "\n",
    "### Remap to form similar to reviewTokens = beerTrainToToken.map(lambda (x,y):(x,y[1]))\n",
    "### which is the input for the idfByKey function.\n",
    "reviewTokensByBeer = trainByBeer.map(lambda (x,(a,b,c)):(x,b))\n",
    "\n",
    "### Now apply the idfByKey Function to get the idf dictionaries for each beer\n",
    "idfByBeer = IDFByKey(reviewTokensByBeer)\n",
    "print idfByBeer.takeSample(False,2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate tf-idf of features in each beer.\n",
    "#### Time to make a tf-idf for each beer, this time we won't weight it by the review, as we're trying to extract honest features from the beer, not each user's opinion about those features.  If someone indicates that the beer tastes like grapefruit but does not enjoy grapefruit, it doesn't mean that another user who does enjoy grapefruit will not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1535', {'houston': 0.21212121212121213, 'gold': 0.17748917748917747, 'summer': 0.7241379310344828, 'ale': 0.14, 'recipe': 0.14, 'aroma': 0.20028794233104577, 'enjoyable': 0.1808035714285714, 'mild': 0.20065520065520065, 'via': 0.2039695945945946, 'citrusy': 0.14, 'carbonation': 0.21875, 'flavor': 0.19068965517241382, 'buddy': 0.2039695945945946, '22': 0.14285714285714285, 'hops': 0.164992784992785, 'texture': 0.14285714285714285, 'actually': 0.14, 'hay': 0.21212121212121213, 'grapefruit': 0.36653006356670154, 'pretty': 0.2501501501501502, 'orange': 0.14613756613756615, '2014': 0.15555555555555556, 'whack': 0.21212121212121213, 'merchant': 0.21212121212121213, 'brown': 0.21212121212121213, 'good': 0.22675026123301986, 'citrus': 0.18715277777777778, 'big': 0.1921182266009852, 'overall': 0.21875, 'truly': 0.14285714285714285, 'bandage': 0.14, 'signiture': 0.3111111111111111, 'colour': 0.1891891891891892, 'crisp': 0.21875, 'like': 0.14, 'notes': 0.16158158158158162, 'dig': 0.14, 'bright': 0.15555555555555556, 'cloudy': 0.16720238095238096, 'bad': 0.15555555555555556, 'caramel': 0.1891891891891892, 'nose': 0.15555555555555556, 'sparse': 0.15555555555555556, 'small': 0.1645945945945946, 'went': 0.21875, 'pint': 0.14, 'diacytl': 0.15555555555555556, 'bone': 0.2857142857142857, 'lasting': 0.2522321428571428, 'cookies': 0.1891891891891892, 'fluffy': 0.15555555555555556, 'light': 1.206896551724138, 'burger': 0.14285714285714285, 'see': 0.14, 'lingers': 0.24137931034482757, 'curious': 0.14, 'pale': 0.14, 'really': 0.1492063492063492, 'opaque': 0.21212121212121213, 'mug': 0.14285714285714285, 'smells': 0.14, 'got': 0.14, 'body': 0.1808035714285714, 'hose': 0.14, 'bold': 0.14285714285714285, 'pours': 0.17143518518518522, 'assertive': 0.21212121212121213, 'however': 0.15555555555555556, 'bj': 0.15555555555555556, 'standard': 0.14, 'base': 0.14, 'quite': 0.14, 'kitchen': 0.14285714285714285, 'dry': 0.2857142857142857, 'league': 0.14285714285714285, 'last': 0.14, 'colored': 0.14285714285714285, 'buffred': 0.21212121212121213, 'bodied': 0.24137931034482757, 'caramelly': 0.14, 'american': 0.14, 'oz': 0.14285714285714285, 'weird': 0.14, 'tx': 0.16253396253396254, 'austin': 0.16253396253396254, 'think': 0.15555555555555556, 'exotic': 0.1891891891891892, 'golden': 0.1891891891891892, 'ipa': 0.1569004719004719, 'dont': 0.15555555555555556, 'presence': 0.14285714285714285, 'sweet': 0.17606060606060608, 'veggie': 0.21875, 'primarily': 0.21875, 'rind': 0.21212121212121213, 'quality': 0.14, 'maple': 0.21212121212121213, 'flavors': 0.15555555555555556, 'rated': 0.2039695945945946, 'hoppy': 0.18264639639639643, 'decent': 0.1645945945945946, 'long': 0.14285714285714285, 'beer': 0.1980439105977899, 'going': 0.14, 'draft': 0.14285714285714285, 'iphone': 0.2039695945945946, 'frothy': 0.14285714285714285, 'white': 0.19390398921648921, 'bitter': 0.20065520065520065, 'sort': 0.15555555555555556, 'head': 0.18569320143827533, 'medium': 0.20377691633079564, 'homemade': 0.14285714285714285, 'mostly': 0.26493055555555556, 'rinds': 0.15555555555555556, 'sedimented': 0.21212121212121213, 'deep': 0.1891891891891892, 'mellow': 0.21212121212121213, 'mutted': 0.3111111111111111, 'dull': 0.3111111111111111, 'shady': 0.14, 'made': 0.14, 'flavour': 0.1891891891891892, 'mouthy': 0.21212121212121213, 'egregious': 0.14, 'tavern': 0.14285714285714285, 'type': 0.28, 'malt': 0.24349986349986352, 'fries': 0.14285714285714285, 'bitterness': 0.1822452994866788, 'cask': 0.24137931034482757, 'paired': 0.14285714285714285, 'tones': 0.17748917748917747, 'fruits': 0.1891891891891892, 'fruity': 0.20065520065520065, 'amber': 0.23006465517241378, 'tap': 0.18383838383838386, 'grassy': 0.28, 'lightly': 0.21212121212121213, 'taste': 0.21875, 'ginger': 0.1891891891891892, 'sticky': 0.21875, 'tastes': 0.14, 'something': 0.15555555555555556, 'sweetish': 0.1891891891891892, 'cream': 0.24137931034482757, 'perhaps': 0.21875, 'lacing': 0.17238756613756614, 'pine': 0.25838873818399677, 'rubber': 0.28, 'smell': 0.14285714285714285, 'nice': 0.3203463203463203, 'finish': 0.21212121212121213, 'though': 0.14, 'draught': 0.1891891891891892, 'june': 0.15555555555555556, 'fruit': 0.7241379310344828, 'floral': 0.2857142857142857, 'tacos': 0.21875, 'man': 0.1891891891891892, 'mineral': 0.21212121212121213, 'grove': 0.14, 'sweetness': 0.1891891891891892, 'clear': 0.1891891891891892, 'lot': 0.14, 'well': 0.17238756613756614, 'cascade': 0.3111111111111111, 'pineapple': 0.21212121212121213, 'fresh': 0.15555555555555556}), ('20248', {'obfuscated': 0.013888888888888888, 'brews': 0.013888888888888888, 'bananas': 0.013888888888888888, 'vinous': 0.013888888888888888, 'within': 0.013888888888888888, 'surprisingly': 0.013888888888888888, 'yellow': 0.013888888888888888, 'second': 0.013888888888888888, 'dough': 0.013888888888888888, 'hazy': 0.013888888888888888, 'flavor': 0.013888888888888888, 'fine': 0.013888888888888888, 'allusions': 0.013888888888888888, 'cloud': 0.013888888888888888, 'monster': 0.013888888888888888, 'even': 0.013888888888888888, 'aging': 0.013888888888888888, 'alcohol': 0.013888888888888888, 'bottom': 0.013888888888888888, 'personal': 0.013888888888888888, 'though': 0.013888888888888888, 'long': 0.013888888888888888, 'rustic': 0.013888888888888888, 'hay': 0.013888888888888888, 'beer': 0.013888888888888888, 'beige': 0.013888888888888888, 'slowly': 0.013888888888888888, 'whip': 0.013888888888888888, 'lot': 0.013888888888888888, 'tends': 0.013888888888888888, 'white': 0.013888888888888888, 'dominate': 0.013888888888888888, 'warmth': 0.013888888888888888, 'treatment': 0.013888888888888888, 'profile': 0.013888888888888888, 'case': 0.013888888888888888, 'finish': 0.027777777777777776, 'easygoing': 0.013888888888888888, 'yeast': 0.013888888888888888, 'atop': 0.013888888888888888, 'foam': 0.013888888888888888, 'envelop': 0.013888888888888888, 'dissipates': 0.013888888888888888, 'tiring': 0.013888888888888888, 'often': 0.013888888888888888, 'glass': 0.013888888888888888, 'base': 0.013888888888888888, 'grapes': 0.013888888888888888, 'sauternes': 0.013888888888888888, 'line': 0.013888888888888888, 'lac': 0.013888888888888888, 'barrel': 0.013888888888888888, 'bread': 0.013888888888888888, 'pancake': 0.013888888888888888, 'perceptions': 0.013888888888888888, 'could': 0.013888888888888888, 'well': 0.027777777777777776, 'never': 0.013888888888888888, 'st': 0.013888888888888888, 'pears': 0.013888888888888888, 'nose': 0.013888888888888888, 'bottle': 0.027777777777777776, 'brew': 0.013888888888888888, 'found': 0.013888888888888888, 'jean': 0.013888888888888888, 'works': 0.013888888888888888, 'notes': 0.013888888888888888, 'say': 0.013888888888888888, 'first': 0.013888888888888888})]\n"
     ]
    }
   ],
   "source": [
    "beerTfIdf = stfidfByKey(trainByBeer,idfByBeer,True,-1)\n",
    "print beerTfIdf.takeSample(False,2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4:  Cosine distance\n",
    "\n",
    "#### We now have two sets of features, one per user and one per beer.  How do we compare the two?  One method is to imagine a multidimensional space where each word, or feature is a direction.  The weight on each feature is the distance along that axis.  In order to compare, we measure the angle between the two vectors.  A smaller angle will correspond to vectors pointing in nearly the same direction.\n",
    "\n",
    "#### The formula for cosine distance is:\n",
    "#### $$ similarity = \\cos \\theta = \\frac{a \\cdot b}{\\|a\\| \\|b\\|} = \\frac{\\sum a_i b_i}{\\sqrt{\\sum a_i^2} \\sqrt{\\sum b_i^2}} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the components of a cosine distance function\n",
    "#### We need to make a function `similarity` that returns cosine distance given two dictionaries.  The dot product of two dictionaries divided by the magnitudes of each dictionary.  Since perpendicular components have a dot product of zero we can ignore features which do not appear in both dictionaries.  To do this we can use the intersection of their keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.925820099773\n",
      "0.633503512093\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def similarity(a, b):\n",
    "    if len(a)==0 or len(b)==0:\n",
    "         sim=0\n",
    "    else:\n",
    "        aDotB= sum([a[token]*b[token] for token in list(set(a.keys())&set(b.keys()))])\n",
    "        magA = sqrt(sum(a[token]*a[token] for token in a.keys()))\n",
    "        magB = sqrt(sum(b[token]*b[token] for token in b.keys()))\n",
    "        if magA!=0 and magB!=0:\n",
    "            sim = aDotB/(magA*magB)\n",
    "        else:\n",
    "            sim=0\n",
    "    return sim\n",
    "\n",
    "testVec1 = {'foo': 2, 'bar': 2, 'baz': 2 }\n",
    "testVec2 = {'foo': 3, 'bar': 2, 'baz': 1 }\n",
    "print similarity(testVec1, testVec2)\n",
    "\n",
    "testVec3 = {'foo': 20, 'bar': 1, 'baz': 1 }\n",
    "print similarity(testVec1, testVec3)\n",
    "\n",
    "testVec4={}\n",
    "print similarity(testVec1, testVec4)\n",
    "\n",
    "testVec5 = {'foo': 0, 'bar': 0, 'baz': 0 }\n",
    "print similarity(testVec1, testVec5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing a menu's worth of beers to a user\n",
    "#### Recall that we split the original data set into 80% for training and 20% for test.  We consider the 20% of each user's reviews as a menu.  We can then compare each of the beers on the menu, using the features extracted from the training set to the features we extracted for each user.  By using the cosine similarity we can generate a score for each beer and rank them.  We can then compare this ranking to the user's given ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### beerTest is of the form (user,line)\n",
    "### we can remap this to (beer, line) and then join with beerTfIdf, then remap back\n",
    "### to (user,line,beerTfIdf).  Then join to scoreTfIdf and generate cosine distance between\n",
    "### beerTfIdf and scoreTFIdf.  We'll then have (user,line,score) which we can examine\n",
    "\n",
    "beerTestByBeer = beerTest.map(lambda (x,y):(y[0],y))\n",
    "beerTestByBeerWithTfIdf = beerTestByBeer.join(beerTfIdf)\n",
    "beerTestByUserWithTfIdf = beerTestByBeerWithTfIdf.map(lambda (x,y):(y[0][19],(y[0],y[1])))\n",
    "beerTestByUserWithDicts = beerTestByUserWithTfIdf.join(scoreTfIdf)\n",
    "beerTestByUserWithDictsFlat = beerTestByUserWithDicts.map(lambda (x,y):(x,y[0][0],y[0][1],y[1]))\n",
    "##special handling, there are users with no review words and beers with no words\n",
    "##so get rid of them.\n",
    "removeEmpties = beerTestByUserWithDictsFlat.filter(lambda (a,b,c,d):(d!=False and c!=False))\n",
    "cosSim = removeEmpties.map(lambda (a,b,c,d):(a,(b,similarity(c,d)))).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('34029', '4.5', 0.06314776249925434), ('32268', '4', 0.022014968603634253), ('1014', '4', 0.015119150932917616), ('41304', '3.8', -0.04408774738651987), ('33588', '3.8', 0.009129180630959433), ('34418', '3.6', 0.012730285531791945), ('33480', '3.6', 0.018590353250082813), ('33279', '3.6', -0.0015263740421353545), ('31919', '3.5', -0.010090406488097217), ('32881', '3.5', -0.016956111266384355), ('11650', '3.5', 0.053751189576677266), ('32629', '3.5', 0.006951154159011795), ('32263', '3.4', -0.0199769491586477), ('34012', '3.4', 0.031111667111214217), ('16635', '3.4', -0.0007188715336961673), ('33918', '3.4', -0.0021392987295092603), ('34324', '3.4', -0.020078258321739657), ('31949', '3.3', 0.006225176856970573), ('34071', '3.3', -0.0040258814466033275), ('32993', '3.3', -0.01293893382921166), ('32467', '3.3', 0.004410876564301802), ('32724', '3.2', 0.011324534038628), ('32292', '3.2', -0.02973258199799241), ('34034', '3.2', -0.02857905058276), ('32020', '3.2', 0.013119988345199075), ('7411', '3.1', -0.03152069848805093), ('41813', '3.1', -0.008765821665025694), ('27671', '3.1', -0.03207850361636283), ('33409', '3.1', -0.02809584246261045), ('34026', '3.1', 0.013188280292664238), ('33294', '3', -0.06058885538668639), ('32162', '2.9', -0.03971352131478246), ('32450', '2.9', -0.006486937144441537), ('10360', '2.9', -0.018961273781143574), ('34013', '2.7', -0.0034676684569495343), ('34049', '2.7', 0.008426237134978226), ('33803', '2.5', -0.03731550446846807), ('33020', '1.4', -0.04339473771567814)]\n"
     ]
    }
   ],
   "source": [
    "oneUser = cosSim.filter(lambda (x,y):x=='patrick767').map(lambda (x,y):(y[0][0],y[0][13],y[1])).collect()\n",
    "print sorted(oneUser,key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantifying the fit\n",
    "#### Now that we've scored the beers and looking at the single user above we can visually see that there's a correspondence between the generated rating and the user's rating, we need to quantify how closely the two lists match.\n",
    "\n",
    "#### There are a number of ways to do this like the Rank Biased Overlap, the Kendall Tau and counting the pair wise swaps to match the lists exactly.  I'm going to try using Spearman's rank correlation coefficient as it measures monotonicity, in a simple way with statistical tests available.  It's also available in the Scipy library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4570\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 3141.0 failed 1 times, most recent failure: Lost task 1.0 in stage 3141.0 (TID 75452, localhost): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/hdp/2.3.0.0-2557/spark/python/pyspark/worker.py\", line 101, in main\n    process()\n  File \"/usr/hdp/2.3.0.0-2557/spark/python/pyspark/worker.py\", line 96, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/hdp/2.3.0.0-2557/spark/python/pyspark/rdd.py\", line 2252, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/hdp/2.3.0.0-2557/spark/python/pyspark/rdd.py\", line 2252, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/hdp/2.3.0.0-2557/spark/python/pyspark/rdd.py\", line 2252, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/hdp/2.3.0.0-2557/spark/python/pyspark/rdd.py\", line 282, in func\n    return f(iterator)\n  File \"/usr/hdp/2.3.0.0-2557/spark/python/pyspark/rdd.py\", line 932, in <lambda>\n    return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum()\n  File \"/usr/hdp/2.3.0.0-2557/spark/python/pyspark/rdd.py\", line 932, in <genexpr>\n    return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum()\n  File \"<ipython-input-83-218dbf42c252>\", line 53, in <lambda>\n  File \"/opt/rh/python27/root/usr/lib64/python2.7/site-packages/scipy/stats/stats.py\", line 2537, in pearsonr\n    mx = x.mean()\n  File \"/opt/rh/python27/root/usr/lib64/python2.7/site-packages/numpy/core/_methods.py\", line 66, in _mean\n    ret = umr_sum(arr, axis, dtype, out, keepdims)\nTypeError: cannot perform reduce with flexible type\n\n\tat org.apache.spark.api.python.PythonRDD$$anon$1.read(PythonRDD.scala:135)\n\tat org.apache.spark.api.python.PythonRDD$$anon$1.<init>(PythonRDD.scala:176)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:94)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:277)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:244)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:64)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:203)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1204)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1193)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1192)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1192)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:693)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:693)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:693)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1393)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1354)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-218dbf42c252>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mavgSpearmanRho\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mavgSpearman\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcosSim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-83-218dbf42c252>\u001b[0m in \u001b[0;36mavgSpearman\u001b[1;34m(inputRDD)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mspearmanByKey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvertedToLists\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpearsonr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mspearmanOnly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspearmanByKey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[1;32mprint\u001b[0m \u001b[0mspearmanOnly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtakeSample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[0mavgSpearmanRho\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspearmanOnly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduceNaN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mspearmanOnly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mspearmanOnly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mspearmanOnly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/hdp/2.3.0.0-2557/spark/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mtakeSample\u001b[1;34m(self, withReplacement, num, seed)\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m         \u001b[0minitialCount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minitialCount\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/hdp/2.3.0.0-2557/spark/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mcount\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    930\u001b[0m         \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \"\"\"\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/hdp/2.3.0.0-2557/spark/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36msum\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    921\u001b[0m         \u001b[1;36m6.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m         \"\"\"\n\u001b[1;32m--> 923\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    924\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/hdp/2.3.0.0-2557/spark/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mreduce\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    737\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m         \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    740\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/hdp/2.3.0.0-2557/spark/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mcollect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    711\u001b[0m         \"\"\"\n\u001b[0;32m    712\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 713\u001b[1;33m             \u001b[0mport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    714\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/hdp/2.3.0.0-2557/spark/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    536\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m         return_value = get_return_value(answer, self.gateway_client,\n\u001b[1;32m--> 538\u001b[1;33m                 self.target_id, self.name)\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/hdp/2.3.0.0-2557/spark/python/lib/py4j-0.8.2.1-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    298\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    299\u001b[0m                     \u001b[1;34m'An error occurred while calling {0}{1}{2}.\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m                     format(target_id, '.', name), value)\n\u001b[0m\u001b[0;32m    301\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 3141.0 failed 1 times, most recent failure: Lost task 1.0 in stage 3141.0 (TID 75452, localhost): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/hdp/2.3.0.0-2557/spark/python/pyspark/worker.py\", line 101, in main\n    process()\n  File \"/usr/hdp/2.3.0.0-2557/spark/python/pyspark/worker.py\", line 96, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/hdp/2.3.0.0-2557/spark/python/pyspark/rdd.py\", line 2252, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/hdp/2.3.0.0-2557/spark/python/pyspark/rdd.py\", line 2252, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/hdp/2.3.0.0-2557/spark/python/pyspark/rdd.py\", line 2252, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/hdp/2.3.0.0-2557/spark/python/pyspark/rdd.py\", line 282, in func\n    return f(iterator)\n  File \"/usr/hdp/2.3.0.0-2557/spark/python/pyspark/rdd.py\", line 932, in <lambda>\n    return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum()\n  File \"/usr/hdp/2.3.0.0-2557/spark/python/pyspark/rdd.py\", line 932, in <genexpr>\n    return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum()\n  File \"<ipython-input-83-218dbf42c252>\", line 53, in <lambda>\n  File \"/opt/rh/python27/root/usr/lib64/python2.7/site-packages/scipy/stats/stats.py\", line 2537, in pearsonr\n    mx = x.mean()\n  File \"/opt/rh/python27/root/usr/lib64/python2.7/site-packages/numpy/core/_methods.py\", line 66, in _mean\n    ret = umr_sum(arr, axis, dtype, out, keepdims)\nTypeError: cannot perform reduce with flexible type\n\n\tat org.apache.spark.api.python.PythonRDD$$anon$1.read(PythonRDD.scala:135)\n\tat org.apache.spark.api.python.PythonRDD$$anon$1.<init>(PythonRDD.scala:176)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:94)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:277)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:244)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:64)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:203)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1204)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1193)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1192)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1192)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:693)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:693)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:693)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1393)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1354)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n"
     ]
    }
   ],
   "source": [
    "### ToDo: lookup Kendall Tau, Rank Biased Overlap (RBO), maybe mean squared error??\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats.stats import rankdata\n",
    "from scipy.stats import pearsonr\n",
    "import math\n",
    "\n",
    "### Need to implement a function which will take the results from the cosSim RDD and spit out\n",
    "### average?? spearman.\n",
    "\n",
    "def catTuplesToLists(tupleOne,tupleTwo):\n",
    "    if len(tupleOne)==len(tupleTwo):\n",
    "        a=[]\n",
    "        for x in range(0,len(tupleOne)):\n",
    "            firstEle=tupleOne[x]\n",
    "            if type(firstEle) is not list: firstEle = [ tupleOne[x] ]\n",
    "            secondEle=tupleTwo[x]\n",
    "            if type(secondEle) is not list: secondEle = [ tupleTwo[x] ]\n",
    "            a.append(firstEle+secondEle)\n",
    "        return tuple(a)\n",
    "    else:\n",
    "        raise ValueError('Two tuples are not the same dimensions')\n",
    "\n",
    "def mattSpearman(listOne,listTwo):\n",
    "    if type(listOne) is list and type(listTwo) is list:\n",
    "        lO=len(listOne)\n",
    "        if lO==len(listTwo) and lO>1:\n",
    "            lOR = rankdata(listOne)\n",
    "            lTR = rankdata(listTwo)\n",
    "            dSquared=0\n",
    "            for x in range(0,lO):\n",
    "                dSquared+=(lOR[x]+lTR[x])**2\n",
    "            return 1-6*dSquared/lO/(lO**2-1)\n",
    "        else:\n",
    "            raise ValueError(\"Both Lists must be same length and greater than one.\")\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def reduceNaN(a,b):\n",
    "    if math.isnan(a[0]):\n",
    "        a[0]=0.5\n",
    "    if math.isnan(b[0]):\n",
    "        b[0]=0.5\n",
    "    return a[0]+b[0]\n",
    "\n",
    "def avgSpearman(inputRDD):\n",
    "    #So the problem here is trying to output two lists which have the scores in the same order.\n",
    "    #Write custom reduce function, catTuplesToLists\n",
    "    convertedToLists = inputRDD.map(lambda (x,y):(x,(y[0][0],y[0][13],y[1]))).reduceByKey(catTuplesToLists)\n",
    "    ##Need to filter out lists that are of length 1, spearman R has term /n(n^2-1)\n",
    "    print convertedToLists.count()\n",
    "    filteredLists = convertedToLists.filter(lambda (x,y):type(y[1]) is list)\n",
    "    ##Now apply spearmanr\n",
    "    spearmanByKey = convertedToLists.map(lambda (x,y):(x,pearsonr(y[1],y[2])[0], len(y[1])))\n",
    "    spearmanOnly = spearmanByKey.map(lambda (x,y,z):(y,z))\n",
    "    print spearmanOnly.takeSample(False,10,1)\n",
    "    avgSpearmanRho=spearmanOnly.reduce(reduceNaN)/spearmanOnly.count()/spearmanOnly.map(lambda (x,y,z):z).reduce(lambda a,b:a+b)\n",
    "    print spearmanOnly.count()\n",
    "    return avgSpearmanRho\n",
    "\n",
    "print avgSpearman(cosSim)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
